{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pulsar-kkaturi/DL-Education/blob/master/VisionDL_Lecture/Lecture4_CNNBuild_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDwyTaV-qfxS"
      },
      "source": [
        "# Lecture 4. CNN build\n",
        "* Ref. 최건호, 파이토치 첫걸음, 한빛미디어 ([link](https://drive.google.com/drive/folders/12zphz36T6gEJac6WScnvRN27-f1tfHO1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbis08CwqfxY"
      },
      "source": [
        "## 1. 인공신경망 (Deep Neural Network; DNN)\n",
        "* 2장의 선형회귀모델과 달리, 비선형인 2차함수에 대한 회귀모델을 딥러닝으로 구현해보자!\n",
        "* y = x<sup>2</sup>+3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaRQj86vqfxZ"
      },
      "source": [
        "### 1.1. 라이브러리 및 데이터 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D-w3vIhiqfxa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5tntzZtKqfxc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "사용 가능한 GPU가 존재하는가? (True or False):  False\n",
            "사용 가능한 GPU가 존재하지 않습니다. 혹은 GPU를 Pytorch가 찾지 못하고 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# GPU에서 학습을 위해 GPU check\n",
        "print(\"사용 가능한 GPU가 존재하는가? (True or False): \", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"사용 가능한 GPU의 수는 {} 개 입니다.\".format(torch.cuda.device_count()))\n",
        "    print(\"GPU 각각의 이름은 아래와 같습니다.\")\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(\"GPU {}: {}\".format(i, torch.cuda.get_device_name(i)))\n",
        "else:\n",
        "    print(\"사용 가능한 GPU가 존재하지 않습니다. 혹은 GPU를 Pytorch가 찾지 못하고 있습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxJkyWgQqfxc"
      },
      "outputs": [],
      "source": [
        "# 데이터 생성\n",
        "num_data = 1000\n",
        "\n",
        "noise = init.normal_(torch.FloatTensor(num_data,1),std=3)\n",
        "x = init.uniform_(torch.Tensor(num_data,1),-15,15)\n",
        "y = (x**2) + 3\n",
        "y_noise = y + noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWyDNZ-Tqfxd"
      },
      "outputs": [],
      "source": [
        "# 데이터 시각화\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(x.numpy(), y_noise.numpy(), s=3, c='gray', label='Original Data') # 학습시킬 실제 데이터 분포\n",
        "plt.scatter(x.numpy(), y.numpy(), s=3, c='red', label='Label Data') # 정답 분포\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgQhpePwqfxe"
      },
      "source": [
        "### 1.2. 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q94P-Zanqfxg"
      },
      "outputs": [],
      "source": [
        "# 3장의 예시처럼 하나의 값이 들어가서 하나의 값이 나오기 때문에 모델의 처음과 끝 특성의 개수는 1개입니다.\n",
        "\n",
        "# https://pytorch.org/docs/stable/nn.html?highlight=sequential\n",
        "# torch.nn.Sequential\n",
        "# Sequential 모듈은 다양한 모듈을 담을 수 있는 일종의 리스트라고 보면 됩니다.\n",
        "# Sequential 에 정의된 순서대로 연산이 진행되며, 많은 연산을 묶어서 한번에 관리할 수 있어서 편리합니다.\n",
        "\n",
        "# 아래 코드는 특성의 개수가 1 -> 6 -> 10 -> 6 -> 1개로 변하는 인공신경망입니다.\n",
        "# 또한 선형변환 이후 활성화 함수를 넣어 비선형성이 생기도록 했습니다.\n",
        "\n",
        "model = nn.Sequential(\n",
        "          nn.Linear(1,6),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(6,10),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(10,6),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(6,1),\n",
        "      )\n",
        "\n",
        "loss_func = nn.L1Loss() # 손실함수로는 L1(절대값의 평균) loss 사용\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.0002) # 옵티마이저로는 SGD 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsqZ2SQqqfxi"
      },
      "outputs": [],
      "source": [
        "num_epoch = 10000 # 학습시킬 epoch 수\n",
        "device = 'cuda:0' # 학습시킬 gpu\n",
        "loss_array = []\n",
        "pbar = tqdm(total=num_epoch) # tqdm으로 학습 진행도 확인 가능\n",
        "for i in range(num_epoch):\n",
        "    x.to(device)\n",
        "    y_noise.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(x)\n",
        "\n",
        "    loss = loss_func(output,y_noise)\n",
        "    loss.backward() # 역전파 손실 연산\n",
        "    optimizer.step() # 옵티마이저로 가중치 업데이트\n",
        "\n",
        "    pbar.set_description(f\"Processing({i+1}/{num_epoch}): loss={loss.data}\")\n",
        "    pbar.update(1)\n",
        "    loss_array.append(loss.detach().numpy()) # 손실값의 데이터만 numpy로 보냄\n",
        "pbar.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i78RshPUqfxi"
      },
      "source": [
        "### 1.3. 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tKSy5Pgqfxk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(loss_array)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ifqdyfhkqfxl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(x.detach().numpy(),y_noise, s=3, c='grey', label=\"Original Data\")\n",
        "plt.scatter(x.detach().numpy(),y, s=3, c='red', label=\"Label Data\")\n",
        "plt.scatter(x.detach().numpy(),output.detach().numpy(), s=3, c='blue',label=\"Model Output\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6tZuaxGqfxm"
      },
      "source": [
        "## 2. 합성곱 신경망 (Convolutional Neural Network; CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDlvSOjpqfxn"
      },
      "source": [
        "* MNIST 데이터 사용\n",
        "* 기초적인 합성곱 신경망 실습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1GaHMk5qfxo"
      },
      "outputs": [],
      "source": [
        "# Colab에서 실행시 파이토치 설치\n",
        "#!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHNfuNIyqfxo"
      },
      "source": [
        "### 2.1. 환경 세팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23wG-8aUqfxq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "\n",
        "# https://pytorch.org/vision/stable/datasets.html\n",
        "# 파이토치에서는 torchvision.datasets에 MNIST 등의 다양한 데이터를 사용하기 용이하게 정리해놨습니다.\n",
        "# 이를 사용하면 데이터를 따로 학습에 맞게 정리하거나 하지 않아도 바로 사용이 가능합니다.\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "# https://pytorch.org/vision/stable/transforms.html\n",
        "# torchvision.transforms에는 이미지 데이터를 자르거나 확대 및 다양하게 변형시키는 함수들이 구현되어 있습니다.\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# https://pytorch.org/docs/stable/data.html\n",
        "# DataLoader는 전처리가 끝난 데이터들을 지정한 배치 크기에 맞게 모아서 전달해주는 역할을 합니다.\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECAE7GHfqfxq"
      },
      "source": [
        "### 2.2. 데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUmgbPLmqfxr"
      },
      "outputs": [],
      "source": [
        "# https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=mnist#torchvision.datasets.MNIST\n",
        "# 첫번째 인자 root는 데이터를 저장할 위치, train은 학습용 데이터인지 테스트용 데이터인지의 여부를 의미합니다.\n",
        "data_path = '/home/student/Datasets/jhjeong/Test/' # 자신의 환경에 맞게 설정!\n",
        "\n",
        "# MNIST 데이터는 숫자 손글씨 이미지와 이에 대한 정답 쌍으로 이루어져 있습니다.\n",
        "# transform은 이미지에 대한 변형, target_transform은 정답 라벨에 대한 변형을 의미합니다.\n",
        "# transform.ToTensor()는 PIL 이미지나 Numpy 배열을 토치 텐서로 바꿔줍니다.\n",
        "\n",
        "# download는 데이터가 저장할 위치에 없을 경우 새로 다운받을지 여부입니다.\n",
        "mnist_train = dset.MNIST(root=data_path, train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "mnist_test = dset.MNIST(root=data_path, train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qHGWVUEqfxr"
      },
      "source": [
        "* MNIST Dataset 구조: (frame1(image, label), frame2(image, label), ..., frame60000(image, label))\n",
        "* index 순서 : mnist_train[frame_index(0~60000)][0(image) or 1(label)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ihcwzCdqfxr"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 확인 (torch tensor)\n",
        "print(mnist_train.__getitem__(0)[0].size(), mnist_train.__len__())\n",
        "print(mnist_test.__getitem__(0)[0].size(), mnist_test.__len__())\n",
        "\n",
        "print(len(mnist_train),len(mnist_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgPGtKo7qfxs"
      },
      "outputs": [],
      "source": [
        "print(mnist_train[0][0].size()) # 0번째 프레임의 이미지 크기 출력\n",
        "print(mnist_train[0][1]) # 0번째 프레임의 레이블(정답) 출력\n",
        "plt.figure(figsize=(12,12))\n",
        "for i in range(3*3): # 9개의 데이터 추가 확인\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(np.moveaxis(mnist_train[i][0].numpy(), 0, -1)) # np.moveaxis()는 channel 위치를 0 -> -1로 옮겨준다.\n",
        "    plt.title(f'label = {mnist_train[i][1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orFFFPHiqfxs"
      },
      "source": [
        "* DataLoader 설정\n",
        "    - batch_size = 배치 사이즈\n",
        "    - shuffle = 섞을지 여부\n",
        "    - num_workers = 데이터를 묶을때 사용할 프로세스 수\n",
        "    - drop_last = 묶고 남은 데이터를 버릴지 여부"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-l1Uiqfqfxs"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False,num_workers=2,drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L2s83L3qfxs"
      },
      "source": [
        "### 2.3. 모델 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eyC3xghqfxt"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5),             # [batch_size,1,28,28] -> [batch_size,16,24,24]\n",
        "            nn.ReLU(),                                                          # 필터의 개수는 1개(흑백이미지)에서 16개로 늘어나도록 임의로 설정했습니다.\n",
        "            nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5),            # [batch_size,16,24,24] -> [batch_size,32,20,20]\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,stride=2),                               # [batch_size,32,20,20] -> [batch_size,32,10,10]\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),          # [batch_size,32,10,10] -> [batch_size,64,6,6]\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2,stride=2)                                # [batch_size,64,6,6] -> [batch_size,64,3,3]\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(64*3*3,100),                                              # [batch_size,64*3*3] -> [batch_size,100]\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100,10)                                                   # [batch_size,100] -> [batch_size,10]\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.layer(x)                                                     # self.layer에 정의한 Sequential의 연산을 차례대로 다 실행합니다.\n",
        "        out = out.view(batch_size,-1)                                           # view 함수를 이용해 텐서의 형태를 [batch_size,나머지]로 바꿔줍니다. 2차원 이미지를 1차원으로 펴주는 과정\n",
        "                                                                                # ex) 2x3 형태였던 텐서를 .view(1,-1) 해주면 1x6의 형태로 바뀝니다. .view(3,-1)이면 3x2로 바뀜.\n",
        "                                                                                # 만약 전체 텐서의 크기가 batch_size로 나누어 떨어지지 않으면 오류가 납니다.\n",
        "        out = self.fc_layer(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vN4ciL0Hqfxt"
      },
      "outputs": [],
      "source": [
        "# gpu가 사용 가능한 경우에는 device를 gpu로 설정하고 불가능하면 cpu로 설정합니다.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# 모델을 지정한 장치로 올립니다.\n",
        "model = CNN().to(device)\n",
        "\n",
        "# 손실함수로는 크로스엔트로피를 사용합니다.\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# 최적화함수로는 Adam을 사용합니다.\n",
        "learning_rate = 0.0002\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFJMCSgAqfxt"
      },
      "source": [
        "### 2.4. 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0uY5ZIZqfxt"
      },
      "outputs": [],
      "source": [
        "# 학습 모듈\n",
        "def train(dataloader, model, loss_fn, optimizer, epoch):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.train()\n",
        "    pbar = tqdm(total=num_batches)\n",
        "    train_loss, train_acc = 0, 0\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Metric\n",
        "        correct = (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "        # Epoch result\n",
        "        train_loss += loss.item()\n",
        "        train_acc += correct\n",
        "\n",
        "        # Traing Process check\n",
        "        loss, current = loss.item(), (batch + 1) * len(x)\n",
        "        acc = correct/len(x)\n",
        "        pbar.set_description(f\" - Batch Training[{epoch}]({current}/{size}): loss = {loss:>5f}, acc = {100*acc:>0.1f}%\")\n",
        "        pbar.update(1)\n",
        "    pbar.close()\n",
        "    # epoch\n",
        "    train_loss /= num_batches\n",
        "    train_acc /= size\n",
        "    return train_loss, train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsmGKJM3qfxu"
      },
      "outputs": [],
      "source": [
        "# 검증 모듈\n",
        "def test(dataloader, model, loss_fn, epoch, show=False):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, test_acc = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            test_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    test_acc /= size\n",
        "    if show:\n",
        "        print(f\"    = Validation[{epoch}]: val_loss = {test_loss:>5f}, val_acc: {(100*test_acc):>0.1f}%\")\n",
        "    return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsH3vG9Rqfxv"
      },
      "outputs": [],
      "source": [
        "num_epoch = 10\n",
        "\n",
        "history = {'loss': [], 'val_loss': [], 'acc': [], 'val_acc': []}\n",
        "for t in range(num_epoch):\n",
        "    train_loss, train_acc = train(train_loader, model, loss_func, optimizer, t+1)\n",
        "    val_loss, val_acc = test(test_loader, model, loss_func, t+1)\n",
        "    history['loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['acc'].append(train_acc)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    print(f'# Training[{t+1}/{num_epoch}]: loss = {train_loss:>5f}, acc = {100*train_acc:>0.1f}, val_loss = {val_loss:5>f}, val_acc = {100*val_acc:>0.1f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBv8ABDAqfxv"
      },
      "source": [
        "### 2.5. 결과 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-lbS7Mrqfxw"
      },
      "outputs": [],
      "source": [
        "for key in history.keys():\n",
        "    print(key, history[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn1lxv5Kqfxw"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(121)\n",
        "plt.title('Loss')\n",
        "plt.plot(history['loss'], c='b', label='train')\n",
        "plt.plot(history['val_loss'], c='r', label='validation')\n",
        "plt.legend()\n",
        "plt.subplot(122)\n",
        "plt.title('Accuracy')\n",
        "plt.plot(history['acc'], c='b', label='train')\n",
        "plt.plot(history['val_acc'], c='r', label='validation')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxhuLW5yqfxw"
      },
      "outputs": [],
      "source": [
        "pred_dic = {'prob': [], 'pred': []}\n",
        "with torch.no_grad():\n",
        "    for img, lab in test_loader:\n",
        "        x = img.to(device)\n",
        "        pred = model.forward(x)\n",
        "        for i in range(len(x)):\n",
        "            probs = pred[i].cpu().detach().numpy()\n",
        "            # probs -= np.min(probs)\n",
        "            # probs /= np.sum(probs)\n",
        "            pred_dic['prob'].append(probs)\n",
        "            pred_dic['pred'].append(pred[i].argmax().item())\n",
        "print(pred_dic['pred'][0])\n",
        "print(pred_dic['prob'][0])\n",
        "print(len(pred_dic['pred']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftz7rDkeqfxx"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "for i in range(9):\n",
        "    img = np.moveaxis(mnist_test[i][0].detach().numpy(), 0 , -1)\n",
        "    pred = pred_dic['pred'][i]\n",
        "    # score = pred_dic['prob'][i][pred]\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f'label/pred = {mnist_test[i][1]}/{pred}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGkjXKBzqfxx"
      },
      "outputs": [],
      "source": [
        "# false case\n",
        "plt.figure(figsize=(12,12))\n",
        "n = 0\n",
        "for i in range(len(pred_dic['pred'])):\n",
        "    pred = pred_dic['pred'][i]\n",
        "    lab = mnist_test[i][1]\n",
        "    if pred != lab and n < 9:\n",
        "        n += 1\n",
        "        img = np.moveaxis(mnist_test[i][0].detach().numpy(), 0 , -1)\n",
        "        plt.subplot(3,3,n)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'label/pred = {mnist_test[i][1]}/{pred}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-5jzU7Pqfxy"
      },
      "source": [
        "## 3. Simple FCN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crt9eEDgqfx4"
      },
      "source": [
        "### 3.1. 환경 세팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mSdVAtrqfx5"
      },
      "outputs": [],
      "source": [
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAlRFa8Hqfx5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "\n",
        "# https://pytorch.org/vision/stable/datasets.html\n",
        "# 파이토치에서는 torchvision.datasets에 MNIST 등의 다양한 데이터를 사용하기 용이하게 정리해놨습니다.\n",
        "# 이를 사용하면 데이터를 따로 학습에 맞게 정리하거나 하지 않아도 바로 사용이 가능합니다.\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "# https://pytorch.org/vision/stable/transforms.html\n",
        "# torchvision.transforms에는 이미지 데이터를 자르거나 확대 및 다양하게 변형시키는 함수들이 구현되어 있습니다.\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# https://pytorch.org/docs/stable/data.html\n",
        "# DataLoader는 전처리가 끝난 데이터들을 지정한 배치 크기에 맞게 모아서 전달해주는 역할을 합니다.\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "\n",
        "# 기본 라이브러리\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 영상처리 관련 라이브러리 불러오기\n",
        "import skimage\n",
        "from skimage import io as skio\n",
        "from skimage import transform as skit\n",
        "from skimage import morphology as skim\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1unN8VQqfx5"
      },
      "source": [
        "### 3.2. 데이터셋"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z7pBIbCqfx5"
      },
      "source": [
        "#### 3.2.1. 데이터셋 다운로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byCE3mSLqfx5"
      },
      "source": [
        "* Dataset Download\n",
        "  - reference link: https://www.kaggle.com/datasets/nikhilroxtomar/brain-tumor-segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVBC9UQoqfx5"
      },
      "outputs": [],
      "source": [
        "# 데이터셋을 이 세션으로 불러오기\n",
        "!git clone https://github.com/Pulsar-kkaturi/DL-Education.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nK0Iq8hqfx6"
      },
      "outputs": [],
      "source": [
        "# 압축 풀기\n",
        "!tar -zxf ./DL-Education/dataset/brain_seg_2d.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4haq2Kaqfx6"
      },
      "source": [
        "#### 3.2.2. 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCTpL7rYqfx7"
      },
      "outputs": [],
      "source": [
        "img_fol_path = './brain_seg_2d/images'\n",
        "msk_fol_path = './brain_seg_2d/masks'\n",
        "img_file_list = [f for f in sorted(os.listdir(img_fol_path))]\n",
        "msk_file_list = [f for f in sorted(os.listdir(msk_fol_path))]\n",
        "# print(img_file_list)\n",
        "# print(msk_file_list)\n",
        "\n",
        "img_list, msk_list = [], []\n",
        "for i, i_ in enumerate(img_file_list):\n",
        "  img_path = os.path.join(img_fol_path, i_)\n",
        "  msk_path = os.path.join(msk_fol_path, msk_file_list[i])\n",
        "  img_arr = skio.imread(img_path)\n",
        "  msk_arr = skio.imread(msk_path)\n",
        "  img_list.append(img_arr)\n",
        "  msk_list.append(msk_arr)\n",
        "\n",
        "print('Image numbers = ', len(img_list))\n",
        "print('Mask numbers = ', len(msk_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcoPO37jqfx7"
      },
      "source": [
        "* 이미지 정보 & 마스크 정보 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxQA7GiZqfx7"
      },
      "outputs": [],
      "source": [
        "# 이미지 정보\n",
        "print('이미지 크기 = ', img_list[0].shape)\n",
        "print(f'이미지 최대값/최소값 = {np.max(img_list[0])}/{np.min(img_list[0])}')\n",
        "# 마스크 정보\n",
        "print('마스크 크기 = ', msk_list[0].shape)\n",
        "print(f'마스크 최대값/최소값 = {np.max(msk_list[0])}/{np.min(msk_list[0])}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSM7hbdqqfx7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(131)\n",
        "plt.title('Image')\n",
        "plt.imshow(img_list[0])\n",
        "plt.subplot(132)\n",
        "plt.title('Mask')\n",
        "plt.imshow(msk_list[0])\n",
        "plt.subplot(133)\n",
        "plt.title('Overlay')\n",
        "plt.imshow(img_list[0], cmap='gray')\n",
        "plt.imshow(msk_list[0], cmap='Reds', alpha=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idh80RgYqfx8"
      },
      "source": [
        "#### 3.2.3. 데이터셋 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjaeOOYuqfx8"
      },
      "source": [
        "* Original Mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVKFTGHqqfx8"
      },
      "outputs": [],
      "source": [
        "img_size = (200, 200) # 이미지 사이즈 정규화\n",
        "num_classes = 1 # 레이블 종류 (tumor 1개)\n",
        "\n",
        "# 이미지 전처리\n",
        "resized_imgs = [skit.resize(img, img_size, anti_aliasing=True) for img in img_list] # 이미지 크기 리사이징\n",
        "img_arrays = np.expand_dims(np.array(resized_imgs, dtype=np.float32), axis=-1) # 이미지를 array로 변환\n",
        "input_imgs = (img_arrays - np.min(img_arrays))/(np.max(img_arrays)-np.min(img_arrays)) # 이미지 정규화 (0~1)\n",
        "\n",
        "# 마스크 전처리\n",
        "resized_msks = [skit.resize(msk, img_size) for msk in msk_list] # 이미지 크기 리사이징\n",
        "msk_arrays = np.expand_dims(np.array(resized_msks), axis=-1) # 마스크를 array로 변환\n",
        "targets = np.where(msk_arrays > 0, 1, 0) # 레이블 형태(0,1)로 변환\n",
        "targets = targets.astype(np.uint8)\n",
        "\n",
        "# 이미지 정보\n",
        "print('입력 어레이 크기 = ', input_imgs.shape)\n",
        "print(f'입력 어레이 최대값/최소값 = {np.max(input_imgs)}/{np.min(input_imgs)}')\n",
        "# 마스크 정보\n",
        "print('타겟 어레이 크기 = ', targets.shape)\n",
        "print(f'타켓 어레이 최대값/최소값 = {np.max(targets)}/{np.min(targets)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06D3ZOglqfx9"
      },
      "outputs": [],
      "source": [
        "# 검증 데이터셋 분할\n",
        "num_val_samples = 100 # 검증 데이터셋에는 100건 사용\n",
        "train_input_imgs = input_imgs[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_input_imgs = input_imgs[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]\n",
        "\n",
        "# 검증 데이터셋 확인\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(131)\n",
        "plt.title('Image')\n",
        "plt.imshow(val_input_imgs[0])\n",
        "plt.subplot(132)\n",
        "plt.title('Mask')\n",
        "plt.imshow(val_targets[0])\n",
        "plt.subplot(133)\n",
        "plt.title('Overlay')\n",
        "plt.imshow(val_input_imgs[0], cmap='gray')\n",
        "plt.imshow(val_targets[0], cmap='Reds', alpha=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJciImptqfx9"
      },
      "source": [
        "#### 3.2.4. New Mask 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqNLRN3yqfx9"
      },
      "source": [
        "* New Mask\n",
        "    * FCN에서 Brain Tumor는 생각보다 어려울 것이므로, 그냥 두경부 전체를 분할하는 것으로 목표를 바꾸자!\n",
        "    * ORG Mask(3.2.3)와 New Mask(3.2.4) 둘 중 하나만 실행시킨 뒤 모델학습으로 넘어가서 성능을 비교해보자!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spCwyw6zqfx9"
      },
      "outputs": [],
      "source": [
        "img_size = (200, 200) # 이미지 사이즈 정규화\n",
        "num_classes = 1 # 레이블 종류 (tumor 1개)\n",
        "\n",
        "# 이미지 전처리\n",
        "resized_imgs = [skit.resize(img, img_size, anti_aliasing=True) for img in img_list] # 이미지 크기 리사이징\n",
        "img_arrays = np.expand_dims(np.array(resized_imgs, dtype=np.float32), axis=-1) # 이미지를 array로 변환\n",
        "input_imgs = (img_arrays - np.min(img_arrays))/(np.max(img_arrays)-np.min(img_arrays)) # 이미지 정규화 (0~1)\n",
        "\n",
        "# 마스크 전처리\n",
        "new_msk_list = [skim.closing(np.where(img > 20,  1, 0)) for img in img_list] # 레이블 형태(0,1)로 변환\n",
        "resized_msks = [skit.resize(msk, img_size) for msk in new_msk_list] # 이미지 크기 리사이징\n",
        "msk_arrays = np.expand_dims(np.array(resized_msks), axis=-1) # 마스크를 array로 변환\n",
        "targets = np.where(msk_arrays > 0, 1, 0) # 레이블 형태(0,1)로 변환\n",
        "\n",
        "targets = targets.astype(np.uint8)\n",
        "\n",
        "# 이미지 정보\n",
        "print('입력 어레이 크기 = ', input_imgs.shape)\n",
        "print(f'입력 어레이 최대값/최소값 = {np.max(input_imgs)}/{np.min(input_imgs)}')\n",
        "# 마스크 정보\n",
        "print('타겟 어레이 크기 = ', targets.shape)\n",
        "print(f'타켓 어레이 최대값/최소값 = {np.max(targets)}/{np.min(targets)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APHcnLjOqfx-"
      },
      "outputs": [],
      "source": [
        "# 검증 데이터셋 분할\n",
        "num_val_samples = 100 # 검증 데이터셋에는 100건 사용\n",
        "train_input_imgs = input_imgs[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_input_imgs = input_imgs[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]\n",
        "\n",
        "# 검증 데이터셋 확인\n",
        "plt.figure(figsize=(12,12))\n",
        "for i in range(3):\n",
        "  plt.subplot(3,3,1+3*i)\n",
        "  plt.title('Image')\n",
        "  plt.imshow(val_input_imgs[i])\n",
        "  plt.subplot(3,3,2+3*i)\n",
        "  plt.title('Mask')\n",
        "  plt.imshow(val_targets[i])\n",
        "  plt.subplot(3,3,3+3*i)\n",
        "  plt.title('Overlay')\n",
        "  plt.imshow(val_input_imgs[i], cmap='gray')\n",
        "  plt.imshow(val_targets[i], cmap='Reds', alpha=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTxSk1hmqfx-"
      },
      "source": [
        "### 3.3. 모델 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVJbIg1hqfx-"
      },
      "source": [
        "#### 3.3.1. 모델 학습 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSNK4LQbqfx-"
      },
      "outputs": [],
      "source": [
        "class BrainDataset(Dataset):\n",
        "    def __init__(self, img_list, resize=200):\n",
        "        self.img_list = img_list\n",
        "        self.resize = (resize, resize)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_list[idx]\n",
        "        img_arr = skio.imread(img_path)\n",
        "\n",
        "        # 이미지 전처리\n",
        "        input_arr = skit.resize(img_arr, self.resize, anti_aliasing=True) # 이미지 크기 리사이징\n",
        "        input_arr = np.expand_dims(np.array(input_arr), axis=0) # 이미지를 tensor로 변환\n",
        "        input_arr = (input_arr - np.min(input_arr))/(np.max(input_arr)-np.min(input_arr)) # 이미지 정규화 (0~1)\n",
        "        input_tensor = torch.tensor(input_arr, dtype=torch.float32)\n",
        "\n",
        "        # 마스크 전처리\n",
        "        output_arr = skim.closing(np.where(img_arr > 20,  1, 0)) # 레이블 형태(0,1)로 변환\n",
        "        output_arr = skit.resize(output_arr, self.resize) # 이미지 크기 리사이징\n",
        "        output_arr = np.expand_dims(np.array(output_arr), axis=0) # 마스크를 tensor로 변환\n",
        "        output_arr = np.where(output_arr > 0, 1, 0) # 레이블 형태(0,1)로 변환\n",
        "        output_tensor = torch.tensor(output_arr, dtype=torch.float32)\n",
        "\n",
        "        # if self.transform:\n",
        "        #     image = self.transform(image)\n",
        "\n",
        "        return input_tensor, output_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHl2mPEuqfx_"
      },
      "outputs": [],
      "source": [
        "# 검증 데이터셋 분할\n",
        "num_val_samples = 100 # 검증 데이터셋에는 100건 사용\n",
        "img_file_list = [os.path.join(img_fol_path, i) for i in sorted(os.listdir(img_fol_path))]\n",
        "train_list = img_file_list[:-num_val_samples]\n",
        "test_list = img_file_list[-num_val_samples:]\n",
        "print(f'Train Number = {len(train_list)} / Validation Number = {len(test_list)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDNKNGBfqfx_"
      },
      "outputs": [],
      "source": [
        "brain_train = BrainDataset(train_list)\n",
        "brain_test = BrainDataset(test_list)\n",
        "\n",
        "# 데이터셋 확인 (torch tensor)\n",
        "print(brain_train.__len__())\n",
        "print(brain_train.__getitem__(0)[0].size(), brain_train.__len__())\n",
        "print(brain_test.__getitem__(0)[0].size(), brain_test.__len__())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fbAj84rqfx_"
      },
      "outputs": [],
      "source": [
        "print(brain_test[0][0].size()) # 0번째 프레임의 이미지 크기 출력\n",
        "print(brain_test[0][1].size()) # 0번째 프레임의 레이블 크기 출력\n",
        "plt.figure(figsize=(12,7))\n",
        "for i in range(4): # 4개의 데이터 추가 확인\n",
        "    plt.subplot(2,4,i+1)\n",
        "    plt.imshow(np.moveaxis(brain_test[i][0].numpy(), 0, -1)) # np.moveaxis()는 channel 위치를 0 -> -1로 옮겨준다.\n",
        "    plt.title(f'image_{i+1}')\n",
        "    plt.subplot(2,4,i+5)\n",
        "    plt.imshow(np.moveaxis(brain_test[i][1].numpy(), 0, -1)) # np.moveaxis()는 channel 위치를 0 -> -1로 옮겨준다.\n",
        "    plt.title(f'label_{i+1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo3YKorRqfyA"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "\n",
        "train_loader = DataLoader(brain_train, batch_size=batch_size, shuffle=True, num_workers=2,drop_last=True)\n",
        "test_loader = DataLoader(brain_test, batch_size=batch_size, shuffle=False, num_workers=2,drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxCcUNNzqfyA"
      },
      "source": [
        "#### 3.3.2. 모델 빌드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAfWzzkoqfyA"
      },
      "outputs": [],
      "source": [
        "class FCN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(FCN, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.Sequential(\n",
        "            nn.Conv2d(64, num_classes, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz7hVwIrqfyB"
      },
      "outputs": [],
      "source": [
        "# gpu가 사용 가능한 경우에는 device를 gpu로 설정하고 불가능하면 cpu로 설정합니다.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# 모델을 지정한 장치로 올립니다.\n",
        "model = FCN(1).to(device)\n",
        "\n",
        "# 손실함수로는 크로스엔트로피를 사용합니다.\n",
        "loss_func = nn.BCELoss() #nn.BCEWithLogitsLoss()\n",
        "\n",
        "# 최적화함수로는 Adam을 사용합니다.\n",
        "learning_rate = 0.0002\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2Nf5lkvqfyB"
      },
      "outputs": [],
      "source": [
        "summary(model, (1, 200, 200))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40ZsF4EAqfyD"
      },
      "source": [
        "### 3.4. 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmXL_lQ0qfyE"
      },
      "outputs": [],
      "source": [
        "# 학습 모듈\n",
        "def train(dataloader, model, loss_fn, optimizer, epoch):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.train()\n",
        "    pbar = tqdm(total=num_batches)\n",
        "    train_loss, train_acc = 0, 0\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Epoch result\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Traing Process check\n",
        "        loss, current = loss.item(), (batch + 1) * len(x)\n",
        "        acc = 1 - loss\n",
        "        pbar.set_description(f\" - Batch Training[{epoch}]({current}/{size}): loss = {loss:>5f}, acc = {100*acc:>0.1f}%\")\n",
        "        pbar.update(1)\n",
        "    pbar.close()\n",
        "    # epoch\n",
        "    train_loss /= num_batches\n",
        "    train_acc = 1 - train_loss\n",
        "    return train_loss, train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RrzYu2vqfyE"
      },
      "outputs": [],
      "source": [
        "# 검증 모듈\n",
        "def test(dataloader, model, loss_fn, epoch, show=False):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, test_acc = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "    test_loss /= num_batches\n",
        "    test_acc = 1 - test_loss\n",
        "    if show:\n",
        "        print(f\"    = Validation[{epoch}]: val_loss = {test_loss:>5f}, val_acc: {(100*test_acc):>0.1f}%\")\n",
        "    return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iYzUFvvqfyE"
      },
      "outputs": [],
      "source": [
        "num_epoch = 10\n",
        "\n",
        "history = {'loss': [], 'val_loss': [], 'acc': [], 'val_acc': []}\n",
        "for t in range(num_epoch):\n",
        "    train_loss, train_acc = train(train_loader, model, loss_func, optimizer, t+1)\n",
        "    val_loss, val_acc = test(test_loader, model, loss_func, t+1)\n",
        "    history['loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['acc'].append(train_acc)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    print(f'# Training[{t+1}/{num_epoch}]: loss = {train_loss:>5f}, acc = {100*train_acc:>0.1f}%, val_loss = {val_loss:5>f}, val_acc = {100*val_acc:>0.1f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qipjZwasqfyE"
      },
      "source": [
        "### 3.5. 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoCiVXFNqfyE"
      },
      "outputs": [],
      "source": [
        "for key in history.keys():\n",
        "    print(key, history[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFfWrQg1qfyF"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(121)\n",
        "plt.title('Loss')\n",
        "plt.plot(history['loss'], c='b', label='train')\n",
        "plt.plot(history['val_loss'], c='r', label='validation')\n",
        "plt.legend()\n",
        "plt.subplot(122)\n",
        "plt.title('Accuracy')\n",
        "plt.plot(history['acc'], c='b', label='train')\n",
        "plt.plot(history['val_acc'], c='r', label='validation')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-fobV1ZqfyF"
      },
      "outputs": [],
      "source": [
        "pred_list = []\n",
        "with torch.no_grad():\n",
        "    for img, lab in test_loader:\n",
        "        x = img.to(device)\n",
        "        pred = model.forward(x)\n",
        "        for i in range(len(x)):\n",
        "            probs = pred[i].cpu().detach().numpy()\n",
        "            pred_list.append(probs)\n",
        "print(pred_list[0].shape)\n",
        "print(len(pred_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ab_ILzxqfyG"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "for i in range(4):\n",
        "    img = np.moveaxis(brain_test[i][0].detach().numpy(), 0 , -1)\n",
        "    label = np.moveaxis(brain_test[i][1].detach().numpy(), 0 , -1)\n",
        "    pred = np.moveaxis(pred_list[i], 0 , -1)\n",
        "    plt.subplot(3,4,i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f'image_{i+1}')\n",
        "    plt.subplot(3,4,i+5)\n",
        "    plt.imshow(label)\n",
        "    plt.title(f'label_{i+1}')\n",
        "    plt.subplot(3,4,i+9)\n",
        "    plt.imshow(pred)\n",
        "    plt.title(f'prediction_{i+1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xe7m4_QqfyG"
      },
      "outputs": [],
      "source": [
        "n = 1\n",
        "img = np.moveaxis(brain_test[n][0].detach().numpy(), 0 , -1)\n",
        "label = np.moveaxis(brain_test[n][1].detach().numpy(), 0 , -1)\n",
        "pred = np.moveaxis(pred_list[n], 0 , -1)\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.subplot(131)\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.imshow(label, cmap='Reds', alpha=0.2)\n",
        "plt.title('Label')\n",
        "plt.subplot(132)\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.imshow(pred, cmap='Blues', alpha=0.2)\n",
        "plt.title('Prediction')\n",
        "plt.subplot(133)\n",
        "plt.imshow(pred, cmap='Blues', alpha=0.5)\n",
        "plt.imshow(label, cmap='Reds', alpha=0.5)\n",
        "plt.title('Comparison')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCOtYuFGqfyG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
