{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pulsar-kkaturi/DL-Education/blob/master/VisionDL_Lecture/Lecture2_MathofNN_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 2. 신경망의 이해"
      ],
      "metadata": {
        "id": "wB1DT19dktPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "metadata": {
        "id": "AUm1skTbuo4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 신경망을 위한 데이터 표현"
      ],
      "metadata": {
        "id": "9J_cNvfZtTUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. 텐서"
      ],
      "metadata": {
        "id": "4y_i0K5bxs9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서 표현"
      ],
      "metadata": {
        "id": "wNJkW2p0uilU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 스칼라\n",
        "x1 = np.array(12)\n",
        "print(f'scalar x1 = {x1}  (rank-{x1.ndim} tensor)')\n",
        "# 벡터\n",
        "x2 = np.array([3, 7, 9, 8, 1])\n",
        "print(f'vector x2 = {x2}  (rank-{x2.ndim} tensor)')\n",
        "# 행렬\n",
        "x3 = np.array([[1,1,1], [2,2,2], [1,2,3]])\n",
        "print(f'matrix x3 = {x3}  (rank-{x3.ndim} tensor)')"
      ],
      "metadata": {
        "id": "iZAp9y-wtXkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서의 핵심 속성"
      ],
      "metadata": {
        "id": "3sZfHyjVukZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST 데이터\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "xBVxPzDMuqtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST 데이터의 핵심 속성\n",
        "print('축의 개수(랭크) = ', train_images.ndim)\n",
        "print('크기 = ', train_images.shape)\n",
        "print('데이터 타입 = ', train_images.dtype)"
      ],
      "metadata": {
        "id": "Q7dY4vmKvFGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST 데이터의 배치(batch) 분류\n",
        "batch_list = []\n",
        "for idx in range(6):\n",
        "  batch_list.append(train_images[10000*idx:10000*(idx+1)])\n",
        "print('총 배치의 수 = ', len(batch_list))\n",
        "print('각 배치의 크기 = ', batch_list[0].shape)"
      ],
      "metadata": {
        "id": "ZcyLfWlLvTlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.title(f'batch_{i+1} sample')\n",
        "  plt.imshow(batch_list[i][0])"
      ],
      "metadata": {
        "id": "GAEuExO-wRYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. 텐서 연산"
      ],
      "metadata": {
        "id": "qRz3wsgLxvhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dense 층 직접 구현**\n",
        "\n",
        "output = relu(dot(W, input) + b)"
      ],
      "metadata": {
        "id": "4w7BekSmxBfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# relu 함수\n",
        "def naive_relu(x):\n",
        "    assert len(x.shape) == 2\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] = max(x[i, j], 0)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ObwRB0hdxC66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sum 함수\n",
        "def naive_add(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert x.shape == y.shape\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[i, j]\n",
        "    return x"
      ],
      "metadata": {
        "id": "4JTYqos6x8oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "직접 구현한 Dense 층 연산"
      ],
      "metadata": {
        "id": "SPt_4R7FyQJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 실험용 데이터 생성\n",
        "x = np.random.random((20, 100))\n",
        "y = np.random.random((20, 100))\n",
        "print(len(x), x[0])"
      ],
      "metadata": {
        "id": "PjP1rSAjyIVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense 정방향 계산\n",
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = naive_add(x, y)\n",
        "    z = naive_relu(z)\n",
        "print(\"걸린 시간: {0:.2f} s\".format(time.time() - t0))"
      ],
      "metadata": {
        "id": "lxgP6Ca8zd6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy 이용 시\n",
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = x + y\n",
        "    z = np.maximum(z, 0.)\n",
        "print(\"걸린 시간: {0:.2f} s\".format(time.time() - t0))"
      ],
      "metadata": {
        "id": "k8NYjd7bzl78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 선형 분류 (linear classification) 실습"
      ],
      "metadata": {
        "id": "7rMorWv2lW_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. 데이터 생성"
      ],
      "metadata": {
        "id": "3zr8mlyvl6yQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2D 평면에 두 클래스의 랜덤한 포인트 생성하기"
      ],
      "metadata": {
        "id": "oQ3GsjPPl42I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples_per_class = 1000\n",
        "negative_samples = np.random.multivariate_normal(\n",
        "    mean=[0, 3], # 포인트 집단의 평균\n",
        "    cov=[[1, 0.5],[0.5, 1]], # 포인트 집단의 공분산\n",
        "    size=num_samples_per_class) # 첫번째 클래스의 포인트 생성\n",
        "positive_samples = np.random.multivariate_normal(\n",
        "    mean=[3, 0],\n",
        "    cov=[[1, 0.5],[0.5, 1]],\n",
        "    size=num_samples_per_class) # 다른 평균과 공분산을 가진 두번째 클래스"
      ],
      "metadata": {
        "id": "Of-50lvVlvgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(positive_samples.shape)\n",
        "print(positive_samples[0])"
      ],
      "metadata": {
        "id": "GpgO09X8l27d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "두 클래스를 (2000, 2) 크기의 하나의 배열로 쌓기"
      ],
      "metadata": {
        "id": "0WRMbw5emn2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)\n",
        "print(inputs.shape)"
      ],
      "metadata": {
        "id": "O5D-phLAmgNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(0과 1로 구성된) 정답지 생성하기"
      ],
      "metadata": {
        "id": "NY-6chf2m17c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets = np.vstack((np.zeros((num_samples_per_class, 1), dtype=\"float32\"),\n",
        "                     np.ones((num_samples_per_class, 1), dtype=\"float32\")))"
      ],
      "metadata": {
        "id": "T41oUPTfmvs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(targets.shape)\n",
        "print(targets[0], targets[1000])"
      ],
      "metadata": {
        "id": "CE7D-UBGmzcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "두 클래스의 포인트를 그래프로 그리기"
      ],
      "metadata": {
        "id": "ubB6Cc02nK5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(inputs[:, 0], inputs[:, 1], c=targets[:, 0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B4_-yM7dnB_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. 모델 설계"
      ],
      "metadata": {
        "id": "PTzXC-QYn0Gl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "선형 분류기의 가중치 변수 만들기 (W, b)"
      ],
      "metadata": {
        "id": "F9os5oj0nxYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 2 # 입력은 2D 포인트\n",
        "output_dim = 1 # 출력 예측은 샘플당 하나의 점수 (0~1)\n",
        "W = tf.Variable(initial_value=tf.random.uniform(shape=(input_dim, output_dim))) # kernel parameter\n",
        "b = tf.Variable(initial_value=tf.zeros(shape=(output_dim,))) # bias parameter"
      ],
      "metadata": {
        "id": "mKTkksGgnS3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "정방향 패스 함수 (선형 분류이므로 연산은 단순한 선형 변환식이다)\n",
        "\n",
        "y = W * x + b"
      ],
      "metadata": {
        "id": "zHPm77kBot0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(inputs):\n",
        "  return tf.matmul(inputs, W) + b\n",
        "# tf.matmul() 함수는 점곱을 수행하는 텐서플로 내장함수"
      ],
      "metadata": {
        "id": "5beYEJRtoE2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "손실함수 = 평균 제곱 오차 함수 (Mean Squared Error; MSE)"
      ],
      "metadata": {
        "id": "lNH4WSXnpQlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def square_loss(targets, predictions):\n",
        "    per_sample_losses = tf.square(targets - predictions) # 각 샘플별 제곱(tf.square()) 오차\n",
        "    return tf.reduce_mean(per_sample_losses) # 전체 샘플별 제곱 오차의 평균(tr.reduce_mean()) = MSE"
      ],
      "metadata": {
        "id": "O6nZxvoAo5NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 스텝 함수"
      ],
      "metadata": {
        "id": "ZvxVLSWNp_fC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1 # 학습률\n",
        "\n",
        "def training_step(inputs, targets):\n",
        "    with tf.GradientTape() as tape: # 계산 그래프 생성\n",
        "        predictions = model(inputs) # 계산 그래프 안에 모델의 정방향 패스 배치\n",
        "        loss = square_loss(targets, predictions) # 손실 계산\n",
        "    grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b]) # 가중치에 대한 손실의 Gradient 계산\n",
        "    W.assign_sub(grad_loss_wrt_W * learning_rate) # 가중치(W) 업데이트\n",
        "    b.assign_sub(grad_loss_wrt_b * learning_rate) # 가중치(b) 업데이트\n",
        "    return loss"
      ],
      "metadata": {
        "id": "RnhRnM7Yp15P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. 모델 훈련"
      ],
      "metadata": {
        "id": "oiaKdPV3qn3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(40): # 40번 학습\n",
        "    loss = training_step(inputs, targets)\n",
        "    print(f\"{step+1}번째 스텝의 손실: {loss:.4f}\") # 각 학습 epoch 별 손실 출력"
      ],
      "metadata": {
        "id": "rg2paLFVqlgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4. 결과 분석"
      ],
      "metadata": {
        "id": "fw9aEEmNq4ZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 예측"
      ],
      "metadata": {
        "id": "nLa6-G9bq9fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model(inputs)\n",
        "plt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] > 0.5, cmap='viridis')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kpJ8-0Lvqyvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "정답지와 비교"
      ],
      "metadata": {
        "id": "Nff-1NSOr8Hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('prediction')\n",
        "plt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] > 0.5, cmap='viridis')\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('target')\n",
        "plt.scatter(inputs[:, 0], inputs[:, 1], c=targets[:, 0])"
      ],
      "metadata": {
        "id": "IFqc6Qpdr7s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "선형분류기의 경계면 그리기"
      ],
      "metadata": {
        "id": "pajFN0nksjgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-1, 4, 100) # 경계선 x축 리스트\n",
        "y = - W[0] /  W[1] * x + (0.5 - b) / W[1] # 경계선 함수\n",
        "plt.plot(x, y, \"-r\")\n",
        "plt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] > 0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CIMkVULMrbzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 밑바닥부터 딥러닝 구현하기 - Lecture 1 예제 재구현"
      ],
      "metadata": {
        "id": "dx2vHhTZtJCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. 데이터 만들기 + 전처리: MNIST"
      ],
      "metadata": {
        "id": "2bfxfTsyz_IS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "jhgKjCB6sv_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서플로로 구현한 모델\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "exMJcGUh0Fru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. 모델 설계"
      ],
      "metadata": {
        "id": "vE2o0yZX0uQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense 층 구현\n",
        "class NaiveDense:\n",
        "    def __init__(self, input_size, output_size, activation):\n",
        "        self.activation = activation\n",
        "\n",
        "        w_shape = (input_size, output_size)\n",
        "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "        self.W = tf.Variable(w_initial_value) # 무작위 초기화된 W 행렬\n",
        "\n",
        "        b_shape = (output_size,)\n",
        "        b_initial_value = tf.zeros(b_shape)\n",
        "        self.b = tf.Variable(b_initial_value) # 무작위 초기화된 b 벡터\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        return self.activation(tf.matmul(inputs, self.W) + self.b) # 정방향 패스 실행\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        return [self.W, self.b] # 가중치 (W, b) 추출용 함수"
      ],
      "metadata": {
        "id": "Jnrs7QO_0Z5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 단순한 직렬 신경망 구현 (Sequential 모델)\n",
        "class NaiveSequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers:\n",
        "           x = layer(x)\n",
        "        return x # 들어온 레이어들을 쌓아서 신경망 구성\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "       weights = []\n",
        "       for layer in self.layers:\n",
        "           weights += layer.weights\n",
        "       return weights # 신경망 전체의 가중치 추출"
      ],
      "metadata": {
        "id": "0tFI_VeD02P0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 직접 신경망 구현하기\n",
        "model = NaiveSequential([\n",
        "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
        "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
        "])\n",
        "assert len(model.weights) == 4"
      ],
      "metadata": {
        "id": "hhoLfuJs1nTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 배치 제네레이터 (전체 MNIST 데이터셋에서 배치 추출)\n",
        "import math\n",
        "\n",
        "class BatchGenerator:\n",
        "    def __init__(self, images, labels, batch_size=128): # 128 단위로 배치 추출\n",
        "        assert len(images) == len(labels)\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_batches = math.ceil(len(images) / batch_size)\n",
        "\n",
        "    def next(self):\n",
        "        images = self.images[self.index : self.index + self.batch_size]\n",
        "        labels = self.labels[self.index : self.index + self.batch_size]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels"
      ],
      "metadata": {
        "id": "QlVHN5Qz1uUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. 훈련 시작"
      ],
      "metadata": {
        "id": "feghnxF62Pmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3 # 학습률\n",
        "\n",
        "def update_weights(gradients, weights): # 가중치 업데이트\n",
        "    for g, w in zip(gradients, weights):\n",
        "        w.assign_sub(g * learning_rate) # 현 가중치에 - gradient * learning_rate"
      ],
      "metadata": {
        "id": "qE2S9z-c2x3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하나의 훈련 스텝 정의\n",
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape: # 계산 그래프 선언\n",
        "        predictions = model(images_batch) # 정방향 패스 실행\n",
        "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "            labels_batch, predictions) # 손실 함수 = categorical crossentropy\n",
        "        average_loss = tf.reduce_mean(per_sample_losses) # 전체 모델의 손실\n",
        "    gradients = tape.gradient(average_loss, model.weights) # 가중치에 대한 손실의 gradient 계산\n",
        "    update_weights(gradients, model.weights) # gradient를 사용하여 가중치 업데이트\n",
        "    return average_loss"
      ],
      "metadata": {
        "id": "12gvIWw02N_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 훈련 루프 선언\n",
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "    for epoch_counter in range(epochs): # 총 epoch에 따라 위에서 정의한 훈련 스텝 반복\n",
        "        print(f\"에포크 {epoch_counter}\")\n",
        "        batch_generator = BatchGenerator(images, labels) # 앞서 정의 배치 제네레이터에서 배치 추출\n",
        "        for batch_counter in range(batch_generator.num_batches):\n",
        "            images_batch, labels_batch = batch_generator.next()\n",
        "            loss = one_training_step(model, images_batch, labels_batch) # 훈련 스텝을 통해 손실 계산 및 가중치 업데이트\n",
        "            if batch_counter % 100 == 0:\n",
        "                print(f\"{batch_counter}번째 배치 손실: {loss:.2f}\")"
      ],
      "metadata": {
        "id": "dtqXnT-73V84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 시작!\n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ],
      "metadata": {
        "id": "oFu3mYTL3hF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4. 모델 평가하기"
      ],
      "metadata": {
        "id": "k6-SugH-4OX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model(test_images)\n",
        "predictions = predictions.numpy()\n",
        "predicted_labels = np.argmax(predictions, axis=1) # 최대값을 가진 index 추출 = 예측한 레이블\n",
        "matches = predicted_labels == test_labels # 예측값 = 정답일 경우 1로 저장, 불칠치할 경우 0으로 저장\n",
        "print(f\"정확도: {matches.mean():.2f}\")"
      ],
      "metadata": {
        "id": "NP61n13r4IlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 하나에 대한 예측 (0번)\n",
        "print(predictions[0])\n",
        "print(predicted_labels[0])\n",
        "print(test_labels[0])\n",
        "print(matches[0])"
      ],
      "metadata": {
        "id": "blhOp2CU4vtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "수고하셨습니다!"
      ],
      "metadata": {
        "id": "owaDdFNtxCgL"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}