{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 19 17:07:42 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.105.01   Driver Version: 515.105.01   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 22%   40C    P8    15W / 250W |     17MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 22%   43C    P8    14W / 250W |      8MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 22%   43C    P8    16W / 250W |      8MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 22%   41C    P8    14W / 250W |      8MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# GPU status\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Jun__8_16:49:14_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.99\n",
      "Build cuda_11.7.r11.7/compiler.31442593_0\n"
     ]
    }
   ],
   "source": [
    "# CUDA Version 확인\n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 pytorch 버전은 무엇인가? : 2.0.0+cu117\n",
      "사용 가능한 GPU가 존재하는가? (True or False):  True\n",
      "사용 가능한 GPU의 수는 4 개 입니다.\n",
      "GPU 각각의 이름은 아래와 같습니다.\n",
      "GPU 0: NVIDIA GeForce GTX TITAN X\n",
      "GPU 1: NVIDIA GeForce GTX TITAN X\n",
      "GPU 2: NVIDIA GeForce GTX TITAN X\n",
      "GPU 3: NVIDIA GeForce GTX TITAN X\n"
     ]
    }
   ],
   "source": [
    "# Pytorch GPU check\n",
    "import os, torch\n",
    "print(\"현재 pytorch 버전은 무엇인가? : %s\" %(torch.__version__))\n",
    "print(\"사용 가능한 GPU가 존재하는가? (True or False): \", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"사용 가능한 GPU의 수는 {} 개 입니다.\".format(torch.cuda.device_count()))\n",
    "    print(\"GPU 각각의 이름은 아래와 같습니다.\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"GPU {}: {}\".format(i, torch.cuda.get_device_name(i)))\n",
    "else:\n",
    "    print(\"사용 가능한 GPU가 존재하지 않습니다. 혹은 GPU를 Pytorch가 찾지 못하고 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "a = torch.FloatTensor([1, 2])\n",
    "a = a.to(device)\n",
    "print(a) # device에 지정한 cuda가 뜬다면 GPU 잡고 있는 것!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 17:06:14.496193: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-19 17:06:15.348304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 tensorflow 버전은 무엇인가? : 2.12.0\n",
      "사용 가능한 GPU가 존재하는가? (True or False):  True\n",
      "현재 사용 가능한 GPU의 수는 4개 입니다.\n",
      "GPU 목록은 아래와 같습니다.\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow/Keras GPU check\n",
    "import tensorflow as tf\n",
    "print(\"현재 tensorflow 버전은 무엇인가? : %s\" %(tf.__version__))\n",
    "device_list = tf.config.list_physical_devices('GPU')\n",
    "print(\"사용 가능한 GPU가 존재하는가? (True or False): \", bool(device_list))\n",
    "if device_list:\n",
    "    print(\"현재 사용 가능한 GPU의 수는 {}개 입니다.\".format(len(device_list)))\n",
    "    print(\"GPU 목록은 아래와 같습니다.\")\n",
    "    for device in device_list:\n",
    "        print(device)\n",
    "else:\n",
    "    print(\"사용 가능한 GPU가 존재하지 않습니다. 혹은 GPU를 Tensorflow가 찾지 못하고 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
