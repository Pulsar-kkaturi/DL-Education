{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pulsar-kkaturi/DL-Education/blob/master/VisionDL_Lecture/Lecture4_CNNBuild_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDCIqpTnJeqZ"
      },
      "source": [
        "# Lecture 4. CNN Build"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTaaZF3HJs40"
      },
      "source": [
        "## 1. Simple CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwbSpz2l8v7_"
      },
      "source": [
        "### 1.1. Library Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIIvdH4_JbR2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os, matplotlib, random\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "### Tensorflow 2.0 ###\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5JgCVTgBH9s"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSc3RZmiKDUv"
      },
      "source": [
        "### 1.2. 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6Z_blzwKB16"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test)= tf.keras.datasets.mnist.load_data(path='minist.npz')\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FLSAWYcKIjl"
      },
      "outputs": [],
      "source": [
        "x_train_list = []\n",
        "x_test_list = []\n",
        "for i, i_ in enumerate(x_train[:1000]):\n",
        "    arr = np.zeros(shape=(32, 32))\n",
        "    arr[:28,:28] = x_train[i]\n",
        "    x_train_list.append(arr)\n",
        "for i, i_ in enumerate(x_test[:500]):\n",
        "    arr = np.zeros(shape=(32, 32))\n",
        "    arr[:28,:28] = x_test[i]\n",
        "    x_test_list.append(arr)\n",
        "\n",
        "x_train1 = np.expand_dims(np.array(x_train_list), axis=-1)\n",
        "x_test1 = np.expand_dims(np.array(x_test_list), axis=-1)\n",
        "print(x_train1.shape, x_test1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xvzy72PlM64n"
      },
      "outputs": [],
      "source": [
        "y_train_list = []\n",
        "y_test_list = []\n",
        "for i, i_ in enumerate(y_train[:1000]):\n",
        "    zero = [0]*10\n",
        "    zero[i_] = 1\n",
        "    y_train_list.append(zero)\n",
        "\n",
        "for i, i_ in enumerate(y_test[:500]):\n",
        "    zero = [0]*10\n",
        "    zero[i_] = 1\n",
        "    y_test_list.append(zero)\n",
        "\n",
        "y_train1 = np.array(y_train_list)\n",
        "y_test1 = np.array(y_test_list)\n",
        "print(y_train1.shape, y_test1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_U2eCQPKNp0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(x_train1[i][...,0], cmap='gray')\n",
        "    plt.title('Class = {}'.format(y_train[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqhgW17uKtdU"
      },
      "source": [
        "### 1.3. 모델 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6UJSQiSK1dr"
      },
      "source": [
        "#### **AI 모델을 구성하는 레이어 만들기**\n",
        "\n",
        "AI 모델은 여러 개의 레이어를 쌓아 올려 만듭니다.  \n",
        "가장 대표적인 레이어 구조인 **CONV-BN-ACT-POOL** 구조를 만들어 보겠습니다.\n",
        "\n",
        "먼저 데이터가 들어가는 첫 번째 레이어를 만들어 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9IJsyASKTTq"
      },
      "outputs": [],
      "source": [
        "first_layer = Input(shape=(32, 32, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQIZ8FEDK51O"
      },
      "source": [
        "그 다음으로 데이터의 특징을 추출할 Convolution 레이어를 연결하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ft6sLtsK859"
      },
      "outputs": [],
      "source": [
        "second_layer = layers.Conv2D(filters=8, kernel_size=(3, 3), activation=None, padding='same')(first_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vizq1nu8LGlU"
      },
      "source": [
        "다음으로 레이어 중간에서 정규화를 도와줄 Batch Normalization 레이어를 추가하겠습니다.다음으로 레이어 중간에서 정규화를 도와줄 Batch Normalization 레이어를 추가하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUmnPVdhK-oo"
      },
      "outputs": [],
      "source": [
        "third_layer = layers.BatchNormalization()(second_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjZprgalLPSn"
      },
      "source": [
        "Batch Normalization 이후 신호를 변환하여 다음 뉴런으로 전달하는 Activation function 레이어를 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idrmW7DWLMUH"
      },
      "outputs": [],
      "source": [
        "fourth_layer = layers.Activation('relu')(third_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yP4a-DALVz7"
      },
      "source": [
        "다음으로 이미지 사이즈를 줄여주는 Pooling 레이어를 연결합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ce7ptoGMLRbp"
      },
      "outputs": [],
      "source": [
        "fifth_layer = layers.MaxPool2D(strides=(2, 2))(fourth_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOPLGDOmLbl3"
      },
      "source": [
        "그 후 모든 뉴런을 일렬로 늘어세우는 Flatten 레이어를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qshjYfELY00"
      },
      "outputs": [],
      "source": [
        "sixth_layer = layers.Flatten()(fifth_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt4puhZMLi75"
      },
      "source": [
        "일렬로 늘어세운 후 이전 계층의 모든 뉴런을 연결해주는 Fully connected(Dense) 레이어를 연결합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Au2f0SaLgLw"
      },
      "outputs": [],
      "source": [
        "seventh_layer = layers.Dense(100, activation = 'relu')(sixth_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wslnvsGLtXH"
      },
      "source": [
        "Dropout 레이어를 활용해 일부 뉴런들을 무작위로 학습에서 배제하도록 합시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHlH9exdLnXE"
      },
      "outputs": [],
      "source": [
        "eighth_layer = layers.Dropout(0.25)(seventh_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKE18CBDLy3y"
      },
      "source": [
        "마지막으로 최종 결과물을 출력해주는 레이어를 만들어 줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JBcDxmpLpzF"
      },
      "outputs": [],
      "source": [
        "final_layer =  layers.Dense(10, activation='sigmoid')(eighth_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzBKkHcLL8u-"
      },
      "source": [
        "지금까지 만든 레이어를 Model 함수에 넣어 연결하면 모델이 완성됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke96nkx5L1_7"
      },
      "outputs": [],
      "source": [
        "model = Model(first_layer, final_layer)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYbBVGh7MI2k"
      },
      "source": [
        "### 1.4. 모델 훈련하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RkQLvYpMlV7"
      },
      "source": [
        "신경망 모델의 손실함수와 옵티마이저, 학습률 등의 파라미터를 지정해줍니다.\n",
        "\n",
        "성능은 정확도를 평가할 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9asGMjBL9Un"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=losses.CategoricalCrossentropy(), optimizer=optimizers.Adam(lr=1e-4), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54u7L5V0MW4D"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train1, y_train1, epochs=20, batch_size=32,\n",
        "                    validation_data=(x_test1, y_test1), shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HsNhn09NhXR"
      },
      "source": [
        "### 1.5. 결과 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB1DGNnlNZUV"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9desSnK0NmDx"
      },
      "outputs": [],
      "source": [
        "epochs = range(1,len(acc)+1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZCdmA9zN9z5"
      },
      "source": [
        "정확도와 손실함수 그래프 그리기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nksI66aLNo_d"
      },
      "outputs": [],
      "source": [
        "plt.plot(epochs, acc, c='blue', label='Training acc')\n",
        "plt.plot(epochs, val_acc, c='red', label='Validation acc')\n",
        "plt.title('Training and validation accuracy', color='w')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, c='blue', label='Training loss')\n",
        "plt.plot(epochs, val_loss, c='red', label='Validation loss')\n",
        "plt.title('Training and validation loss', color='w')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_KMswpkB-yT"
      },
      "source": [
        "* 학습 결과 추론하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFLW5MRmNtcm"
      },
      "outputs": [],
      "source": [
        "test1 = x_test1[0]\n",
        "print(test1.shape)\n",
        "plt.imshow(test1[...,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-77kUNwwCGEF"
      },
      "outputs": [],
      "source": [
        "testp = x_test1[:100]\n",
        "testg = y_test[:100]\n",
        "scores = model.predict(testp)\n",
        "\n",
        "new_scores = []\n",
        "for score in scores:\n",
        "  max_val = np.max(score)\n",
        "  prob_num = list(score).index(max_val)\n",
        "  new_scores.append(prob_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ovj6NjIwCKV7"
      },
      "outputs": [],
      "source": [
        "plt.imshow(testp[0,...,0])\n",
        "print(f'label={testg[0]}, predict={new_scores[0]}')\n",
        "print(scores[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hLPRD53-k6-"
      },
      "source": [
        "## 2. Classification: VGG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8oMRw4jCvug"
      },
      "source": [
        "### 2.1. Data Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSHZ7fLECS8D"
      },
      "outputs": [],
      "source": [
        "from skimage import morphology\n",
        "from skimage import measure\n",
        "from skimage import exposure\n",
        "from skimage import transform as skit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd7R5lv0CFmG"
      },
      "outputs": [],
      "source": [
        "x_train_list = []\n",
        "x_test_list = []\n",
        "for i, i_ in enumerate(x_train[:1000]):\n",
        "    x_train_list.append(skit.resize(i_, (32, 32))) # Simple CNN때와 달리 이번에는 resize\n",
        "for i, i_ in enumerate(x_test[:500]):\n",
        "    x_test_list.append(skit.resize(i_, (32, 32)))\n",
        "\n",
        "x_train1 = np.expand_dims(np.array(x_train_list), axis=-1)\n",
        "x_test1 = np.expand_dims(np.array(x_test_list), axis=-1)\n",
        "print(x_train1.shape, x_test1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeK3ZmvECk_V"
      },
      "outputs": [],
      "source": [
        "y_train_list = []\n",
        "y_test_list = []\n",
        "for i, i_ in enumerate(y_train[:1000]):\n",
        "    zero = [0]*10\n",
        "    zero[i_] = 1\n",
        "    y_train_list.append(zero)\n",
        "\n",
        "for i, i_ in enumerate(y_test[:500]):\n",
        "    zero = [0]*10\n",
        "    zero[i_] = 1\n",
        "    y_test_list.append(zero)\n",
        "\n",
        "y_train1 = np.array(y_train_list)\n",
        "y_test1 = np.array(y_test_list)\n",
        "print(y_train1.shape, y_test1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmggEJhEClUQ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(x_train1[i][...,0], cmap='gray')\n",
        "    plt.title('Class = {}'.format(y_train[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpIZIZzWCyqn"
      },
      "source": [
        "### 2.2. Model Build"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhHqT4dLEE4u"
      },
      "source": [
        "* 2.2.1. VGG code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMgL9poaCubZ"
      },
      "outputs": [],
      "source": [
        "def conv_block_2d(lr_conv, lr_num, par_list, bkn):\n",
        "        # parameter\n",
        "        filter_num = par_list[0]\n",
        "        conv_size = par_list[1]\n",
        "        conv_act = par_list[2]\n",
        "        pool_size = par_list[3]\n",
        "        # code\n",
        "        for i in range(lr_num):\n",
        "            lr_conv = layers.Conv2D(filter_num, conv_size, activation=None, padding='same',\n",
        "                                    kernel_initializer='he_normal',\n",
        "                                    name='block{}_conv{}'.format(bkn, i+1))(lr_conv)\n",
        "            lr_conv = layers.BatchNormalization(axis=-1, name='block{}_batchnorm{}'.format(bkn, i+1))(lr_conv)\n",
        "            lr_conv = layers.Activation(conv_act, name='block{}_activ{}'.format(bkn, i+1))(lr_conv)\n",
        "        lr_pool = layers.MaxPooling2D(pool_size=pool_size, name='block{}_pool'.format(bkn, i+1))(lr_conv)\n",
        "        return lr_pool\n",
        "\n",
        "def output_block(lr_dense, block_num, dens_count, act_func, drop_rate):\n",
        "    lr_dense = layers.Flatten(name='flatten_layer')(lr_dense)\n",
        "    for i in range(block_num):\n",
        "        lr_dense = layers.Dense(dens_count[i], kernel_regularizer=None,\n",
        "                                activation=act_func, name='classifier_dense_{}'.format(i+1))(lr_dense)\n",
        "        lr_dense = layers.Dropout(drop_rate, name='classifier_dropout_{}'.format(i+1))(lr_dense)\n",
        "    return lr_dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suOXhB3iDS8g"
      },
      "outputs": [],
      "source": [
        "def VGG16_2D(par_dic):\n",
        "    # parameters\n",
        "    input_size = par_dic['input_size']\n",
        "    conv_size = par_dic['conv_size']\n",
        "    conv_act = par_dic['conv_act']\n",
        "    pool_size = par_dic['pool_size']\n",
        "    dens_num = par_dic['dens_num']\n",
        "    dens_count = par_dic['dens_count']\n",
        "    dens_act = par_dic['dens_act']\n",
        "    drop_out = par_dic['drop_out']\n",
        "    output_count = par_dic['output_count']\n",
        "    output_act = par_dic['output_act']\n",
        "\n",
        "    # code block\n",
        "    inputs = Input(shape=(input_size, input_size, 1), name='input_layer')\n",
        "    block1 = conv_block_2d(inputs, 2, [64, conv_size, conv_act, pool_size], 1)\n",
        "    block2 = conv_block_2d(block1, 2, [128, conv_size, conv_act, pool_size], 2)\n",
        "    block3 = conv_block_2d(block2, 3, [256, conv_size, conv_act, pool_size], 3)\n",
        "    block4 = conv_block_2d(block3, 3, [512, conv_size, conv_act, pool_size], 4)\n",
        "    block5 = conv_block_2d(block4, 3, [512, conv_size, conv_act, pool_size], 5)\n",
        "    dens = output_block(block5, dens_num, dens_count, dens_act, drop_out)\n",
        "    outputs = layers.Dense(output_count, activation=output_act, name='output_layer')(dens)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYHQhdfwDCH5"
      },
      "outputs": [],
      "source": [
        "def VGG19_2D(par_dic):\n",
        "    # parameters\n",
        "    input_size = par_dic['input_size']\n",
        "    conv_size = par_dic['conv_size']\n",
        "    conv_act = par_dic['conv_act']\n",
        "    pool_size = par_dic['pool_size']\n",
        "    dens_num = par_dic['dens_num']\n",
        "    dens_count = par_dic['dens_count']\n",
        "    dens_act = par_dic['dens_act']\n",
        "    drop_out = par_dic['drop_out']\n",
        "    output_count = par_dic['output_count']\n",
        "    output_act = par_dic['output_act']\n",
        "\n",
        "    # code block\n",
        "    inputs = Input(shape=(input_size, input_size, 1))\n",
        "    block1 = conv_block_2d(inputs, 2, [64, conv_size, conv_act, pool_size], 1)\n",
        "    block2 = conv_block_2d(block1, 2, [128, conv_size, conv_act, pool_size], 2)\n",
        "    block3 = conv_block_2d(block2, 4, [256, conv_size, conv_act, pool_size], 3)\n",
        "    block4 = conv_block_2d(block3, 4, [512, conv_size, conv_act, pool_size], 4)\n",
        "    block5 = conv_block_2d(block4, 4, [512, conv_size, conv_act, pool_size], 5)\n",
        "    dens = output_block(block5, dens_num, dens_count, dens_act, drop_out)\n",
        "    outputs = layers.Dense(output_count, activation=output_act)(dens)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJJrsVXFELCF"
      },
      "source": [
        "* 2.2.2 VGG Build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBH0JyXGDSMg"
      },
      "outputs": [],
      "source": [
        "network_param_2d = {'input_size': 32,\n",
        "                     'conv_size': 3,\n",
        "                     'conv_act': 'relu',\n",
        "                     'pool_size': 2,\n",
        "                     'dens_num': 2,\n",
        "                     'dens_count': [1000,500],\n",
        "                     'dens_act': 'relu',\n",
        "                     'drop_out': 0.5,\n",
        "                     'output_count': 10,\n",
        "                     'output_act': 'softmax'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqHmqfgTD-Oz"
      },
      "outputs": [],
      "source": [
        "model = VGG16_2D(network_param_2d)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WsHElLPEBfO"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=losses.CategoricalCrossentropy(), optimizer=optimizers.Adam(learning_rate=1e-4), metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKhnowo1EZtx"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train1, y_train1, epochs=20, batch_size=32,\n",
        "                    validation_data=(x_test1, y_test1), shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tet0PzxmFU_U"
      },
      "source": [
        "### 2.3. Model Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vfxwSafEsu_"
      },
      "outputs": [],
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "# Accuracy graph\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(epochs, acc, 'b', label='Training acc = {}%'.format(np.around(np.max(acc) * 100, decimals=1)))\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc = {}%'.format(np.around(np.max(val_acc) * 100, decimals=1)))\n",
        "plt.title('{} Accuracy (Total Epoch = {})'.format('VGG16', len(acc)), fontsize=15, y=1.02)\n",
        "plt.xticks(size=15)\n",
        "plt.yticks(size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()\n",
        "# Loss graph\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(epochs, loss, 'b', label='Training loss = {}'.format(np.around(np.min(loss), decimals=3)))\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss= {}'.format(np.around(np.min(val_loss), decimals=3)))\n",
        "plt.title('{} Loss (Total Epoch = {})'.format('VGG16', len(loss)), fontsize=15, y=1.02)\n",
        "plt.xticks(size=15)\n",
        "plt.yticks(size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsKsB1J5FQIW"
      },
      "source": [
        "### 2.4. Model Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iURQXorTE3Nd"
      },
      "outputs": [],
      "source": [
        "test1 = x_test1[0]\n",
        "print(test1.shape)\n",
        "plt.imshow(test1[...,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPRNaZHAE5Ja"
      },
      "outputs": [],
      "source": [
        "testp = x_test1[:100]\n",
        "testg = y_test[:100]\n",
        "scores = model.predict(testp)\n",
        "\n",
        "new_scores = []\n",
        "for score in scores:\n",
        "  max_val = np.max(score)\n",
        "  prob_num = list(score).index(max_val)\n",
        "  new_scores.append(prob_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LD2oneiE53X"
      },
      "outputs": [],
      "source": [
        "plt.imshow(testp[0,...,0])\n",
        "print(f'label={testg[0]}, predict={new_scores[0]}')\n",
        "print(scores[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv2nkq6lFl5w"
      },
      "source": [
        "## 3. Segmentation: Simple FCN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 영상처리 관련 라이브러리 불러오기\n",
        "import skimage\n",
        "from skimage import io as skio\n",
        "from skimage import transform as skit\n",
        "from skimage import morphology as skim"
      ],
      "metadata": {
        "id": "1wt4LhFb49Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. Data Loading"
      ],
      "metadata": {
        "id": "W8xZs4JAsOT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Dataset Download\n",
        "  - reference link: https://www.kaggle.com/datasets/nikhilroxtomar/brain-tumor-segmentation"
      ],
      "metadata": {
        "id": "Btz6RNQ0sTzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋을 이 세션으로 불러오기\n",
        "!git clone https://github.com/Pulsar-kkaturi/DL-Education.git"
      ],
      "metadata": {
        "id": "lGublw8TsIF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 압축 풀기\n",
        "!tar -zxf ./DL-Education/dataset/brain_seg_2d.tar.gz"
      ],
      "metadata": {
        "id": "YBqqF0tk4jE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터 경로 지정"
      ],
      "metadata": {
        "id": "lVRyvtUgshTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_fol_path = './brain_seg_2d/images'\n",
        "msk_fol_path = './brain_seg_2d/masks'\n",
        "img_file_list = [f for f in sorted(os.listdir(img_fol_path))]\n",
        "msk_file_list = [f for f in sorted(os.listdir(msk_fol_path))]\n",
        "# print(img_file_list)\n",
        "# print(msk_file_list)\n",
        "\n",
        "img_list, msk_list = [], []\n",
        "for i, i_ in enumerate(img_file_list):\n",
        "  img_path = os.path.join(img_fol_path, i_)\n",
        "  msk_path = os.path.join(msk_fol_path, msk_file_list[i])\n",
        "  img_arr = skio.imread(img_path)\n",
        "  msk_arr = skio.imread(msk_path)\n",
        "  img_list.append(img_arr)\n",
        "  msk_list.append(msk_arr)\n",
        "\n",
        "print('Image numbers = ', len(img_list))\n",
        "print('Mask numbers = ', len(msk_list))"
      ],
      "metadata": {
        "id": "K8rY5b3O5DuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이미지 확인 & 레이블 확인"
      ],
      "metadata": {
        "id": "UHz4IX2GtDAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 정보\n",
        "print('이미지 크기 = ', img_list[0].shape)\n",
        "print(f'이미지 최대값/최소값 = {np.max(img_list[0])}/{np.min(img_list[0])}')\n",
        "# 마스크 정보\n",
        "print('마스크 크기 = ', msk_list[0].shape)\n",
        "print(f'마스크 최대값/최소값 = {np.max(msk_list[0])}/{np.min(msk_list[0])}')"
      ],
      "metadata": {
        "id": "qXmQQdSN8n7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(131)\n",
        "plt.title('Image')\n",
        "plt.imshow(img_list[0])\n",
        "plt.subplot(132)\n",
        "plt.title('Mask')\n",
        "plt.imshow(msk_list[0])\n",
        "plt.subplot(133)\n",
        "plt.title('Overlay')\n",
        "plt.imshow(img_list[0], cmap='gray')\n",
        "plt.imshow(msk_list[0], cmap='Reds', alpha=0.3)\n"
      ],
      "metadata": {
        "id": "79Ua_TEhssDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. Dataset Pre-processing"
      ],
      "metadata": {
        "id": "IjZb4e8-tPG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.1. Original Mask"
      ],
      "metadata": {
        "id": "WX_b9DbRyfKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (200, 200) # 이미지 사이즈 정규화\n",
        "num_classes = 1 # 레이블 종류 (tumor 1개)\n",
        "\n",
        "# 이미지 전처리\n",
        "resized_imgs = [skit.resize(img, img_size, anti_aliasing=True) for img in img_list] # 이미지 크기 리사이징\n",
        "img_arrays = np.expand_dims(np.array(resized_imgs, dtype=np.float32), axis=-1) # 이미지를 array로 변환\n",
        "input_imgs = (img_arrays - np.min(img_arrays))/(np.max(img_arrays)-np.min(img_arrays)) # 이미지 정규화 (0~1)\n",
        "\n",
        "# 마스크 전처리\n",
        "resized_msks = [skit.resize(msk, img_size) for msk in msk_list] # 이미지 크기 리사이징\n",
        "msk_arrays = np.expand_dims(np.array(resized_msks), axis=-1) # 마스크를 array로 변환\n",
        "targets = np.where(msk_arrays > 0, 1, 0) # 레이블 형태(0,1)로 변환\n",
        "targets = targets.astype(np.uint8)\n",
        "\n",
        "# 이미지 정보\n",
        "print('입력 어레이 크기 = ', input_imgs.shape)\n",
        "print(f'입력 어레이 최대값/최소값 = {np.max(input_imgs)}/{np.min(input_imgs)}')\n",
        "# 마스크 정보\n",
        "print('타겟 어레이 크기 = ', targets.shape)\n",
        "print(f'타켓 어레이 최대값/최소값 = {np.max(targets)}/{np.min(targets)}')"
      ],
      "metadata": {
        "id": "0lcsdXvntJVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 데이터셋 분할\n",
        "num_val_samples = 100 # 검증 데이터셋에는 100건 사용\n",
        "train_input_imgs = input_imgs[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_input_imgs = input_imgs[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]\n",
        "\n",
        "# 검증 데이터셋 확인\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(131)\n",
        "plt.title('Image')\n",
        "plt.imshow(val_input_imgs[0])\n",
        "plt.subplot(132)\n",
        "plt.title('Mask')\n",
        "plt.imshow(val_targets[0])\n",
        "plt.subplot(133)\n",
        "plt.title('Overlay')\n",
        "plt.imshow(val_input_imgs[0], cmap='gray')\n",
        "plt.imshow(val_targets[0], cmap='Reds', alpha=0.3)"
      ],
      "metadata": {
        "id": "09n0xvi79z5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.2. New Mask\n",
        "* FCN에서 Brain Tumor는 생각보다 어려울 것이므로, 그냥 두경부 전체를 분할하는 것으로 목표를 바꾸자!\n",
        "* 3.2.1과 3.2.2 둘 중 하나만 실행시킨 뒤 모델학습(3.3)으로 넘어가서 성능을 비교해보자!"
      ],
      "metadata": {
        "id": "wpqxtne2ywbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (200, 200) # 이미지 사이즈 정규화\n",
        "num_classes = 1 # 레이블 종류 (tumor 1개)\n",
        "\n",
        "# 이미지 전처리\n",
        "resized_imgs = [skit.resize(img, img_size, anti_aliasing=True) for img in img_list] # 이미지 크기 리사이징\n",
        "img_arrays = np.expand_dims(np.array(resized_imgs, dtype=np.float32), axis=-1) # 이미지를 array로 변환\n",
        "input_imgs = (img_arrays - np.min(img_arrays))/(np.max(img_arrays)-np.min(img_arrays)) # 이미지 정규화 (0~1)\n",
        "\n",
        "# 마스크 전처리\n",
        "new_msk_list = [skim.closing(np.where(img > 20,  1, 0)) for img in img_list] # 레이블 형태(0,1)로 변환\n",
        "resized_msks = [skit.resize(msk, img_size) for msk in new_msk_list] # 이미지 크기 리사이징\n",
        "msk_arrays = np.expand_dims(np.array(resized_msks), axis=-1) # 마스크를 array로 변환\n",
        "targets = np.where(msk_arrays > 0, 1, 0) # 레이블 형태(0,1)로 변환\n",
        "\n",
        "targets = targets.astype(np.uint8)\n",
        "\n",
        "# 이미지 정보\n",
        "print('입력 어레이 크기 = ', input_imgs.shape)\n",
        "print(f'입력 어레이 최대값/최소값 = {np.max(input_imgs)}/{np.min(input_imgs)}')\n",
        "# 마스크 정보\n",
        "print('타겟 어레이 크기 = ', targets.shape)\n",
        "print(f'타켓 어레이 최대값/최소값 = {np.max(targets)}/{np.min(targets)}')"
      ],
      "metadata": {
        "id": "DkNejU-hy77d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 데이터셋 분할\n",
        "num_val_samples = 100 # 검증 데이터셋에는 100건 사용\n",
        "train_input_imgs = input_imgs[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_input_imgs = input_imgs[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]\n",
        "\n",
        "# 검증 데이터셋 확인\n",
        "plt.figure(figsize=(12,12))\n",
        "for i in range(3):\n",
        "  plt.subplot(3,3,1+3*i)\n",
        "  plt.title('Image')\n",
        "  plt.imshow(val_input_imgs[i])\n",
        "  plt.subplot(3,3,2+3*i)\n",
        "  plt.title('Mask')\n",
        "  plt.imshow(val_targets[i])\n",
        "  plt.subplot(3,3,3+3*i)\n",
        "  plt.title('Overlay')\n",
        "  plt.imshow(val_input_imgs[i], cmap='gray')\n",
        "  plt.imshow(val_targets[i], cmap='Reds', alpha=0.3)"
      ],
      "metadata": {
        "id": "GX0UkF1hzn7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Model Build"
      ],
      "metadata": {
        "id": "xapLt9QFuHn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=img_size + (1,))\n",
        "\n",
        "    # encoder\n",
        "    x = layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\")(inputs) # Padding 영향 제거 ('same')\n",
        "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(256, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "\n",
        "    # decoder\n",
        "    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"sigmoid\", padding=\"same\")(x) # 최종 클래스 1개\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = get_model(img_size=img_size, num_classes=num_classes)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "sz9ITnxct5dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 컴파일\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['acc'])"
      ],
      "metadata": {
        "id": "inJnMOGvDWdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4. Model Training"
      ],
      "metadata": {
        "id": "qFta5bREvcG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"brain_seg_weights.h5\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(train_input_imgs, train_targets,\n",
        "                    epochs=20,\n",
        "                    callbacks=callbacks,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(val_input_imgs, val_targets))"
      ],
      "metadata": {
        "id": "DoGFCYCivbF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4. Model Evaluate"
      ],
      "metadata": {
        "id": "-cK8HUOnxMuZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 학습 결과 확인"
      ],
      "metadata": {
        "id": "z8B8nb-5xTRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(1, len(history.history[\"loss\"]) + 1)\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "acc = history.history[\"acc\"]\n",
        "val_acc = history.history[\"val_acc\"]\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(121)\n",
        "plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.subplot(122)\n",
        "plt.plot(epochs, acc, \"b\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"r\", label=\"Validation acc\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "zfoCeCbDxP69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 테스트 데이터"
      ],
      "metadata": {
        "id": "XoVSSXH2xVww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 불러오기\n",
        "model = keras.models.load_model(\"brain_seg_weights.h5\")\n",
        "\n",
        "# Test data predict\n",
        "i = 0 # data index\n",
        "test_image = val_input_imgs[i]\n",
        "test_mask = val_targets[i]\n",
        "res_mask = model.predict(np.expand_dims(test_image, 0))[0]"
      ],
      "metadata": {
        "id": "WXevkhJXFAZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thres = 0.1 # threshold\n",
        "fin_mask = np.where(res_mask > thres, 1, 0)\n",
        "\n",
        "# result show\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(131)\n",
        "plt.title('Label')\n",
        "plt.imshow(test_image, cmap='gray')\n",
        "plt.imshow(test_mask, cmap='Reds', alpha=0.3)\n",
        "plt.subplot(132)\n",
        "plt.title('Prediction')\n",
        "plt.imshow(test_image, cmap='gray')\n",
        "plt.imshow(fin_mask, cmap='Blues', alpha=0.3)\n",
        "plt.subplot(133)\n",
        "plt.title('Comparsion')\n",
        "plt.imshow(test_mask + fin_mask)\n"
      ],
      "metadata": {
        "id": "zEccVBmtFF9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "수고하셨습니다!"
      ],
      "metadata": {
        "id": "ypdTMG09NA47"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lecture1_CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}