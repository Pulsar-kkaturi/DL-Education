{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pulsar-kkaturi/DL-Education/blob/master/VisionDL_Lecture/Lecture4_CNNBuild_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDCIqpTnJeqZ"
      },
      "source": [
        "# Lecture 3. CNN Build"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTaaZF3HJs40"
      },
      "source": [
        "## 1. Simple CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwbSpz2l8v7_"
      },
      "source": [
        "### 1.1. Library Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIIvdH4_JbR2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os, matplotlib, random\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "### Tensorflow 2.0 ###\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5JgCVTgBH9s"
      },
      "outputs": [],
      "source": [
        "mport tensorflow as tf\n",
        "tf.config.list_physical_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSc3RZmiKDUv"
      },
      "source": [
        "### 1.2. 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6Z_blzwKB16"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test)= tf.keras.datasets.mnist.load_data(path='minist.npz')\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FLSAWYcKIjl"
      },
      "outputs": [],
      "source": [
        "x_train_list = []\n",
        "x_test_list = []\n",
        "for i, i_ in enumerate(x_train[:1000]):\n",
        "    arr = np.zeros(shape=(32, 32))\n",
        "    arr[:28,:28] = x_train[i]\n",
        "    x_train_list.append(arr)\n",
        "for i, i_ in enumerate(x_test[:500]):\n",
        "    arr = np.zeros(shape=(32, 32))\n",
        "    arr[:28,:28] = x_test[i]\n",
        "    x_test_list.append(arr)\n",
        "\n",
        "x_train1 = np.expand_dims(np.array(x_train_list), axis=-1)\n",
        "x_test1 = np.expand_dims(np.array(x_test_list), axis=-1)\n",
        "print(x_train1.shape, x_test1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xvzy72PlM64n"
      },
      "outputs": [],
      "source": [
        "y_train_list = []\n",
        "y_test_list = []\n",
        "for i, i_ in enumerate(y_train[:1000]):\n",
        "    zero = [0]*10\n",
        "    zero[i_] = 1\n",
        "    y_train_list.append(zero)\n",
        "\n",
        "for i, i_ in enumerate(y_test[:500]):\n",
        "    zero = [0]*10\n",
        "    zero[i_] = 1\n",
        "    y_test_list.append(zero)\n",
        "\n",
        "y_train1 = np.array(y_train_list)\n",
        "y_test1 = np.array(y_test_list)\n",
        "print(y_train1.shape, y_test1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_U2eCQPKNp0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(x_train1[i][...,0], cmap='gray')\n",
        "    plt.title('Class = {}'.format(y_train[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqhgW17uKtdU"
      },
      "source": [
        "### 1.3. 모델 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6UJSQiSK1dr"
      },
      "source": [
        "#### **AI 모델을 구성하는 레이어 만들기**\n",
        "\n",
        "AI 모델은 여러 개의 레이어를 쌓아 올려 만듭니다.  \n",
        "가장 대표적인 레이어 구조인 **CONV-BN-ACT-POOL** 구조를 만들어 보겠습니다.\n",
        "\n",
        "먼저 데이터가 들어가는 첫 번째 레이어를 만들어 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9IJsyASKTTq"
      },
      "outputs": [],
      "source": [
        "first_layer = Input(shape=(32, 32, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQIZ8FEDK51O"
      },
      "source": [
        "그 다음으로 데이터의 특징을 추출할 Convolution 레이어를 연결하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ft6sLtsK859"
      },
      "outputs": [],
      "source": [
        "second_layer = layers.Conv2D(filters=8, kernel_size=(3, 3), activation=None, padding='same')(first_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vizq1nu8LGlU"
      },
      "source": [
        "다음으로 레이어 중간에서 정규화를 도와줄 Batch Normalization 레이어를 추가하겠습니다.다음으로 레이어 중간에서 정규화를 도와줄 Batch Normalization 레이어를 추가하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUmnPVdhK-oo"
      },
      "outputs": [],
      "source": [
        "third_layer = layers.BatchNormalization()(second_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjZprgalLPSn"
      },
      "source": [
        "Batch Normalization 이후 신호를 변환하여 다음 뉴런으로 전달하는 Activation function 레이어를 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idrmW7DWLMUH"
      },
      "outputs": [],
      "source": [
        "fourth_layer = layers.Activation('relu')(third_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yP4a-DALVz7"
      },
      "source": [
        "다음으로 이미지 사이즈를 줄여주는 Pooling 레이어를 연결합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ce7ptoGMLRbp"
      },
      "outputs": [],
      "source": [
        "fifth_layer = layers.MaxPool2D(strides=(2, 2))(fourth_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOPLGDOmLbl3"
      },
      "source": [
        "그 후 모든 뉴런을 일렬로 늘어세우는 Flatten 레이어를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qshjYfELY00"
      },
      "outputs": [],
      "source": [
        "sixth_layer = layers.Flatten()(fifth_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt4puhZMLi75"
      },
      "source": [
        "일렬로 늘어세운 후 이전 계층의 모든 뉴런을 연결해주는 Fully connected(Dense) 레이어를 연결합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Au2f0SaLgLw"
      },
      "outputs": [],
      "source": [
        "seventh_layer = layers.Dense(100, activation = 'relu')(sixth_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wslnvsGLtXH"
      },
      "source": [
        "Dropout 레이어를 활용해 일부 뉴런들을 무작위로 학습에서 배제하도록 합시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHlH9exdLnXE"
      },
      "outputs": [],
      "source": [
        "eighth_layer = layers.Dropout(0.25)(seventh_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKE18CBDLy3y"
      },
      "source": [
        "마지막으로 최종 결과물을 출력해주는 레이어를 만들어 줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JBcDxmpLpzF"
      },
      "outputs": [],
      "source": [
        "final_layer =  layers.Dense(10, activation='sigmoid')(eighth_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzBKkHcLL8u-"
      },
      "source": [
        "지금까지 만든 레이어를 Model 함수에 넣어 연결하면 모델이 완성됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke96nkx5L1_7"
      },
      "outputs": [],
      "source": [
        "model = Model(first_layer, final_layer)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYbBVGh7MI2k"
      },
      "source": [
        "### 1.4. 모델 훈련하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RkQLvYpMlV7"
      },
      "source": [
        "신경망 모델의 손실함수와 옵티마이저, 학습률 등의 파라미터를 지정해줍니다.\n",
        "\n",
        "성능은 정확도를 평가할 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9asGMjBL9Un"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=losses.CategoricalCrossentropy(), optimizer=optimizers.Adam(lr=1e-4), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54u7L5V0MW4D"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train1, y_train1, epochs=20, batch_size=32,\n",
        "                    validation_data=(x_test1, y_test1), shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HsNhn09NhXR"
      },
      "source": [
        "### 1.5. 결과 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB1DGNnlNZUV"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9desSnK0NmDx"
      },
      "outputs": [],
      "source": [
        "epochs = range(1,len(acc)+1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZCdmA9zN9z5"
      },
      "source": [
        "정확도와 손실함수 그래프 그리기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nksI66aLNo_d"
      },
      "outputs": [],
      "source": [
        "plt.plot(epochs, acc, c='blue', label='Training acc')\n",
        "plt.plot(epochs, val_acc, c='red', label='Validation acc')\n",
        "plt.title('Training and validation accuracy', color='w')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, c='blue', label='Training loss')\n",
        "plt.plot(epochs, val_loss, c='red', label='Validation loss')\n",
        "plt.title('Training and validation loss', color='w')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_KMswpkB-yT"
      },
      "source": [
        "* 학습 결과 추론하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFLW5MRmNtcm"
      },
      "outputs": [],
      "source": [
        "test1 = x_test1[0]\n",
        "print(test1.shape)\n",
        "plt.imshow(test1[...,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-77kUNwwCGEF"
      },
      "outputs": [],
      "source": [
        "testp = x_test1[:100]\n",
        "testg = y_test[:100]\n",
        "scores = model.predict(testp)\n",
        "\n",
        "new_scores = []\n",
        "for score in scores:\n",
        "  max_val = np.max(score)\n",
        "  prob_num = list(score).index(max_val)\n",
        "  new_scores.append(prob_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ovj6NjIwCKV7"
      },
      "outputs": [],
      "source": [
        "plt.imshow(testp[0,...,0])\n",
        "print(f'label={testg[0]}, predict={new_scores[0]}')\n",
        "print(scores[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hLPRD53-k6-"
      },
      "source": [
        "## 2. VGG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8oMRw4jCvug"
      },
      "source": [
        "### 2.1. Data Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSHZ7fLECS8D"
      },
      "outputs": [],
      "source": [
        "from skimage import morphology\n",
        "from skimage import measure\n",
        "from skimage import exposure\n",
        "from skimage import transform as skit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd7R5lv0CFmG"
      },
      "outputs": [],
      "source": [
        "x_train_list = []\n",
        "x_test_list = []\n",
        "for i, i_ in enumerate(x_train[:1000]):\n",
        "    x_train_list.append(skit.resize(i_, (32, 32)))\n",
        "for i, i_ in enumerate(x_test[:500]):\n",
        "    x_test_list.append(skit.resize(i_, (32, 32)))\n",
        "\n",
        "x_train1 = np.expand_dims(np.array(x_train_list), axis=-1)\n",
        "x_test1 = np.expand_dims(np.array(x_test_list), axis=-1)\n",
        "print(x_train1.shape, x_test1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeK3ZmvECk_V"
      },
      "outputs": [],
      "source": [
        "y_train_list = []\n",
        "y_test_list = []\n",
        "for i, i_ in enumerate(y_train[:1000]):\n",
        "    zero = [0]*10\n",
        "    zero[i_] = 1\n",
        "    y_train_list.append(zero)\n",
        "\n",
        "for i, i_ in enumerate(y_test[:500]):\n",
        "    zero = [0]*10\n",
        "    zero[i_] = 1\n",
        "    y_test_list.append(zero)\n",
        "\n",
        "y_train1 = np.array(y_train_list)\n",
        "y_test1 = np.array(y_test_list)\n",
        "print(y_train1.shape, y_test1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmggEJhEClUQ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(x_train1[i][...,0], cmap='gray')\n",
        "    plt.title('Class = {}'.format(y_train[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpIZIZzWCyqn"
      },
      "source": [
        "### 2.2. Model Build"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhHqT4dLEE4u"
      },
      "source": [
        "* 2.2.1. VGG code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMgL9poaCubZ"
      },
      "outputs": [],
      "source": [
        "def conv_block_2d(lr_conv, lr_num, par_list, bkn):\n",
        "        # parameter\n",
        "        filter_num = par_list[0]\n",
        "        conv_size = par_list[1]\n",
        "        conv_act = par_list[2]\n",
        "        pool_size = par_list[3]\n",
        "        # code\n",
        "        for i in range(lr_num):\n",
        "            lr_conv = layers.Conv2D(filter_num, conv_size, activation=None, padding='same',\n",
        "                                    kernel_initializer='he_normal',\n",
        "                                    name='block{}_conv{}'.format(bkn, i+1))(lr_conv)\n",
        "            lr_conv = layers.BatchNormalization(axis=-1, name='block{}_batchnorm{}'.format(bkn, i+1))(lr_conv)\n",
        "            lr_conv = layers.Activation(conv_act, name='block{}_activ{}'.format(bkn, i+1))(lr_conv)\n",
        "        lr_pool = layers.MaxPooling2D(pool_size=pool_size, name='block{}_pool'.format(bkn, i+1))(lr_conv)\n",
        "        return lr_pool\n",
        "\n",
        "def output_block(lr_dense, block_num, dens_count, act_func, drop_rate):\n",
        "    lr_dense = layers.Flatten(name='flatten_layer')(lr_dense)\n",
        "    for i in range(block_num):\n",
        "        lr_dense = layers.Dense(dens_count[i], kernel_regularizer=None,\n",
        "                                activation=act_func, name='classifier_dense_{}'.format(i+1))(lr_dense)\n",
        "        lr_dense = layers.Dropout(drop_rate, name='classifier_dropout_{}'.format(i+1))(lr_dense)\n",
        "    return lr_dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suOXhB3iDS8g"
      },
      "outputs": [],
      "source": [
        "def VGG16_2D(par_dic):\n",
        "    # parameters\n",
        "    input_size = par_dic['input_size']\n",
        "    conv_size = par_dic['conv_size']\n",
        "    conv_act = par_dic['conv_act']\n",
        "    pool_size = par_dic['pool_size']\n",
        "    dens_num = par_dic['dens_num']\n",
        "    dens_count = par_dic['dens_count']\n",
        "    dens_act = par_dic['dens_act']\n",
        "    drop_out = par_dic['drop_out']\n",
        "    output_count = par_dic['output_count']\n",
        "    output_act = par_dic['output_act']\n",
        "\n",
        "    # code block\n",
        "    inputs = Input(shape=(input_size, input_size, 1), name='input_layer')\n",
        "    block1 = conv_block_2d(inputs, 2, [64, conv_size, conv_act, pool_size], 1)\n",
        "    block2 = conv_block_2d(block1, 2, [128, conv_size, conv_act, pool_size], 2)\n",
        "    block3 = conv_block_2d(block2, 3, [256, conv_size, conv_act, pool_size], 3)\n",
        "    block4 = conv_block_2d(block3, 3, [512, conv_size, conv_act, pool_size], 4)\n",
        "    block5 = conv_block_2d(block4, 3, [512, conv_size, conv_act, pool_size], 5)\n",
        "    dens = output_block(block5, dens_num, dens_count, dens_act, drop_out)\n",
        "    outputs = layers.Dense(output_count, activation=output_act, name='output_layer')(dens)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYHQhdfwDCH5"
      },
      "outputs": [],
      "source": [
        "def VGG19_2D(par_dic):\n",
        "    # parameters\n",
        "    input_size = par_dic['input_size']\n",
        "    conv_size = par_dic['conv_size']\n",
        "    conv_act = par_dic['conv_act']\n",
        "    pool_size = par_dic['pool_size']\n",
        "    dens_num = par_dic['dens_num']\n",
        "    dens_count = par_dic['dens_count']\n",
        "    dens_act = par_dic['dens_act']\n",
        "    drop_out = par_dic['drop_out']\n",
        "    output_count = par_dic['output_count']\n",
        "    output_act = par_dic['output_act']\n",
        "\n",
        "    # code block\n",
        "    inputs = Input(shape=(input_size, input_size, 1))\n",
        "    block1 = conv_block_2d(inputs, 2, [64, conv_size, conv_act, pool_size], 1)\n",
        "    block2 = conv_block_2d(block1, 2, [128, conv_size, conv_act, pool_size], 2)\n",
        "    block3 = conv_block_2d(block2, 4, [256, conv_size, conv_act, pool_size], 3)\n",
        "    block4 = conv_block_2d(block3, 4, [512, conv_size, conv_act, pool_size], 4)\n",
        "    block5 = conv_block_2d(block4, 4, [512, conv_size, conv_act, pool_size], 5)\n",
        "    dens = output_block(block5, dens_num, dens_count, dens_act, drop_out)\n",
        "    outputs = layers.Dense(output_count, activation=output_act)(dens)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJJrsVXFELCF"
      },
      "source": [
        "* 2.2.2 VGG Build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBH0JyXGDSMg"
      },
      "outputs": [],
      "source": [
        "network_param_2d = {'input_size': 32,\n",
        "                     'conv_size': 3,\n",
        "                     'conv_act': 'relu',\n",
        "                     'pool_size': 2,\n",
        "                     'dens_num': 2,\n",
        "                     'dens_count': [1000,500],\n",
        "                     'dens_act': 'relu',\n",
        "                     'drop_out': 0.5,\n",
        "                     'output_count': 10,\n",
        "                     'output_act': 'softmax'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqHmqfgTD-Oz"
      },
      "outputs": [],
      "source": [
        "model = VGG16_2D(network_param_2d)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WsHElLPEBfO"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=losses.CategoricalCrossentropy(), optimizer=optimizers.Adam(learning_rate=1e-4), metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKhnowo1EZtx"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train1, y_train1, epochs=20, batch_size=32,\n",
        "                    validation_data=(x_test1, y_test1), shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tet0PzxmFU_U"
      },
      "source": [
        "### 2.3. Model Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vfxwSafEsu_"
      },
      "outputs": [],
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "# Accuracy graph\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(epochs, acc, 'b', label='Training acc = {}%'.format(np.around(np.max(acc) * 100, decimals=1)))\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc = {}%'.format(np.around(np.max(val_acc) * 100, decimals=1)))\n",
        "plt.title('{} Accuracy (Total Epoch = {})'.format('VGG16', len(acc)), fontsize=15, y=1.02)\n",
        "plt.xticks(size=15)\n",
        "plt.yticks(size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()\n",
        "# Loss graph\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(epochs, loss, 'b', label='Training loss = {}'.format(np.around(np.min(loss), decimals=3)))\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss= {}'.format(np.around(np.min(val_loss), decimals=3)))\n",
        "plt.title('{} Loss (Total Epoch = {})'.format('VGG16', len(loss)), fontsize=15, y=1.02)\n",
        "plt.xticks(size=15)\n",
        "plt.yticks(size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsKsB1J5FQIW"
      },
      "source": [
        "### 2.4. Model Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iURQXorTE3Nd"
      },
      "outputs": [],
      "source": [
        "test1 = x_test1[0]\n",
        "print(test1.shape)\n",
        "plt.imshow(test1[...,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPRNaZHAE5Ja"
      },
      "outputs": [],
      "source": [
        "testp = x_test1[:100]\n",
        "testg = y_test[:100]\n",
        "scores = model.predict(testp)\n",
        "\n",
        "new_scores = []\n",
        "for score in scores:\n",
        "  max_val = np.max(score)\n",
        "  prob_num = list(score).index(max_val)\n",
        "  new_scores.append(prob_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LD2oneiE53X"
      },
      "outputs": [],
      "source": [
        "plt.imshow(testp[0,...,0])\n",
        "print(f'label={testg[0]}, predict={new_scores[0]}')\n",
        "print(scores[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv2nkq6lFl5w"
      },
      "source": [
        "## 3. Segmentation: Simple FCN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. Data Loading"
      ],
      "metadata": {
        "id": "W8xZs4JAsOT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Dataset Download"
      ],
      "metadata": {
        "id": "Btz6RNQ0sTzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
        "!tar -xf images.tar.gz\n",
        "!tar -xf annotations.tar.gz"
      ],
      "metadata": {
        "id": "lGublw8TsIF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터 경로 지정"
      ],
      "metadata": {
        "id": "lVRyvtUgshTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = \"images/\"\n",
        "target_dir = \"annotations/trimaps/\"\n",
        "\n",
        "input_img_paths = sorted(\n",
        "    [os.path.join(input_dir, fname)\n",
        "     for fname in os.listdir(input_dir)\n",
        "     if fname.endswith(\".jpg\")])\n",
        "target_paths = sorted(\n",
        "    [os.path.join(target_dir, fname)\n",
        "     for fname in os.listdir(target_dir)\n",
        "     if fname.endswith(\".png\") and not fname.startswith(\".\")])\n",
        "\n",
        "print(len(input_img_paths), input_img_paths)\n",
        "print(len(target_paths), target_paths)"
      ],
      "metadata": {
        "id": "Dt1HpEdgseL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이미지 확인"
      ],
      "metadata": {
        "id": "UHz4IX2GtDAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(load_img(input_img_paths[9]))"
      ],
      "metadata": {
        "id": "79Ua_TEhssDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 레이블 확인\n",
        "  * 1(전경), 2(배경), 3(윤곽)"
      ],
      "metadata": {
        "id": "kNadvPqEtG_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_target(target_array):\n",
        "    normalized_array = (target_array.astype(\"uint8\") - 1) * 127 # label 값은 1,2,3 -> 0,1,2\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(normalized_array[:, :, 0])\n",
        "\n",
        "img = img_to_array(load_img(target_paths[9], color_mode=\"grayscale\"))\n",
        "display_target(img)"
      ],
      "metadata": {
        "id": "ZVb8d3Tws_cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. Dataset Pre-processing"
      ],
      "metadata": {
        "id": "IjZb4e8-tPG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (200, 200) # 이미지 사이즈 정규화\n",
        "num_imgs = len(input_img_paths)\n",
        "\n",
        "# 데이터 셔플링\n",
        "random.Random(1337).shuffle(input_img_paths) # 이미지 셔플링\n",
        "random.Random(1337).shuffle(target_paths) # 타겟 셔플링\n",
        "\n",
        "# 이미지를 array로 변환\n",
        "def path_to_input_image(path):\n",
        "    return img_to_array(load_img(path, target_size=img_size))\n",
        "\n",
        "# 레이블 이미지를 마스크(1, 0) 이미지로 변환\n",
        "def path_to_target(path):\n",
        "    img = img_to_array(\n",
        "        load_img(path, target_size=img_size, color_mode=\"grayscale\"))\n",
        "    img = img.astype(\"uint8\") - 1\n",
        "    return img\n",
        "\n",
        "input_imgs = np.zeros((num_imgs,) + img_size + (3,), dtype=\"float32\") # 이미지는 RBG 3채널\n",
        "targets = np.zeros((num_imgs,) + img_size + (1,), dtype=\"uint8\")\n",
        "for i in range(num_imgs):\n",
        "    input_imgs[i] = path_to_input_image(input_img_paths[i])\n",
        "    targets[i] = path_to_target(target_paths[i])\n",
        "\n",
        "# 검증 데이터셋 분할\n",
        "num_val_samples = 1000 # 검증 데이터셋에는 1000건 사용\n",
        "train_input_imgs = input_imgs[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_input_imgs = input_imgs[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]"
      ],
      "metadata": {
        "id": "0lcsdXvntJVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Model Build"
      ],
      "metadata": {
        "id": "xapLt9QFuHn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(img_size, num_classes):\n",
        "    inputs = keras.Input(shape=img_size + (3,))\n",
        "    x = layers.Rescaling(1./255)(inputs) # 이미지 정규화 (0~1)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\")(x) # Padding 영향 제거 ('same')\n",
        "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(256, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "\n",
        "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x) # 최종 클래스 3개\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = get_model(img_size=img_size, num_classes=3)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "sz9ITnxct5dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Model Training"
      ],
      "metadata": {
        "id": "qFta5bREvcG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"oxford_segmentation.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(train_input_imgs, train_targets,\n",
        "                    epochs=50,\n",
        "                    callbacks=callbacks,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(val_input_imgs, val_targets))"
      ],
      "metadata": {
        "id": "DoGFCYCivbF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4. Model Evaluate"
      ],
      "metadata": {
        "id": "-cK8HUOnxMuZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 학습 결과 확인"
      ],
      "metadata": {
        "id": "z8B8nb-5xTRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(1, len(history.history[\"loss\"]) + 1)\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "zfoCeCbDxP69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 테스트 데이터"
      ],
      "metadata": {
        "id": "XoVSSXH2xVww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import array_to_img\n",
        "\n",
        "# 모델 불러오기\n",
        "model = keras.models.load_model(\"oxford_segmentation.keras\")\n",
        "\n",
        "# Test data predict\n",
        "i = 4\n",
        "test_image = val_input_imgs[i]\n",
        "mask = model.predict(np.expand_dims(test_image, 0))[0]\n",
        "\n",
        "def display_mask(pred):\n",
        "    mask = np.argmax(pred, axis=-1)\n",
        "    mask *= 127\n",
        "    return mask\n",
        "\n",
        "# Result show\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.subplot(121)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(array_to_img(test_image))\n",
        "plt.title('Image')\n",
        "plt.subplot(122)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(display_mask(mask))\n",
        "plt.title('mask')"
      ],
      "metadata": {
        "id": "cAXIYzd6xi15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKZV9ZAMyJnp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lecture1_CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}