{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "CNN_VGG_Build.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pulsar-kkaturi/Deepnoid-Education/blob/master/notebooks/CNN_VGG_Build.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fsLexN5mWmf"
      },
      "source": [
        "# NEURAL NETWORK BUILD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ-lxCOpmWmj"
      },
      "source": [
        "# 1. LIbrary Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMUn1R-5mWmj"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.ticker import MultipleLocator\n",
        "import pandas as pd\n",
        "import csv\n",
        "import shutil\n",
        "import json\n",
        "from sklearn import metrics as skmet\n",
        "from skimage import morphology\n",
        "from skimage import measure\n",
        "from skimage import exposure\n",
        "\n",
        "### Tensorflow 2.0 ###\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyxOHppVmWmk"
      },
      "source": [
        "# 2. Module Fuction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9nTwrpImWmk"
      },
      "source": [
        "##2.1. keras application VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw7cnbF6mWmk",
        "outputId": "44c1af9d-75cb-4618-c24a-fb2a8329b824"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JQNlRBPmWml"
      },
      "source": [
        "## 2.2. Conv Block & Output Block Define "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PsFuh3pmWml"
      },
      "source": [
        "def conv_block_2d(lr_conv, lr_num, par_list, bkn):\n",
        "        # parameter\n",
        "        filter_num = par_list[0]\n",
        "        conv_size = par_list[1]\n",
        "        conv_act = par_list[2]\n",
        "        pool_size = par_list[3]\n",
        "        # code\n",
        "        for i in range(lr_num):\n",
        "            lr_conv = layers.Conv2D(filter_num, conv_size, activation=None, padding='same', \n",
        "                                    kernel_initializer='he_normal',\n",
        "                                    name='block{}_conv{}'.format(bkn, i+1))(lr_conv)\n",
        "            lr_conv = layers.BatchNormalization(axis=-1, name='block{}_batchnorm{}'.format(bkn, i+1))(lr_conv)\n",
        "            lr_conv = layers.Activation(conv_act, name='block{}_activ{}'.format(bkn, i+1))(lr_conv)\n",
        "        lr_pool = layers.MaxPooling2D(pool_size=pool_size, name='block{}_pool'.format(bkn, i+1))(lr_conv)\n",
        "        return lr_pool\n",
        "\n",
        "def conv_block_3d(lr_conv, lr_num, par_list, bkn):\n",
        "        # parameter\n",
        "        filter_num = par_list[0]\n",
        "        conv_size = par_list[1]\n",
        "        conv_act = par_list[2]\n",
        "        pool_size = par_list[3]\n",
        "        # code\n",
        "        for i in range(lr_num):\n",
        "            lr_conv = layers.Conv3D(filter_num, conv_size, activation=None, padding='same', \n",
        "                                    kernel_initializer='he_normal',\n",
        "                                    name='block{}_conv{}'.format(bkn, i+1))(lr_conv)\n",
        "            lr_conv = layers.BatchNormalization(axis=-1, name='block{}_batchnorm{}'.format(bkn, i+1))(lr_conv)\n",
        "            lr_conv = layers.Activation(conv_act, name='block{}_activ{}'.format(bkn, i+1))(lr_conv)\n",
        "        lr_pool = layers.MaxPooling3D(pool_size=pool_size, name='block{}_pool'.format(bkn, i+1))(lr_conv)\n",
        "        return lr_pool\n",
        "\n",
        "def output_block(lr_dense, block_num, dens_count, act_func, drop_rate):\n",
        "    lr_dense = layers.Flatten(name='flatten_layer')(lr_dense)\n",
        "    for i in range(block_num):\n",
        "        lr_dense = layers.Dense(dens_count[i], kernel_regularizer=None,\n",
        "                                activation=act_func, name='classifier_dense_{}'.format(i+1))(lr_dense)\n",
        "        lr_dense = layers.Dropout(drop_rate, name='classifier_dropout_{}'.format(i+1))(lr_dense)\n",
        "    return lr_dense"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7PO44Q0GSW1"
      },
      "source": [
        "## 2.3. VGG16 Build(2D & 3D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nkrFK5jmWmm"
      },
      "source": [
        "def VGG16_2D(par_dic):\n",
        "    # parameters\n",
        "    input_size = par_dic['input_size']\n",
        "    conv_size = par_dic['conv_size']\n",
        "    conv_act = par_dic['conv_act']\n",
        "    pool_size = par_dic['pool_size']\n",
        "    dens_num = par_dic['dens_num']\n",
        "    dens_count = par_dic['dens_count']\n",
        "    dens_act = par_dic['dens_act']\n",
        "    drop_out = par_dic['drop_out']\n",
        "    output_count = par_dic['output_count']\n",
        "    output_act = par_dic['output_act']\n",
        "\n",
        "    # code block\n",
        "    inputs = Input(shape=(input_size, input_size, 1), name='input_layer')\n",
        "    block1 = conv_block_2d(inputs, 2, [64, conv_size, conv_act, pool_size])\n",
        "    block2 = conv_block_2d(block1, 2, [128, conv_size, conv_act, pool_size])\n",
        "    block3 = conv_block_2d(block2, 3, [256, conv_size, conv_act, pool_size])\n",
        "    block4 = conv_block_2d(block3, 3, [512, conv_size, conv_act, pool_size])\n",
        "    block5 = conv_block_2d(block4, 3, [512, conv_size, conv_act, pool_size])\n",
        "    dens = output_block(block5, dens_num, dens_count, dens_act, drop_out)\n",
        "    outputs = layers.Dense(output_count, activation=output_act, name='output_layer')(dens)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEPu_HilGAJk"
      },
      "source": [
        "def VGG16_3D(par_dic):\r\n",
        "    # parameters\r\n",
        "    input_size = par_dic['input_size']\r\n",
        "    conv_size = par_dic['conv_size']\r\n",
        "    conv_act = par_dic['conv_act']\r\n",
        "    pool_size = par_dic['pool_size']\r\n",
        "    dens_num = par_dic['dens_num']\r\n",
        "    dens_count = par_dic['dens_count']\r\n",
        "    dens_act = par_dic['dens_act']\r\n",
        "    drop_out = par_dic['drop_out']\r\n",
        "    output_count = par_dic['output_count']\r\n",
        "    output_act = par_dic['output_act']\r\n",
        "\r\n",
        "    # code block\r\n",
        "    inputs = Input(shape=(input_size, input_size, input_size, 1), name='input_layer')\r\n",
        "    block1 = conv_block_3d(inputs, 2, [64, conv_size, conv_act, pool_size])\r\n",
        "    block2 = conv_block_3d(block1, 2, [128, conv_size, conv_act, pool_size])\r\n",
        "    block3 = conv_block_3d(block2, 3, [256, conv_size, conv_act, pool_size])\r\n",
        "    block4 = conv_block_3d(block3, 3, [512, conv_size, conv_act, pool_size])\r\n",
        "    block5 = conv_block_3d(block4, 3, [512, conv_size, conv_act, pool_size])\r\n",
        "    dens = output_block(block5, dens_num, dens_count, dens_act, drop_out)\r\n",
        "    outputs = layers.Dense(output_count, activation=output_act, name='output_layer')(dens)\r\n",
        "    model = Model(inputs, outputs)\r\n",
        "    return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq-aWq23GnYP"
      },
      "source": [
        "## 2.4. VGG19 Build (2D & 3D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOi3RDaomWmm"
      },
      "source": [
        "def VGG19_2D(par_dic):\n",
        "    # parameters\n",
        "    input_size = par_dic['input_size']\n",
        "    conv_size = par_dic['conv_size']\n",
        "    conv_act = par_dic['conv_act']\n",
        "    pool_size = par_dic['pool_size']\n",
        "    dens_num = par_dic['dens_num']\n",
        "    dens_count = par_dic['dens_count']\n",
        "    dens_act = par_dic['dens_act']\n",
        "    drop_out = par_dic['drop_out']\n",
        "    output_count = par_dic['output_count']\n",
        "    output_act = par_dic['output_act']\n",
        "\n",
        "    # code block\n",
        "    inputs = Input(shape=(input_size, input_size, 1))\n",
        "    block1 = conv_block_2d(inputs, 2, [64, conv_size, conv_act, pool_size], 1)\n",
        "    block2 = conv_block_2d(block1, 2, [128, conv_size, conv_act, pool_size], 2)\n",
        "    block3 = conv_block_2d(block2, 4, [256, conv_size, conv_act, pool_size], 3)\n",
        "    block4 = conv_block_2d(block3, 4, [512, conv_size, conv_act, pool_size], 4)\n",
        "    block5 = conv_block_2d(block4, 4, [512, conv_size, conv_act, pool_size], 5)\n",
        "    dens = output_block(block5, dens_num, dens_count, dens_act, drop_out)\n",
        "    outputs = layers.Dense(output_count, activation=output_act)(dens)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdh1YajTHGRY"
      },
      "source": [
        "def VGG19_3D(par_dic):\r\n",
        "    # parameters\r\n",
        "    input_size = par_dic['input_size']\r\n",
        "    conv_size = par_dic['conv_size']\r\n",
        "    conv_act = par_dic['conv_act']\r\n",
        "    pool_size = par_dic['pool_size']\r\n",
        "    dens_num = par_dic['dens_num']\r\n",
        "    dens_count = par_dic['dens_count']\r\n",
        "    dens_act = par_dic['dens_act']\r\n",
        "    drop_out = par_dic['drop_out']\r\n",
        "    output_count = par_dic['output_count']\r\n",
        "    output_act = par_dic['output_act']\r\n",
        "\r\n",
        "    # code block\r\n",
        "    inputs = Input(shape=(input_size, input_size, input_size, 1))\r\n",
        "    block1 = conv_block_3d(inputs, 2, [64, conv_size, conv_act, pool_size], 1)\r\n",
        "    block2 = conv_block_3d(block1, 2, [128, conv_size, conv_act, pool_size], 2)\r\n",
        "    block3 = conv_block_3d(block2, 4, [256, conv_size, conv_act, pool_size], 3)\r\n",
        "    block4 = conv_block_3d(block3, 4, [512, conv_size, conv_act, pool_size], 4)\r\n",
        "    block5 = conv_block_3d(block4, 4, [512, conv_size, conv_act, pool_size], 5)\r\n",
        "    dens = output_block(block5, dens_num, dens_count, dens_act, drop_out)\r\n",
        "    outputs = layers.Dense(output_count, activation=output_act)(dens)\r\n",
        "    model = Model(inputs, outputs)\r\n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvmjT-BDmWmm"
      },
      "source": [
        "# 3. Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h21VXXuImWmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22a88442-1d56-4047-82f5-88d682639dff"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test)=keras.datasets.mnist.load_data(path='minist.npz')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZhc0G0emWmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f60046-f0f3-417a-b3c0-641d363bf8da"
      },
      "source": [
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7YSw3QkmWmn"
      },
      "source": [
        "# 3.1 2D dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5iscUbymWmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caa65d4d-4e6e-4eb6-9983-4c8a9088b499"
      },
      "source": [
        "x_train_list = []\n",
        "x_test_list = []\n",
        "for i, i_ in enumerate(x_train[:5000]):\n",
        "    arr = np.zeros(shape=(32, 32))\n",
        "    arr[:28,:28] = x_train[i]\n",
        "    x_train_list.append(arr)\n",
        "for i, i_ in enumerate(x_test[:500]):\n",
        "    arr = np.zeros(shape=(32, 32))\n",
        "    arr[:28,:28] = x_test[i]\n",
        "    x_test_list.append(arr)\n",
        "\n",
        "x_train1 = np.expand_dims(np.array(x_train_list), axis=-1)\n",
        "x_test1 = np.expand_dims(np.array(x_test_list), axis=-1)\n",
        "print(x_train1.shape, x_test1.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 32, 32, 1) (500, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYrbF26lmWmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6cc622-a793-4c58-c100-8019f6cd1b65"
      },
      "source": [
        "y_train_list = []\n",
        "y_test_list = []\n",
        "for i, i_ in enumerate(y_train[:5000]):\n",
        "    zero = [0]*10\n",
        "    zero[i_] = 1\n",
        "    y_train_list.append(zero)\n",
        "\n",
        "for i, i_ in enumerate(y_test[:500]):\n",
        "    zero = [0]*10\n",
        "    zero[i_] = 1\n",
        "    y_test_list.append(zero)    \n",
        "    \n",
        "y_train1 = np.array(y_train_list)\n",
        "y_test1 = np.array(y_test_list)\n",
        "print(y_train1.shape, y_test1.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 10) (500, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDbfzKwImWmo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "1b9ef7eb-4c29-4281-a98b-b27cd3d13de5"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(x_train1[i][...,0], cmap='gray')\n",
        "    plt.title('Class = {}'.format(y_train[i]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNvCkU-rmWmo"
      },
      "source": [
        "## 3.2 3D dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7_FSBYamWmo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cc9164f-0b50-4f4e-fee9-f1ba69d59081"
      },
      "source": [
        "x_train_list = []\n",
        "y_train_list = []\n",
        "x_test_list = []\n",
        "y_test_list = []\n",
        "for i in range(1200):\n",
        "    zero = np.zeros(shape=(32,32,32))\n",
        "    ones = np.ones(shape=(16,16,16))\n",
        "    ran = int(np.random.randint(10, size=1)-5)\n",
        "    if 0 <= i < 400:\n",
        "        zero[:,:,:] = (ran*10) + 150\n",
        "        x_train_list.append(zero)\n",
        "        y_train_list.append([1,0,0])\n",
        "    elif 400 <= i < 800:\n",
        "        zero[8+ran:24+ran,8+ran:24+ran,8+ran:24+ran] = (ran*10) + 200\n",
        "        x_train_list.append(zero)\n",
        "        y_train_list.append([0,1,0])\n",
        "    elif 800 <= i < 1200:\n",
        "        for j in range(32):\n",
        "            for k in range(32):\n",
        "                for l in range(32):\n",
        "                    if ((j-16+ran)**2) + ((k-16+ran)**2) + ((l-16+ran)**2) < 100:\n",
        "                        zero[j,k,l] = (ran*10) + 200\n",
        "        x_train_list.append(zero)\n",
        "        y_train_list.append([0,0,1])\n",
        "\n",
        "for i in range(600):\n",
        "    zero = np.zeros(shape=(32,32,32))\n",
        "    ones = np.ones(shape=(16,16,16))\n",
        "    ran = int(np.random.randint(10, size=1)-5)\n",
        "    if 0 <= i < 200:\n",
        "        zero[:,:,:] = (ran*10) + 150\n",
        "        x_test_list.append(zero)\n",
        "        y_test_list.append([1,0,0])\n",
        "    elif 200 <= i < 400:\n",
        "        zero[8+ran:24+ran,8+ran:24+ran,8+ran:24+ran] = (ran*10) + 200\n",
        "        x_test_list.append(zero)\n",
        "        y_test_list.append([0,1,0])\n",
        "    elif 400 <= i < 600:\n",
        "        for j in range(32):\n",
        "            for k in range(32):\n",
        "                for l in range(32):\n",
        "                    if ((j-16+ran)**2) + ((k-16+ran)**2) + ((l-16+ran)**2) < 100:\n",
        "                        zero[j,k,l] = (ran*10) + 200\n",
        "        x_test_list.append(zero)\n",
        "        y_test_list.append([0,0,1])\n",
        "\n",
        "x3_train1 = np.expand_dims(np.array(x_train_list), axis=-1)\n",
        "x3_test1 = np.expand_dims(np.array(x_test_list), axis=-1)\n",
        "y3_train1 = np.array(y_train_list)\n",
        "y3_test1 = np.array(y_test_list)\n",
        "print(x3_train1.shape, x3_test1.shape)\n",
        "print(y3_train1.shape, y3_test1.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1200, 32, 32, 32, 1) (600, 32, 32, 32, 1)\n",
            "(1200, 3) (600, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp8apIbbmWmp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "fa1b5bf5-3e63-495d-ebdb-c8c9c6bfd505"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        plt.subplot(3,3, (3*i)+j+1)\n",
        "        plt.imshow(x3_train1[(i*400)+(j*100)][(8*j)+8,...,0], cmap='gray')\n",
        "        plt.title('Class = {}'.format(str(y3_train1[(i*400)+(j*100)])))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWCfiABkmWmp"
      },
      "source": [
        "# 3. Model Build"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck3Ecxs8mWmp"
      },
      "source": [
        "## 3.1 2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RyJRUzAmWmp"
      },
      "source": [
        "network_param_2d = {'input_size': 32,\n",
        "                     'conv_size': 3,\n",
        "                     'conv_act': 'relu',\n",
        "                     'pool_size': 2,\n",
        "                     'dens_num': 2,\n",
        "                     'dens_count': [1000,500],\n",
        "                     'dens_act': 'relu',\n",
        "                     'drop_out': 0.5,\n",
        "                     'output_count': 10,\n",
        "                     'output_act': 'softmax'}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yRcrJ1-RmWmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a7e4238-4d44-4a23-9a42-7bffbafd8b59"
      },
      "source": [
        "model = VGG19_2D(network_param_2d)\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        640       \n",
            "_________________________________________________________________\n",
            "block1_batchnorm1 (BatchNorm (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "block1_activ1 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_batchnorm2 (BatchNorm (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "block1_activ2 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_batchnorm1 (BatchNorm (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "block2_activ1 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_batchnorm2 (BatchNorm (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "block2_activ2 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_batchnorm1 (BatchNorm (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "block3_activ1 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_batchnorm2 (BatchNorm (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "block3_activ2 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_batchnorm3 (BatchNorm (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "block3_activ3 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_batchnorm4 (BatchNorm (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "block3_activ4 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_batchnorm1 (BatchNorm (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "block4_activ1 (Activation)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_batchnorm2 (BatchNorm (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "block4_activ2 (Activation)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_batchnorm3 (BatchNorm (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "block4_activ3 (Activation)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_batchnorm4 (BatchNorm (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "block4_activ4 (Activation)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_batchnorm1 (BatchNorm (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "block5_activ1 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_batchnorm2 (BatchNorm (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "block5_activ2 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_batchnorm3 (BatchNorm (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "block5_activ3 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_batchnorm4 (BatchNorm (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "block5_activ4 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_layer (Flatten)      (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "classifier_dense_1 (Dense)   (None, 1000)              513000    \n",
            "_________________________________________________________________\n",
            "classifier_dropout_1 (Dropou (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "classifier_dense_2 (Dense)   (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "classifier_dropout_2 (Dropou (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 21,063,758\n",
            "Trainable params: 21,052,750\n",
            "Non-trainable params: 11,008\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJt621_cmWmq"
      },
      "source": [
        "model.compile(loss=losses.CategoricalCrossentropy(), optimizer=optimizers.Adam(lr=1e-5), metrics=['acc'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "iKfz_dDumWmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d7ad4cd-69f4-4288-a7d6-a58a48ab2388"
      },
      "source": [
        "callback_list = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=20),\n",
        "                         keras.callbacks.ModelCheckpoint(filepath=os.path.join('2d_model.h5'),\n",
        "                                                         monitor='val_accuracy', save_best_only=True),\n",
        "                         keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10)]\n",
        "\n",
        "history = model.fit(x_train1, y_train1, epochs=50, batch_size=32, \n",
        "                    validation_data=(x_test1, y_test1),\n",
        "                    callbacks=callback_list, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "148/157 [===========================>..] - ETA: 26s - loss: 3.8944 - acc: 0.2021"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYSn7pqmmWmq"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "# Accuracy graph\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(epochs, acc, 'b', label='Training acc = {}%'.format(np.around(np.max(acc) * 100, decimals=1)))\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc = {}%'.format(np.around(np.max(val_acc) * 100, decimals=1)))\n",
        "plt.title('{} Accuracy (Total Epoch = {})'.format('VGG16', len(acc)), fontsize=15, y=1.02)\n",
        "plt.xticks(size=15)\n",
        "plt.yticks(size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()\n",
        "# Loss graph\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(epochs, loss, 'b', label='Training loss = {}'.format(np.around(np.min(loss), decimals=3)))\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss= {}'.format(np.around(np.min(val_loss), decimals=3)))\n",
        "plt.title('{} Loss (Total Epoch = {})'.format('VGG16', len(loss)), fontsize=15, y=1.02)\n",
        "plt.xticks(size=15)\n",
        "plt.yticks(size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVT4KNd5mWmq"
      },
      "source": [
        "## 3.2 3D "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpaWZMjpH5J4"
      },
      "source": [
        "network_param_3d = {'input_size': 32,\r\n",
        "                     'conv_size': 3,\r\n",
        "                     'conv_act': 'relu',\r\n",
        "                     'pool_size': 2,\r\n",
        "                     'dens_num': 2,\r\n",
        "                     'dens_count': [1000,500],\r\n",
        "                     'dens_act': 'relu',\r\n",
        "                     'drop_out': 0.5,\r\n",
        "                     'output_count': 3,\r\n",
        "                     'output_act': 'softmax'}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Et33FS_1mWmr",
        "outputId": "92d01c7d-2967-4a29-9284-5340b4db0d2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = VGG19_3D(network_param_3d)\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 32, 32, 32, 1)]   0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv3D)        (None, 32, 32, 32, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_batchnorm1 (BatchNorm (None, 32, 32, 32, 64)    256       \n",
            "_________________________________________________________________\n",
            "block1_activ1 (Activation)   (None, 32, 32, 32, 64)    0         \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv3D)        (None, 32, 32, 32, 64)    110656    \n",
            "_________________________________________________________________\n",
            "block1_batchnorm2 (BatchNorm (None, 32, 32, 32, 64)    256       \n",
            "_________________________________________________________________\n",
            "block1_activ2 (Activation)   (None, 32, 32, 32, 64)    0         \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling3D)   (None, 16, 16, 16, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv3D)        (None, 16, 16, 16, 128)   221312    \n",
            "_________________________________________________________________\n",
            "block2_batchnorm1 (BatchNorm (None, 16, 16, 16, 128)   512       \n",
            "_________________________________________________________________\n",
            "block2_activ1 (Activation)   (None, 16, 16, 16, 128)   0         \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv3D)        (None, 16, 16, 16, 128)   442496    \n",
            "_________________________________________________________________\n",
            "block2_batchnorm2 (BatchNorm (None, 16, 16, 16, 128)   512       \n",
            "_________________________________________________________________\n",
            "block2_activ2 (Activation)   (None, 16, 16, 16, 128)   0         \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling3D)   (None, 8, 8, 8, 128)      0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv3D)        (None, 8, 8, 8, 256)      884992    \n",
            "_________________________________________________________________\n",
            "block3_batchnorm1 (BatchNorm (None, 8, 8, 8, 256)      1024      \n",
            "_________________________________________________________________\n",
            "block3_activ1 (Activation)   (None, 8, 8, 8, 256)      0         \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv3D)        (None, 8, 8, 8, 256)      1769728   \n",
            "_________________________________________________________________\n",
            "block3_batchnorm2 (BatchNorm (None, 8, 8, 8, 256)      1024      \n",
            "_________________________________________________________________\n",
            "block3_activ2 (Activation)   (None, 8, 8, 8, 256)      0         \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv3D)        (None, 8, 8, 8, 256)      1769728   \n",
            "_________________________________________________________________\n",
            "block3_batchnorm3 (BatchNorm (None, 8, 8, 8, 256)      1024      \n",
            "_________________________________________________________________\n",
            "block3_activ3 (Activation)   (None, 8, 8, 8, 256)      0         \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv3D)        (None, 8, 8, 8, 256)      1769728   \n",
            "_________________________________________________________________\n",
            "block3_batchnorm4 (BatchNorm (None, 8, 8, 8, 256)      1024      \n",
            "_________________________________________________________________\n",
            "block3_activ4 (Activation)   (None, 8, 8, 8, 256)      0         \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling3D)   (None, 4, 4, 4, 256)      0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv3D)        (None, 4, 4, 4, 512)      3539456   \n",
            "_________________________________________________________________\n",
            "block4_batchnorm1 (BatchNorm (None, 4, 4, 4, 512)      2048      \n",
            "_________________________________________________________________\n",
            "block4_activ1 (Activation)   (None, 4, 4, 4, 512)      0         \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv3D)        (None, 4, 4, 4, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "block4_batchnorm2 (BatchNorm (None, 4, 4, 4, 512)      2048      \n",
            "_________________________________________________________________\n",
            "block4_activ2 (Activation)   (None, 4, 4, 4, 512)      0         \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv3D)        (None, 4, 4, 4, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "block4_batchnorm3 (BatchNorm (None, 4, 4, 4, 512)      2048      \n",
            "_________________________________________________________________\n",
            "block4_activ3 (Activation)   (None, 4, 4, 4, 512)      0         \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv3D)        (None, 4, 4, 4, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "block4_batchnorm4 (BatchNorm (None, 4, 4, 4, 512)      2048      \n",
            "_________________________________________________________________\n",
            "block4_activ4 (Activation)   (None, 4, 4, 4, 512)      0         \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling3D)   (None, 2, 2, 2, 512)      0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv3D)        (None, 2, 2, 2, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "block5_batchnorm1 (BatchNorm (None, 2, 2, 2, 512)      2048      \n",
            "_________________________________________________________________\n",
            "block5_activ1 (Activation)   (None, 2, 2, 2, 512)      0         \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv3D)        (None, 2, 2, 2, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "block5_batchnorm2 (BatchNorm (None, 2, 2, 2, 512)      2048      \n",
            "_________________________________________________________________\n",
            "block5_activ2 (Activation)   (None, 2, 2, 2, 512)      0         \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv3D)        (None, 2, 2, 2, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "block5_batchnorm3 (BatchNorm (None, 2, 2, 2, 512)      2048      \n",
            "_________________________________________________________________\n",
            "block5_activ3 (Activation)   (None, 2, 2, 2, 512)      0         \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv3D)        (None, 2, 2, 2, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "block5_batchnorm4 (BatchNorm (None, 2, 2, 2, 512)      2048      \n",
            "_________________________________________________________________\n",
            "block5_activ4 (Activation)   (None, 2, 2, 2, 512)      0         \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling3D)   (None, 1, 1, 1, 512)      0         \n",
            "_________________________________________________________________\n",
            "flatten_layer (Flatten)      (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "classifier_dense_1 (Dense)   (None, 1000)              513000    \n",
            "_________________________________________________________________\n",
            "classifier_dropout_1 (Dropou (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "classifier_dense_2 (Dense)   (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "classifier_dropout_2 (Dropou (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 1503      \n",
            "=================================================================\n",
            "Total params: 61,095,707\n",
            "Trainable params: 61,084,699\n",
            "Non-trainable params: 11,008\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06KnVstxmWmr",
        "outputId": "c129192b-b2dd-40e8-ec06-df710c25fec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "model.compile(loss=losses.CategoricalCrossentropy(), optimizer=optimizers.Adam(lr=1e-5), metrics=['acc'])\n",
        "callback_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=12),\n",
        "                         keras.callbacks.ModelCheckpoint(filepath=os.path.join('3d_model.h5'),\n",
        "                                                         monitor='val_accuracy', save_best_only=True),\n",
        "                         keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10)]\n",
        "\n",
        "history = model.fit(x3_train1, y3_train1, epochs=100, batch_size=32, \n",
        "                    validation_data=(x3_test1, y3_test1),\n",
        "                    callbacks=callback_list, shuffle=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 5/38 [==>...........................] - ETA: 25s - loss: 0.0925 - acc: 0.9622"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-1ccecc35b671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m history = model.fit(x3_train1, y3_train1, epochs=100, batch_size=32, \n\u001b[1;32m      8\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my3_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     callbacks=callback_list, shuffle=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK_aCtLrmWmr"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "# Accuracy graph\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(epochs, acc, 'b', label='Training acc = {}%'.format(np.around(np.max(acc) * 100, decimals=1)))\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc = {}%'.format(np.around(np.max(val_acc) * 100, decimals=1)))\n",
        "plt.title('{} Accuracy (Total Epoch = {})'.format('VGG16', len(acc)), fontsize=15, y=1.02)\n",
        "plt.xticks(size=15)\n",
        "plt.yticks(size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()\n",
        "# Loss graph\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(epochs, loss, 'b', label='Training loss = {}'.format(np.around(np.min(loss), decimals=3)))\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss= {}'.format(np.around(np.min(val_loss), decimals=3)))\n",
        "plt.title('{} Loss (Total Epoch = {})'.format('VGG16', len(loss)), fontsize=15, y=1.02)\n",
        "plt.xticks(size=15)\n",
        "plt.yticks(size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26qBMmXXmWmr"
      },
      "source": [
        "# 4. Additional Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8_uGVPnmWmr"
      },
      "source": [
        "# 4.1 VGG19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j2tjkknmWmr"
      },
      "source": [
        "* keras application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWjw1sw8mWmr"
      },
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "model = VGG19(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm27XS59mWms"
      },
      "source": [
        "def VGGfree_2D(input_size, block_num, layer_num, drop_out, flat_count, class_count, conv_act, flat_act, output_act, conv_str, pool_str):\n",
        "\n",
        "    inputs = Input(shape=(input_size, input_size, 1))\n",
        "    block = layers.Conv2D(32, conv_str, activation=conv_act, padding='same', kernel_initializer='he_normal')(inputs)\n",
        "    for i in range(block_num):\n",
        "        block = cn.conv_block_2d(block, layer_num, [32*(2**i), conv_str, conv_act, pool_str, drop_out])\n",
        "    flat = layers.Flatten()(block)\n",
        "    drop1 = layers.Dropout(drop_out)(flat)\n",
        "    dens = layers.Dense(flat_count, activation=flat_act)(drop1)\n",
        "    drop2 = layers.Dropout(drop_out)(dens)\n",
        "    outputs = layers.Dense(class_count, activation=output_act)(drop2)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = VGGfree_2D(32, 5, 2, 0.5, 256, 2, 'relu', 'relu', 'sigmoid', 3, 2)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mtaCfqFmWms"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}