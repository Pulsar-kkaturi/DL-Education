{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4. CNN build\n",
    "* Ref. 최건호, 파이토치 첫걸음, 한빛미디어 ([link](https://drive.google.com/drive/folders/12zphz36T6gEJac6WScnvRN27-f1tfHO1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 인공신경망 (Deep Neural Network; DNN)\n",
    "* 2장의 선형회귀모델과 달리, 비선형인 2차함수에 대한 회귀모델을 딥러닝으로 구현해보자!\n",
    "* y = x<sup>2</sup>+3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. 라이브러리 및 데이터 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU에서 학습을 위해 GPU check\n",
    "print(\"사용 가능한 GPU가 존재하는가? (True or False): \", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"사용 가능한 GPU의 수는 {} 개 입니다.\".format(torch.cuda.device_count()))\n",
    "    print(\"GPU 각각의 이름은 아래와 같습니다.\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"GPU {}: {}\".format(i, torch.cuda.get_device_name(i)))\n",
    "else:\n",
    "    print(\"사용 가능한 GPU가 존재하지 않습니다. 혹은 GPU를 Pytorch가 찾지 못하고 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "num_data = 1000\n",
    "\n",
    "noise = init.normal_(torch.FloatTensor(num_data,1),std=3)\n",
    "x = init.uniform_(torch.Tensor(num_data,1),-15,15)\n",
    "y = (x**2) + 3 \n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 시각화\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(x.numpy(), y_noise.numpy(), s=3, c='gray', label='Original Data') # 학습시킬 실제 데이터 분포\n",
    "plt.scatter(x.numpy(), y.numpy(), s=3, c='red', label='Label Data') # 정답 분포\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3장의 예시처럼 하나의 값이 들어가서 하나의 값이 나오기 때문에 모델의 처음과 끝 특성의 개수는 1개입니다.\n",
    "\n",
    "# https://pytorch.org/docs/stable/nn.html?highlight=sequential\n",
    "# torch.nn.Sequential\n",
    "# Sequential 모듈은 다양한 모듈을 담을 수 있는 일종의 리스트라고 보면 됩니다.\n",
    "# Sequential 에 정의된 순서대로 연산이 진행되며, 많은 연산을 묶어서 한번에 관리할 수 있어서 편리합니다.\n",
    "\n",
    "# 아래 코드는 특성의 개수가 1 -> 6 -> 10 -> 6 -> 1개로 변하는 인공신경망입니다. \n",
    "# 또한 선형변환 이후 활성화 함수를 넣어 비선형성이 생기도록 했습니다.\n",
    "\n",
    "model = nn.Sequential(\n",
    "          nn.Linear(1,6),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(6,10),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(10,6),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(6,1),\n",
    "      )\n",
    "\n",
    "loss_func = nn.L1Loss() # 손실함수로는 L1(절대값의 평균) loss 사용\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.0002) # 옵티마이저로는 SGD 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 10000 # 학습시킬 epoch 수\n",
    "device = 'cuda:0' # 학습시킬 gpu\n",
    "loss_array = []\n",
    "pbar = tqdm(total=num_epoch) # tqdm으로 학습 진행도 확인 가능\n",
    "for i in range(num_epoch): \n",
    "    x.to(device)\n",
    "    y_noise.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    \n",
    "    loss = loss_func(output,y_noise)\n",
    "    loss.backward() # 역전파 손실 연산\n",
    "    optimizer.step() # 옵티마이저로 가중치 업데이트\n",
    "    \n",
    "    pbar.set_description(f\"Processing({i+1}/{num_epoch}): loss={loss.data}\")\n",
    "    pbar.update(1)\n",
    "    loss_array.append(loss.detach().numpy()) # 손실값의 데이터만 numpy로 보냄\n",
    "pbar.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(loss_array)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(x.detach().numpy(),y_noise, s=3, c='grey', label=\"Original Data\")\n",
    "plt.scatter(x.detach().numpy(),y, s=3, c='red', label=\"Label Data\")\n",
    "plt.scatter(x.detach().numpy(),output.detach().numpy(), s=3, c='blue',label=\"Model Output\")\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 합성곱 신경망 (Convolutional Neural Network; CNN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MNIST 데이터 사용\n",
    "* 기초적인 합성곱 신경망 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab에서 실행시 파이토치 설치\n",
    "#!pip install torch torchvision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 환경 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "# https://pytorch.org/vision/stable/datasets.html\n",
    "# 파이토치에서는 torchvision.datasets에 MNIST 등의 다양한 데이터를 사용하기 용이하게 정리해놨습니다.\n",
    "# 이를 사용하면 데이터를 따로 학습에 맞게 정리하거나 하지 않아도 바로 사용이 가능합니다.\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "# https://pytorch.org/vision/stable/transforms.html\n",
    "# torchvision.transforms에는 이미지 데이터를 자르거나 확대 및 다양하게 변형시키는 함수들이 구현되어 있습니다. \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# https://pytorch.org/docs/stable/data.html\n",
    "# DataLoader는 전처리가 끝난 데이터들을 지정한 배치 크기에 맞게 모아서 전달해주는 역할을 합니다.\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=mnist#torchvision.datasets.MNIST\n",
    "# 첫번째 인자 root는 데이터를 저장할 위치, train은 학습용 데이터인지 테스트용 데이터인지의 여부를 의미합니다.\n",
    "data_path = '/home/student/Datasets/jhjeong/Test/' # 자신의 환경에 맞게 설정!\n",
    "\n",
    "# MNIST 데이터는 숫자 손글씨 이미지와 이에 대한 정답 쌍으로 이루어져 있습니다. \n",
    "# transform은 이미지에 대한 변형, target_transform은 정답 라벨에 대한 변형을 의미합니다.\n",
    "# transform.ToTensor()는 PIL 이미지나 Numpy 배열을 토치 텐서로 바꿔줍니다.\n",
    "\n",
    "# download는 데이터가 저장할 위치에 없을 경우 새로 다운받을지 여부입니다.\n",
    "mnist_train = dset.MNIST(root=data_path, train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
    "mnist_test = dset.MNIST(root=data_path, train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MNIST Dataset 구조: (frame1(image, label), frame2(image, label), ..., frame60000(image, label))\n",
    "* index 순서 : mnist_train[frame_index(0~60000)][0(image) or 1(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 확인 (torch tensor)\n",
    "print(mnist_train.__getitem__(0)[0].size(), mnist_train.__len__())\n",
    "print(mnist_test.__getitem__(0)[0].size(), mnist_test.__len__())\n",
    "\n",
    "print(len(mnist_train),len(mnist_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mnist_train[0][0].size()) # 0번째 프레임의 이미지 크기 출력\n",
    "print(mnist_train[0][1]) # 0번째 프레임의 레이블(정답) 출력\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(3*3): # 9개의 데이터 추가 확인\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(np.moveaxis(mnist_train[i][0].numpy(), 0, -1)) # np.moveaxis()는 channel 위치를 0 -> -1로 옮겨준다.\n",
    "    plt.title(f'label = {mnist_train[i][1]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DataLoader 설정\n",
    "    - batch_size = 배치 사이즈\n",
    "    - shuffle = 섞을지 여부\n",
    "    - num_workers = 데이터를 묶을때 사용할 프로세스 수\n",
    "    - drop_last = 묶고 남은 데이터를 버릴지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False,num_workers=2,drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5),             # [batch_size,1,28,28] -> [batch_size,16,24,24]\n",
    "            nn.ReLU(),                                                          # 필터의 개수는 1개(흑백이미지)에서 16개로 늘어나도록 임의로 설정했습니다. \n",
    "            nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5),            # [batch_size,16,24,24] -> [batch_size,32,20,20]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),                               # [batch_size,32,20,20] -> [batch_size,32,10,10]\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),          # [batch_size,32,10,10] -> [batch_size,64,6,6]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)                                # [batch_size,64,6,6] -> [batch_size,64,3,3]\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(                                          \n",
    "            nn.Linear(64*3*3,100),                                              # [batch_size,64*3*3] -> [batch_size,100]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,10)                                                   # [batch_size,100] -> [batch_size,10]\n",
    "        )       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)                                                     # self.layer에 정의한 Sequential의 연산을 차례대로 다 실행합니다.\n",
    "        out = out.view(batch_size,-1)                                           # view 함수를 이용해 텐서의 형태를 [batch_size,나머지]로 바꿔줍니다. 2차원 이미지를 1차원으로 펴주는 과정\n",
    "                                                                                # ex) 2x3 형태였던 텐서를 .view(1,-1) 해주면 1x6의 형태로 바뀝니다. .view(3,-1)이면 3x2로 바뀜.\n",
    "                                                                                # 만약 전체 텐서의 크기가 batch_size로 나누어 떨어지지 않으면 오류가 납니다.\n",
    "        out = self.fc_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu가 사용 가능한 경우에는 device를 gpu로 설정하고 불가능하면 cpu로 설정합니다.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# 모델을 지정한 장치로 올립니다.\n",
    "model = CNN().to(device)\n",
    "\n",
    "# 손실함수로는 크로스엔트로피를 사용합니다.\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화함수로는 Adam을 사용합니다.\n",
    "learning_rate = 0.0002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 모듈\n",
    "def train(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    pbar = tqdm(total=num_batches)\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metric\n",
    "        correct = (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # Epoch result \n",
    "        train_loss += loss.item()\n",
    "        train_acc += correct\n",
    "\n",
    "        # Traing Process check\n",
    "        loss, current = loss.item(), (batch + 1) * len(x)\n",
    "        acc = correct/len(x)\n",
    "        pbar.set_description(f\" - Batch Training[{epoch}]({current}/{size}): loss = {loss:>5f}, acc = {100*acc:>0.1f}%\")\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    # epoch \n",
    "    train_loss /= num_batches\n",
    "    train_acc /= size\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 모듈\n",
    "def test(dataloader, model, loss_fn, epoch, show=False):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            test_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    test_acc /= size\n",
    "    if show:\n",
    "        print(f\"    = Validation[{epoch}]: val_loss = {test_loss:>5f}, val_acc: {(100*test_acc):>0.1f}%\")\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 10\n",
    "\n",
    "history = {'loss': [], 'val_loss': [], 'acc': [], 'val_acc': []}\n",
    "for t in range(num_epoch):\n",
    "    train_loss, train_acc = train(train_loader, model, loss_func, optimizer, t+1)\n",
    "    val_loss, val_acc = test(test_loader, model, loss_func, t+1)\n",
    "    history['loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    print(f'# Training[{t+1}/{num_epoch}]: loss = {train_loss:>5f}, acc = {100*train_acc:>0.1f}, val_loss = {val_loss:5>f}, val_acc = {100*val_acc:>0.1f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. 결과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history.keys():\n",
    "    print(key, history[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.title('Loss')\n",
    "plt.plot(history['loss'], c='b', label='train')\n",
    "plt.plot(history['val_loss'], c='r', label='validation')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history['acc'], c='b', label='train')\n",
    "plt.plot(history['val_acc'], c='r', label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dic = {'prob': [], 'pred': []}\n",
    "with torch.no_grad():\n",
    "    for img, lab in test_loader:\n",
    "        x = img.to(device)\n",
    "        pred = model.forward(x)\n",
    "        for i in range(len(x)):\n",
    "            probs = pred[i].cpu().detach().numpy()\n",
    "            # probs -= np.min(probs)\n",
    "            # probs /= np.sum(probs)\n",
    "            pred_dic['prob'].append(probs)\n",
    "            pred_dic['pred'].append(pred[i].argmax().item())\n",
    "print(pred_dic['pred'][0])\n",
    "print(pred_dic['prob'][0])\n",
    "print(len(pred_dic['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i in range(9):\n",
    "    img = np.moveaxis(mnist_test[i][0].detach().numpy(), 0 , -1)\n",
    "    pred = pred_dic['pred'][i]\n",
    "    # score = pred_dic['prob'][i][pred]\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'label/pred = {mnist_test[i][1]}/{pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false case\n",
    "plt.figure(figsize=(12,12))\n",
    "n = 0\n",
    "for i in range(len(pred_dic['pred'])):\n",
    "    pred = pred_dic['pred'][i]\n",
    "    lab = mnist_test[i][1]\n",
    "    if pred != lab and n < 9:\n",
    "        n += 1\n",
    "        img = np.moveaxis(mnist_test[i][0].detach().numpy(), 0 , -1)\n",
    "        plt.subplot(3,3,n)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'label/pred = {mnist_test[i][1]}/{pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
