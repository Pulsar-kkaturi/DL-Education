{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pulsar-kkaturi/DL-Education/blob/master/VisionDL_Lecture/Lecture7_Segmentation_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segmentation"
      ],
      "metadata": {
        "id": "ULjcdV5Znve2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os, matplotlib, random\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "### Tensorflow 2.0 ###\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "gatQReoNRKzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 영상처리 관련 라이브러리 불러오기\n",
        "import skimage\n",
        "from skimage import io as skio\n",
        "from skimage import transform as skit\n",
        "from skimage import morphology as skim"
      ],
      "metadata": {
        "id": "9z4QBdzdRGcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices()"
      ],
      "metadata": {
        "id": "6OZTvcw7RO_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. U-Net"
      ],
      "metadata": {
        "id": "2BKrUswVnx6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Data Loading"
      ],
      "metadata": {
        "id": "az8SwE_Pn1jw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Dataset Download\n",
        "  - reference link: https://www.kaggle.com/datasets/nikhilroxtomar/brain-tumor-segmentation"
      ],
      "metadata": {
        "id": "rmlpvQ2TRVs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋을 이 세션으로 불러오기\n",
        "!git clone https://github.com/Pulsar-kkaturi/DL-Education.git"
      ],
      "metadata": {
        "id": "bhScPJpwnmCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 압축 풀기\n",
        "!tar -zxf ./DL-Education/dataset/brain_seg_2d.tar.gz"
      ],
      "metadata": {
        "id": "zVUYE4ITRgqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 데이터 경로 지정"
      ],
      "metadata": {
        "id": "vwRuNuIwRnKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_fol_path = './brain_seg_2d/images'\n",
        "msk_fol_path = './brain_seg_2d/masks'\n",
        "img_file_list = [f for f in sorted(os.listdir(img_fol_path))]\n",
        "msk_file_list = [f for f in sorted(os.listdir(msk_fol_path))]\n",
        "# print(img_file_list)\n",
        "# print(msk_file_list)\n",
        "\n",
        "img_list, msk_list = [], []\n",
        "for i, i_ in enumerate(img_file_list):\n",
        "  img_path = os.path.join(img_fol_path, i_)\n",
        "  msk_path = os.path.join(msk_fol_path, msk_file_list[i])\n",
        "  img_arr = skio.imread(img_path)\n",
        "  msk_arr = skio.imread(msk_path)\n",
        "  img_list.append(img_arr)\n",
        "  msk_list.append(msk_arr)\n",
        "\n",
        "print('Image numbers = ', len(img_list))\n",
        "print('Mask numbers = ', len(msk_list))"
      ],
      "metadata": {
        "id": "b357B0z-Rooy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이미지 & 레이블 확인"
      ],
      "metadata": {
        "id": "uXnLnBq8RsRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 정보\n",
        "print('이미지 크기 = ', img_list[0].shape)\n",
        "print(f'이미지 최대값/최소값 = {np.max(img_list[0])}/{np.min(img_list[0])}')\n",
        "# 마스크 정보\n",
        "print('마스크 크기 = ', msk_list[0].shape)\n",
        "print(f'마스크 최대값/최소값 = {np.max(msk_list[0])}/{np.min(msk_list[0])}')"
      ],
      "metadata": {
        "id": "-B3txUzLRt8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(131)\n",
        "plt.title('Image')\n",
        "plt.imshow(img_list[0])\n",
        "plt.subplot(132)\n",
        "plt.title('Mask')\n",
        "plt.imshow(msk_list[0])\n",
        "plt.subplot(133)\n",
        "plt.title('Overlay')\n",
        "plt.imshow(img_list[0], cmap='gray')\n",
        "plt.imshow(msk_list[0], cmap='Reds', alpha=0.3)"
      ],
      "metadata": {
        "id": "FbsQIdw7RvKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Data Pre-processing"
      ],
      "metadata": {
        "id": "PPz1LzGuotZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (256, 256) # 이미지 사이즈 정규화\n",
        "num_classes = 1 # 레이블 종류 (tumor 1개)\n",
        "\n",
        "# 이미지 전처리\n",
        "resized_imgs = [skit.resize(img, img_size, anti_aliasing=True) for img in img_list] # 이미지 크기 리사이징\n",
        "img_arrays = np.expand_dims(np.array(resized_imgs, dtype=np.float32), axis=-1) # 이미지를 array로 변환\n",
        "input_imgs = (img_arrays - np.min(img_arrays))/(np.max(img_arrays)-np.min(img_arrays)) # 이미지 정규화 (0~1)\n",
        "\n",
        "# 마스크 전처리\n",
        "resized_msks = [skit.resize(msk, img_size) for msk in msk_list] # 이미지 크기 리사이징\n",
        "msk_arrays = np.expand_dims(np.array(resized_msks), axis=-1) # 마스크를 array로 변환\n",
        "targets = np.where(msk_arrays > 0, 1, 0) # 레이블 형태(0,1)로 변환\n",
        "targets = targets.astype(np.uint8)\n",
        "\n",
        "# 이미지 정보\n",
        "print('입력 어레이 크기 = ', input_imgs.shape)\n",
        "print(f'입력 어레이 최대값/최소값 = {np.max(input_imgs)}/{np.min(input_imgs)}')\n",
        "# 마스크 정보\n",
        "print('타겟 어레이 크기 = ', targets.shape)\n",
        "print(f'타켓 어레이 최대값/최소값 = {np.max(targets)}/{np.min(targets)}')"
      ],
      "metadata": {
        "id": "BaJLMHqDR2oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 데이터셋 분할\n",
        "num_val_samples = 100 # 검증 데이터셋에는 100건 사용\n",
        "train_input_imgs = input_imgs[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_input_imgs = input_imgs[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]\n",
        "\n",
        "# 검증 데이터셋 확인\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(131)\n",
        "plt.title('Image')\n",
        "plt.imshow(val_input_imgs[0])\n",
        "plt.subplot(132)\n",
        "plt.title('Mask')\n",
        "plt.imshow(val_targets[0])\n",
        "plt.subplot(133)\n",
        "plt.title('Overlay')\n",
        "plt.imshow(val_input_imgs[0], cmap='gray')\n",
        "plt.imshow(val_targets[0], cmap='Reds', alpha=0.3)"
      ],
      "metadata": {
        "id": "SdVU5b9CR56W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3. Model Build"
      ],
      "metadata": {
        "id": "IqUBHI_Q7GUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet:\n",
        "    def __init__(self, params):\n",
        "        self.input_size = params['input_size']\n",
        "        self.conv_act = params['conv_act']\n",
        "        self.output_num = params['output_num']\n",
        "        self.output_act = params['output_act']\n",
        "    def __call__(self, model_name):\n",
        "        if model_name == \"UNet\":\n",
        "            inputs = Input(shape=self.input_size, name='input_layer')\n",
        "            # Encoder\n",
        "            cblock1 = self.conv_block(inputs, 1, 2, 32, 3, self.conv_act)\n",
        "            pool1 = layers.MaxPooling2D(pool_size=(2, 2), strides=2, name='max_pool%s' %(1))(cblock1)\n",
        "            cblock2 = self.conv_block(pool1, 2, 2, 64, 3, self.conv_act)\n",
        "            pool2 = layers.MaxPooling2D(pool_size=(2, 2), strides=2, name='max_pool%s' %(2))(cblock2)\n",
        "            cblock3 = self.conv_block(pool2, 3, 2, 128, 3, self.conv_act)\n",
        "            pool3 = layers.MaxPooling2D(pool_size=(2, 2), strides=2, name='max_pool%s' %(3))(cblock3)\n",
        "            cblock4 = self.conv_block(pool3, 4, 2, 256, 3, self.conv_act)\n",
        "            pool4 = layers.MaxPooling2D(pool_size=(2, 2), strides=2, name='max_pool%s' %(4))(cblock4)\n",
        "            cblock5 = self.conv_block(pool4, 5, 2, 512, 3, self.conv_act)\n",
        "            pool5 = layers.MaxPooling2D(pool_size=(2, 2), strides=2, name='max_pool%s' %(5))(cblock5)\n",
        "            # Bottleneck\n",
        "            bottleneck = self.conv_block(pool5, 4, 2, 1024, 3, self.conv_act, bottle=True)\n",
        "            # Decoder\n",
        "            up1 = layers.Conv2DTranspose(512, 2, strides=2, name='conv_trans%s' %(1))(bottleneck)\n",
        "            ublock1 = self.up_block(up1, cblock5, 1, 2, 512, 3, self.conv_act)\n",
        "            up2 = layers.Conv2DTranspose(256, 2, strides=2, name='conv_trans%s' %(2))(ublock1)\n",
        "            ublock2 = self.up_block(up2, cblock4, 2, 2, 256, 3, self.conv_act)\n",
        "            up3 = layers.Conv2DTranspose(128, 2, strides=2, name='conv_trans%s' %(3))(ublock2)\n",
        "            ublock3 = self.up_block(up3, cblock3, 3, 2, 128, 3, self.conv_act)\n",
        "            up4 = layers.Conv2DTranspose(64, 2, strides=2, name='conv_trans%s' %(4))(ublock3)\n",
        "            ublock4 = self.up_block(up4, cblock2, 4, 2, 64, 3, self.conv_act)\n",
        "            up5 = layers.Conv2DTranspose(32, 2, strides=2, name='conv_trans%s' %(5))(ublock4)\n",
        "            ublock5 = self.up_block(up5, cblock1, 5, 2, 32, 3, self.conv_act)\n",
        "            outputs = layers.Conv2D(self.output_num, 1, padding='same', activation=self.output_act, name='output_layer')(ublock5)\n",
        "            model = Model(inputs=inputs, outputs=outputs)\n",
        "            return model\n",
        "    def conv_block(self,\n",
        "                   lr_conv, # input layer\n",
        "                   bk_num:int, # block number\n",
        "                   lr_num:int, # convolution number\n",
        "                   filters:int, # filter number\n",
        "                   kern_size:int, # kernel size\n",
        "                   activ:str, # activation\n",
        "                   reg_weight=None, # kernel regularizer\n",
        "                   bottle:bool=False\n",
        "                   ):\n",
        "        # code\n",
        "        for i in range(lr_num):\n",
        "            lr_conv = layers.Conv2D(filters, kern_size, activation=None, padding='same',\n",
        "                                        name=f'conv_block{bk_num}-conv{i+1}' if bottle == False else f'bottleneck-conv{i+1}',\n",
        "                                        kernel_regularizer=reg_weight, kernel_initializer='he_normal')(lr_conv)\n",
        "            lr_conv = layers.BatchNormalization(name=f'conv_block{bk_num}-batch_norm{i+1}' if bottle == False else f'bottleneck-batch_norm{i+1}')(lr_conv)\n",
        "            lr_conv = layers.Activation(activ, name=f'conv_block{bk_num}-activ{i+1}' if bottle == False else f'bottleneck-activ{i+1}')(lr_conv)\n",
        "        return lr_conv\n",
        "\n",
        "    def up_block(self,\n",
        "                 input_up, # up input\n",
        "                 input_skip, # skip input\n",
        "                 bk_num:int, # block number\n",
        "                 lr_num:int, # convolution number\n",
        "                 filters:int, # filters\n",
        "                 kern_size:int, # kernel size\n",
        "                 activ:str, # activation\n",
        "                 reg_weight:str=None # kernel regularizer\n",
        "                 ):\n",
        "        # code\n",
        "        lr_conc = layers.Concatenate(name='up_block%s-concatenate' %(bk_num))([input_skip, input_up])\n",
        "        for i in range(lr_num):\n",
        "            if i == 0:\n",
        "                conv_in = lr_conc\n",
        "            else:\n",
        "                conv_in = lr_conv\n",
        "            lr_conv = layers.Conv2D(filters, kern_size, activation=None, padding='same',\n",
        "                                        name='up_block%s-upsample%s' %(bk_num, i+1),\n",
        "                                        kernel_regularizer=reg_weight, kernel_initializer='he_normal')(conv_in)\n",
        "            lr_conv = layers.BatchNormalization(name='up_block%s-batch_norm%s' %(bk_num, i+1))(lr_conv)\n",
        "            lr_conv = layers.Activation(activ, name='up_block%s-activ%s' %(bk_num, i+1))(lr_conv)\n",
        "        return lr_conv"
      ],
      "metadata": {
        "id": "gt2o2NH5ANpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_param = {'input_size': (256,256,1),\n",
        "              'conv_act': 'relu',\n",
        "              'output_num': 1,\n",
        "              'output_act': 'sigmoid'}\n",
        "\n",
        "unet = UNet(unet_param)\n",
        "model = unet('UNet')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "oh_mnZpyA-E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 일반적인 pixel accuracy가 아니라 dice socre를 활용해보자"
      ],
      "metadata": {
        "id": "s-JzwNsRS3tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "  y_true_f = K.flatten(y_true)\n",
        "  y_pred_f = K.flatten(y_pred)\n",
        "  intersection = K.sum(y_true_f * y_pred_f)\n",
        "  return (2. * intersection + 0.0001) / (K.sum(y_true_f) + K.sum(y_pred_f) + 0.0001)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "  return 1 - dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "qctXPGC2S27z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 컴파일\n",
        "model.compile(optimizer=\"adam\", loss=dice_coef_loss, metrics=['acc', dice_coef])"
      ],
      "metadata": {
        "id": "WGJCKiwUTPt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4. Model Training"
      ],
      "metadata": {
        "id": "YBlJXkbB9won"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callback_list = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),\n",
        "                 keras.callbacks.ModelCheckpoint(filepath='unet_model.h5', monitor='val_loss', save_best_only=True),\n",
        "                 keras.callbacks.ReduceLROnPlateau(monitor='val_dice_coef', factor=0.1, patience=5)]\n",
        "\n",
        "history = model.fit(train_input_imgs, train_targets.astype(np.float16),\n",
        "                    epochs=100,\n",
        "                    callbacks=callback_list,\n",
        "                    batch_size=16,\n",
        "                    validation_data=(val_input_imgs, val_targets.astype(np.float16)))"
      ],
      "metadata": {
        "id": "550iK_Xx9vqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5. Model Evaluate"
      ],
      "metadata": {
        "id": "fELzMz74YE2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 학습 결과 확인"
      ],
      "metadata": {
        "id": "9CK2YCGSYNRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(1, len(history.history[\"loss\"]) + 1)\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "acc = history.history[\"acc\"]\n",
        "val_acc = history.history[\"val_acc\"]\n",
        "dice = history.history[\"dice_coef\"]\n",
        "val_dice = history.history[\"val_dice_coef\"]\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.subplot(131)\n",
        "plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.subplot(132)\n",
        "plt.plot(epochs, acc, \"b\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"r\", label=\"Validation acc\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.subplot(133)\n",
        "plt.plot(epochs, dice, \"b\", label=\"Training Dice\")\n",
        "plt.plot(epochs, val_dice, \"r\", label=\"Validation Dice\")\n",
        "plt.title(\"Training and validation Dice coef.\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "TGZXRJ43YCkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 성능\n",
        "result = model.evaluate(val_input_imgs, val_targets.astype(np.float16))\n",
        "print('test loss = ', result[0])\n",
        "print('test Accuracy = ', result[1])\n",
        "print('test Dice Coef. Score = ', result[2])"
      ],
      "metadata": {
        "id": "ixQtwLivYkDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Model Prediction"
      ],
      "metadata": {
        "id": "8u3BgKXCZUGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(val_input_imgs)\n",
        "print(len(preds))"
      ],
      "metadata": {
        "id": "ehmrr325Y_Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preds[0].shape)"
      ],
      "metadata": {
        "id": "mdqO_OJaZbcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,6))\n",
        "plt.subplot(131)\n",
        "plt.title('MRI')\n",
        "plt.imshow(val_input_imgs[0])\n",
        "plt.subplot(132)\n",
        "plt.title('GT')\n",
        "plt.imshow(val_input_imgs[0], cmap='gray')\n",
        "plt.imshow(val_targets[0], cmap='Reds', alpha=0.3)\n",
        "plt.subplot(133)\n",
        "plt.title('Pred')\n",
        "plt.imshow(val_input_imgs[0], cmap='gray')\n",
        "plt.imshow(preds[0], cmap='Blues', alpha=0.3)"
      ],
      "metadata": {
        "id": "cnxLEEaJZtae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "for i in range(4):\n",
        "  plt.subplot(4,4,1+4*i)\n",
        "  plt.title('MRI')\n",
        "  plt.imshow(val_input_imgs[i])\n",
        "  plt.subplot(4,4,2+4*i)\n",
        "  plt.title('GT')\n",
        "  plt.imshow(val_input_imgs[i], cmap='gray')\n",
        "  plt.imshow(val_targets[i], cmap='Reds', alpha=0.3)\n",
        "  plt.subplot(4,4,3+4*i)\n",
        "  plt.title('Pred')\n",
        "  plt.imshow(val_input_imgs[i], cmap='gray')\n",
        "  plt.imshow(preds[i], cmap='Blues', alpha=0.3)\n",
        "  plt.subplot(4,4,4+4*i)\n",
        "  plt.title('Compare')\n",
        "  plt.imshow(val_targets[i], cmap='Reds', alpha=1)\n",
        "  plt.imshow(preds[i], cmap='Blues', alpha=0.5)\n"
      ],
      "metadata": {
        "id": "R_mdZq_SZdAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "41EsOZwna0Mw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}