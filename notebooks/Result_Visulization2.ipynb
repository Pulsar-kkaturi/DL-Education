{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pulsar-kkaturi/DL-Education/blob/master/notebooks/Result_Visulization2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37DOVvDMm-_A"
      },
      "source": [
        "# Result Visulization (결과 시각화)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4XY8H1nnFe_"
      },
      "source": [
        "# 1. Library Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vEPrq0skcWj"
      },
      "outputs": [],
      "source": [
        "import os, matplotlib, csv, shutil, json\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import pandas as pd\n",
        "from IPython.display import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import skimage\n",
        "from skimage import transform as skit\n",
        "from skimage import filters as skif\n",
        "\n",
        "### Tensorflow 2.0 ###\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as K\n",
        "\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78f6Q_C-8dnh"
      },
      "source": [
        "# 2. 데이터셋 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwNtiL33oGpZ"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test)=keras.datasets.cifar10.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP8qLluRuV2O"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hkS7G1ruu5q"
      },
      "source": [
        "# 2.1 Cifar10 to Cifar2 (airplane, automobile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UHKqWuXuWuu"
      },
      "outputs": [],
      "source": [
        "x_train_list, y_train_list = [], []\n",
        "x_test_list, y_test_list = [], []\n",
        "n0, n1 = 0, 0\n",
        "t0, t1 = 0, 0\n",
        "for i, i_ in enumerate(x_train):\n",
        "  if y_train[i] == 0 and n0 < 500:\n",
        "    arr = skit.resize(i_, (64, 64), anti_aliasing=True)\n",
        "    onehot = [1, 0]\n",
        "    n0 += 1\n",
        "    x_train_list.append(arr)\n",
        "    y_train_list.append(onehot)\n",
        "  elif y_train[i] == 1 and n1 < 500:\n",
        "    arr = skit.resize(i_, (64, 64), anti_aliasing=True)\n",
        "    onehot = [0, 1]\n",
        "    n1 += 1\n",
        "    x_train_list.append(arr)\n",
        "    y_train_list.append(onehot)\n",
        "for i, i_ in enumerate(x_test):\n",
        "    if y_test[i] == 0 and t0 < 100:\n",
        "      arr = skit.resize(i_, (64, 64), anti_aliasing=True)\n",
        "      onehot = [1, 0]\n",
        "      t0 += 1\n",
        "      x_test_list.append(arr)\n",
        "      y_test_list.append(onehot)\n",
        "    elif y_test[i] == 1 and t1 < 100:\n",
        "      arr = skit.resize(i_, (64, 64), anti_aliasing=True)\n",
        "      onehot = [0, 1]\n",
        "      t1 += 1\n",
        "      x_test_list.append(arr)\n",
        "      y_test_list.append(onehot)\n",
        "\n",
        "train_x = np.array(x_train_list)\n",
        "train_y = np.array(y_train_list)\n",
        "print(train_x.shape, train_y.shape)\n",
        "test_x = np.array(x_test_list)\n",
        "test_y = np.array(y_test_list)\n",
        "print(test_x.shape, test_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2-6RHzfvi0N"
      },
      "source": [
        "## 2.2 Cifar2 figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM8fOyzMutQi"
      },
      "outputs": [],
      "source": [
        "label_list = ['ariplane', 'automobile']\n",
        "plt.figure(figsize=(10,10))\n",
        "num = 3\n",
        "for i in range(num):\n",
        "    for j in range(num):\n",
        "      id = (num*i) + j\n",
        "      plt.subplot(num,num,id+1)\n",
        "      plt.imshow(train_x[id])\n",
        "      plt.title('Class = {}'.format(label_list[list(train_y[id]).index(1)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PsuhnRmvosv"
      },
      "source": [
        "# 3. VGG Model Build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQyNwsW7vhw0"
      },
      "outputs": [],
      "source": [
        "def conv_block_2d(lr_conv, lr_num, par_list, bkn):\n",
        "        # parameter\n",
        "        filter_num = par_list[0]\n",
        "        conv_size = par_list[1]\n",
        "        conv_act = par_list[2]\n",
        "        pool_size = par_list[3]\n",
        "        # code\n",
        "        for i in range(lr_num):\n",
        "            lr_conv = layers.Conv2D(filter_num, conv_size, activation=None, padding='same', \n",
        "                                    kernel_initializer='he_normal',\n",
        "                                    name='block{}_conv{}'.format(bkn, i+1))(lr_conv)\n",
        "            lr_conv = layers.BatchNormalization(axis=-1, name='block{}_batchnorm{}'.format(bkn, i+1))(lr_conv)\n",
        "            lr_conv = layers.Activation(conv_act, name='block{}_activ{}'.format(bkn, i+1))(lr_conv)\n",
        "        lr_pool = layers.MaxPooling2D(pool_size=pool_size, name='block{}_pool'.format(bkn, i+1))(lr_conv)\n",
        "        return lr_pool\n",
        "\n",
        "def output_block(lr_dense, block_num, dens_count, act_func, drop_rate):\n",
        "    lr_dense = layers.Flatten(name='flatten_layer')(lr_dense)\n",
        "    for i in range(block_num):\n",
        "        lr_dense = layers.Dense(dens_count[i], kernel_regularizer=None,\n",
        "                                activation=act_func, name='classifier_dense_{}'.format(i+1))(lr_dense)\n",
        "        lr_dense = layers.Dropout(drop_rate, name='classifier_dropout_{}'.format(i+1))(lr_dense)\n",
        "    return lr_dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ6tQ28ZwFmO"
      },
      "outputs": [],
      "source": [
        "def VGG16_2D(par_dic):\n",
        "    # parameters\n",
        "    input_size = par_dic['input_size']\n",
        "    channels = par_dic['channels']\n",
        "    conv_size = par_dic['conv_size']\n",
        "    conv_act = par_dic['conv_act']\n",
        "    pool_size = par_dic['pool_size']\n",
        "    dens_num = par_dic['dens_num']\n",
        "    dens_count = par_dic['dens_count']\n",
        "    dens_act = par_dic['dens_act']\n",
        "    drop_out = par_dic['drop_out']\n",
        "    output_count = par_dic['output_count']\n",
        "    output_act = par_dic['output_act']\n",
        "\n",
        "    # code block\n",
        "    inputs = Input(shape=(input_size, input_size, channels), name='input_layer')\n",
        "    block1 = conv_block_2d(inputs, 2, [64, conv_size, conv_act, pool_size], 1)\n",
        "    block2 = conv_block_2d(block1, 2, [128, conv_size, conv_act, pool_size], 2)\n",
        "    block3 = conv_block_2d(block2, 3, [256, conv_size, conv_act, pool_size], 3)\n",
        "    block4 = conv_block_2d(block3, 3, [512, conv_size, conv_act, pool_size], 4)\n",
        "    block5 = conv_block_2d(block4, 3, [512, conv_size, conv_act, pool_size], 5)\n",
        "    dens = output_block(block5, dens_num, dens_count, dens_act, drop_out)\n",
        "    outputs = layers.Dense(output_count, activation=output_act, name='output_layer')(dens)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEKz3nqgxYQQ"
      },
      "outputs": [],
      "source": [
        "def VGG19_2D(par_dic):\n",
        "    # parameters\n",
        "    input_size = par_dic['input_size']\n",
        "    channels = par_dic['channels']\n",
        "    conv_size = par_dic['conv_size']\n",
        "    conv_act = par_dic['conv_act']\n",
        "    pool_size = par_dic['pool_size']\n",
        "    dens_num = par_dic['dens_num']\n",
        "    dens_count = par_dic['dens_count']\n",
        "    dens_act = par_dic['dens_act']\n",
        "    drop_out = par_dic['drop_out']\n",
        "    output_count = par_dic['output_count']\n",
        "    output_act = par_dic['output_act']\n",
        "\n",
        "    # code block\n",
        "    inputs = Input(shape=(input_size, input_size, channels))\n",
        "    block1 = conv_block_2d(inputs, 2, [64, conv_size, conv_act, pool_size], 1)\n",
        "    block2 = conv_block_2d(block1, 2, [128, conv_size, conv_act, pool_size], 2)\n",
        "    block3 = conv_block_2d(block2, 4, [256, conv_size, conv_act, pool_size], 3)\n",
        "    block4 = conv_block_2d(block3, 4, [512, conv_size, conv_act, pool_size], 4)\n",
        "    block5 = conv_block_2d(block4, 4, [512, conv_size, conv_act, pool_size], 5)\n",
        "    dens = output_block(block5, dens_num, dens_count, dens_act, drop_out)\n",
        "    outputs = layers.Dense(output_count, activation=output_act)(dens)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94txtM58xuKS"
      },
      "outputs": [],
      "source": [
        "network_param_set = {'input_size': 64,\n",
        "                     'channels': 3,\n",
        "                     'conv_size': 3,\n",
        "                     'conv_act': 'relu',\n",
        "                     'pool_size': 2,\n",
        "                     'dens_num': 2,\n",
        "                     'dens_count': [1000,500],\n",
        "                     'dens_act': 'relu',\n",
        "                     'drop_out': 0.5,\n",
        "                     'output_count': 2,\n",
        "                     'output_act': 'softmax'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87IRklsi0_t0"
      },
      "outputs": [],
      "source": [
        "model = VGG16_2D(network_param_set)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRre4jFLxoXI"
      },
      "source": [
        "# 4. MNIST Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jhKYdmd119b"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=losses.CategoricalCrossentropy(), optimizer=optimizers.Adam(lr=1e-4), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3tXYPUV17YC"
      },
      "outputs": [],
      "source": [
        "callback_list = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),\n",
        "                         keras.callbacks.ModelCheckpoint(filepath=os.path.join('model.h5'),\n",
        "                                                         monitor='val_loss', save_best_only=True),\n",
        "                         keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)]\n",
        "\n",
        "history = model.fit(train_x, train_y, epochs=50, batch_size=20, \n",
        "                    validation_data=(test_x, test_y),\n",
        "                    callbacks=callback_list, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVbOLIN1kFq4"
      },
      "source": [
        "# 5. Train Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPK_eXBMkLou"
      },
      "source": [
        "## 5.1. Loss & Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPAPGT9XkC0a"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1,len(acc)+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8uaVegLksW4"
      },
      "outputs": [],
      "source": [
        "plt.plot(epochs, acc, 'b', color='blue', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', color='red', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', color='blue', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', color='red', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD0WC69Fk7af"
      },
      "source": [
        "##5.2. Prediction Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQL2Tcuak_86"
      },
      "outputs": [],
      "source": [
        "test1 = test_x[0]\n",
        "print(test1.shape)\n",
        "plt.imshow(test1)\n",
        "plt.title(label_list[list(test_y[0]).index(1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOqgXtWqlX11"
      },
      "outputs": [],
      "source": [
        "scores = model.predict(test_x)\n",
        "\n",
        "new_scores = []\n",
        "for score in scores:\n",
        "  max_val = np.max(score)\n",
        "  prob_num = label_list[list(score).index(max_val)]\n",
        "  new_scores.append(prob_num)\n",
        "print(new_scores)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_labels = []\n",
        "for y in test_y:\n",
        "  max_val = np.max(y)\n",
        "  prob_num = label_list[list(y).index(max_val)]\n",
        "  new_labels.append(prob_num)\n",
        "print(new_labels)"
      ],
      "metadata": {
        "id": "Ittr2g-sLasq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_x[0])\n",
        "print(f'label={label_list[list(test_y[0]).index(1)]}, predict={new_scores[0]}')\n",
        "print(scores[0])\n"
      ],
      "metadata": {
        "id": "5ornqMTyJUov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3. Confusion Matrix"
      ],
      "metadata": {
        "id": "rkrDS_3ZLgy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf = confusion_matrix(new_labels, new_scores, labels=label_list)\n",
        "print(conf)"
      ],
      "metadata": {
        "id": "51cwU6mvLf3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "ax = sns.heatmap(conf, annot = True, cmap=\"coolwarm\", vmax = 100, \n",
        "                 annot_kws={\"fontsize\":20}, center=50, cbar=True, \n",
        "                 xticklabels=label_list, yticklabels=label_list)\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels',fontsize=20);ax.set_ylabel('True labels',fontsize=20); \n",
        "ax.set_title('Confusion Matrix', fontsize=30); \n",
        "ax.xaxis.set_ticklabels(label_list, fontsize=20); ax.yaxis.set_ticklabels(label_list, fontsize=20)"
      ],
      "metadata": {
        "id": "oPTp7NnfMd4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsqVifQSmj7y"
      },
      "source": [
        "# 6. Result Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1. Class Activation Map"
      ],
      "metadata": {
        "id": "IZxlR82FbsJ8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKaUH9KbwxXv"
      },
      "source": [
        "먼저 GRAD-CAM을 구해주는 함수를 정의한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwn_3iaRoJJz"
      },
      "outputs": [],
      "source": [
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names):\n",
        "\n",
        "    # 1. 먼저 모델에서 마지막 컨브넷층을 output으로 하고, 테스트 이미지를 input으로 하는 모델을 구성한다.\n",
        "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
        "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # 2. 마지막 컨브넷층과 최종 예측결과를 인아웃으로 받는 모델을 구성한다.\n",
        "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    for layer_name in classifier_layer_names:\n",
        "        x = model.get_layer(layer_name)(x)\n",
        "    classifier_model = keras.Model(classifier_input, x)\n",
        "\n",
        "    # 그다음, 테스트 이미지에 대한 가장 높은 예측 클래스와 마지막 컨브넷층에 대한 그래디언트를 구한다.\n",
        "    with tf.GradientTape() as tape:\n",
        "        # 최종 컨브넷층의 결과 추출\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # 예측 클래스 계산\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # 마지막 컨브넷층의 특성맵에 대한 가장 높은 예측 클래스의 그래디언트.\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # 특성 맵 채널별 그래디언트 평균 값이 담긴 (512,) 크기의 벡터.\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # 가장 높은 예측 클래스에 대한 \"채널의 중요도\"를 특성 맵 배열의 채널에 곱한다.\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # 만들어진 특성 맵에서 채널 축을 따라 평균한 값이 클래스 활성화의 히트맵.\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # 마지막으로 구해진 히트맵을 0 ~ 1 사이값으로 정규화\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUkU8LUMy35r"
      },
      "outputs": [],
      "source": [
        "# 테스트 이미지에 대한 히트맵을 구한다.\n",
        "test1 = np.expand_dims(test_x[0], axis=0)\n",
        "heatmap1 = make_gradcam_heatmap(test1, model, 'block4_activ3',['block5_pool','flatten_layer'])\n",
        "heatmap2 = make_gradcam_heatmap(test1, model, 'block5_activ3',['block5_pool','flatten_layer'])\n",
        "print(test1.shape, heatmap1.shape, heatmap2.shape)\n",
        "\n",
        "# Display heatmap\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(heatmap1)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(heatmap2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본크기에 맞게 히트맵 변환\n",
        "hm1 = skit.resize(heatmap1, (64, 64), anti_aliasing=True) \n",
        "hm1 = skif.gaussian(hm1, sigma=3)\n",
        "hm2 = skit.resize(heatmap2, (64, 64), anti_aliasing=True) \n",
        "hm2 = skif.gaussian(hm2, sigma=3)\n",
        "hmn = (hm1+hm2)/2\n",
        "\n",
        "# 히트맵을 0 ~255 사이 값으로 재조정\n",
        "heatmap_n = np.uint8(255 * hmn)\n",
        "test_n = np.uint8(255*test1)\n",
        "\n",
        "# 결과 시각화\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(test_n[0])\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(heatmap_n)\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(test_n[0])\n",
        "plt.imshow(heatmap_n, alpha=0.5)"
      ],
      "metadata": {
        "id": "TIbO9vrhhRRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2. CAM 모듈화"
      ],
      "metadata": {
        "id": "o1EjJnAZSqRr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohFectDW1iLT"
      },
      "outputs": [],
      "source": [
        "def make_gradcam(img_arr):\n",
        "  img1 = np.expand_dims(img_arr, axis=0)\n",
        "  hm1 = make_gradcam_heatmap(img1, model, 'block4_activ3',['block5_pool','flatten_layer'])\n",
        "  hm2 = make_gradcam_heatmap(img1, model, 'block5_activ3',['block5_pool','flatten_layer'])\n",
        "  \n",
        "  # 원본크기에 맞게 히트맵 변환\n",
        "  hm1 = skit.resize(hm1, (64, 64), anti_aliasing=True) \n",
        "  hm1 = skif.gaussian(hm1, sigma=3)\n",
        "  hm2 = skit.resize(hm2, (64, 64), anti_aliasing=True) \n",
        "  hm2 = skif.gaussian(hm2, sigma=3)\n",
        "  hmn = (hm1+hm2)/2\n",
        "\n",
        "  # 히트맵을 0 ~255 사이 값으로 재조정\n",
        "  heatmap1 = np.uint8(255 * hmn)\n",
        "  img1 = np.uint8(255*img1)\n",
        "  return img1[0], heatmap1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "n,s = 5, 0\n",
        "for i in range(n):\n",
        "  for j in range(n):\n",
        "    img, hm = make_gradcam(test_x[(i*n)+j+s])\n",
        "    plt.subplot(n,n,(i*n)+j+1)\n",
        "    plt.imshow(img)\n",
        "    plt.imshow(hm, alpha=0.5, cmap='Reds')\n",
        "    if new_scores[(i*n)+j] == new_labels[(i*n)+j]:\n",
        "      cor = 'True'\n",
        "    else:\n",
        "      cor = 'False'\n",
        "    plt.title(f'({cor})')"
      ],
      "metadata": {
        "id": "jBUAakLwdvU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3. Feature Map 시각화"
      ],
      "metadata": {
        "id": "G4kJ30ZydKT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_outputs = []\n",
        "layer_names = []\n",
        "for layer in model.layers:\n",
        "  if isinstance(layer, (layers.Conv2D, layers.MaxPooling2D)):\n",
        "    layer_outputs.append(layer.output)\n",
        "    layer_names.append(layer.name)\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)"
      ],
      "metadata": {
        "id": "ZicbnZ2tXvFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = np.expand_dims(test_x[0], axis=0)\n",
        "print(test_img.shape)\n",
        "plt.imshow(test_img[0])"
      ],
      "metadata": {
        "id": "27u_j8AgZqsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act_result = activation_model.predict(test_img)\n",
        "print(len(act_result))\n",
        "for act in act_result:\n",
        "  print(act.shape)"
      ],
      "metadata": {
        "id": "A03chMG5YrZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_feature_map(features, all_mode=True):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  if all_mode:\n",
        "    chn = features.shape[-1]\n",
        "    chns = np.sqrt(chn)\n",
        "  else:\n",
        "    chn = 16\n",
        "    chns = 4\n",
        "  for i in range(chn):\n",
        "    plt.subplot(chns, chns, i+1)\n",
        "    plt.imshow(features[0,...,i])"
      ],
      "metadata": {
        "id": "Bj5S-jvmY-Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_feature_map(act_result[1], all_mode=False)"
      ],
      "metadata": {
        "id": "ig5WIAsybT9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,40))\n",
        "for i, i_ in enumerate(act_result):\n",
        "  for j in range(4):\n",
        "    plt.subplot(len(act_result), 4, (4*i)+j+1)\n",
        "    plt.imshow(act_result[i][0,...,j])"
      ],
      "metadata": {
        "id": "flVxFijrp1Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.4. Filter 시각화"
      ],
      "metadata": {
        "id": "wGF2qb5jsYsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient 상승법을 사용한 loss function 최대화\n",
        "def compute_loss(image, filter_index, feature_extractor):\n",
        "    activation = feature_extractor(image)\n",
        "    filter_activation = activation[:, 2:-2, 2:-2, filter_index]\n",
        "    return tf.reduce_mean(filter_activation)\n",
        "\n",
        "def gradient_ascent_step(image, filter_index, learning_rate, feature_extractor):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(image)\n",
        "        loss = compute_loss(image, filter_index, feature_extractor)\n",
        "    grads = tape.gradient(loss, image)\n",
        "    grads = tf.math.l2_normalize(grads)\n",
        "    image += learning_rate * grads\n",
        "    return image"
      ],
      "metadata": {
        "id": "iQ2zf6dDqopw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필터 시각화 함수\n",
        "def generate_filter_pattern(filter_index, img_width, img_height, feature_extractor):\n",
        "    iterations = 30\n",
        "    learning_rate = 10.\n",
        "    image = tf.random.uniform(\n",
        "        minval=0.4,\n",
        "        maxval=0.6,\n",
        "        shape=(1, img_width, img_height, 3))\n",
        "    for i in range(iterations):\n",
        "        image = gradient_ascent_step(image, filter_index, learning_rate, feature_extractor)\n",
        "    return image[0].numpy()"
      ],
      "metadata": {
        "id": "HK74EE7Us7OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deprocess_image(image, margin):\n",
        "    image -= np.mean(image)\n",
        "    image /= np.std(image)\n",
        "    image *= 64\n",
        "    image += 128\n",
        "    image = np.clip(image, 0, 255).astype(np.uint8)\n",
        "    margin = int(image.shape[-2] * margin)\n",
        "    image = image[margin:-margin, margin:-margin, :]\n",
        "    return image.astype(np.uint8)"
      ],
      "metadata": {
        "id": "Lf_18dPBv9aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_visual(layer_name, width, height):\n",
        "  layer = model.get_layer(name=layer_name)\n",
        "  feature_extractor = keras.Model(inputs=model.input, outputs=layer.output)\n",
        "\n",
        "  all_images = []\n",
        "  for filter_index in tqdm(range(25)):\n",
        "      image = deprocess_image(generate_filter_pattern(filter_index, width, height, feature_extractor), 0.1)\n",
        "      all_images.append(image)\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for i in range(5):\n",
        "    for j in range(5):\n",
        "      plt.subplot(5,5,(i*5)+j+1)\n",
        "      plt.imshow(all_images[(i*5)+j])\n"
      ],
      "metadata": {
        "id": "BzbV0x6WvthQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4.1. cifar2 result"
      ],
      "metadata": {
        "id": "t2uVX-qS4DNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    if isinstance(layer, (keras.layers.Conv2D, keras.layers.Activation)):\n",
        "        print(layer.name)"
      ],
      "metadata": {
        "id": "01TMi55HyiOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_visual('block5_conv1', 64, 64)"
      ],
      "metadata": {
        "id": "AZ3xhXDj0ae1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4.2. ImageNet Result"
      ],
      "metadata": {
        "id": "1EUyb2PN35QF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False)\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, (keras.layers.Conv2D)):\n",
        "        print(layer.name)"
      ],
      "metadata": {
        "id": "rKYkKQ6n0fEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "24m_Zc8B51wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_visual('block5_conv1', 256, 256)"
      ],
      "metadata": {
        "id": "CXElFsvU39FH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YU9P4YSj4Kue"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Result_Visulization.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}