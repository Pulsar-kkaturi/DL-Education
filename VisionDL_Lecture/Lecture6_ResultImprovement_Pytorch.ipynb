{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pulsar-kkaturi/DL-Education/blob/master/VisionDL_Lecture/Lecture6_ResultImprovement_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fecjmHu0wCB_"
      },
      "source": [
        "# Lecture 6. Result Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKEUbraoCnSv"
      },
      "source": [
        "## 1. Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twmYH5Y6wCCD"
      },
      "source": [
        "### 컴퓨터 비전(Vision)을 위한 전이학습(Transfer Learning)\n",
        "\n",
        "**Author**: [Sasank Chilamkurthy](https://chsasank.github.io)\n",
        "  **번역**: [박정환](http://github.com/9bow)\n",
        "\n",
        "이 튜토리얼에서는 전이학습(Transfer Learning)을 이용하여 이미지 분류를 위한\n",
        "합성곱 신경망을 어떻게 학습시키는지 배워보겠습니다. 전이학습에 대해서는\n",
        "[CS231n 노트](http://cs231n.github.io/transfer-learning/)_ 에서 더 많은 내용을\n",
        "읽어보실 수 있습니다.\n",
        "\n",
        "위 노트를 인용해보면,\n",
        "\n",
        "    실제로 충분한 크기의 데이터셋을 갖추기는 상대적으로 드물기 때문에,\n",
        "    (무작위 초기화를 통해) 맨 처음부터 합성곱 신경망(Convolutional\n",
        "    Network) 전체를 학습하는 사람은 매우 적습니다. 대신, 매우 큰 데이터셋(예.\n",
        "    100가지 분류에 대해 120만개의 이미지가 포함된 ImageNet)에서 합성곱\n",
        "    신경망(ConvNet)을 미리 학습한 후, 이 합성곱 신경망을 관심있는 작업\n",
        "    을 위한 초기 설정 또는 고정된 특징 추출기(fixed feature extractor)로 사용합니다.\n",
        "\n",
        "이러한 전이학습 시나리오의 주요한 2가지는 다음과 같습니다:\n",
        "\n",
        "-  **합성곱 신경망의 미세조정(finetuning)**: 무작위 초기화 대신, 신경망을\n",
        "   ImageNet 1000 데이터셋 등으로 미리 학습한 신경망으로 초기화합니다. 학습의 나머지\n",
        "   과정들은 평상시와 같습니다.\n",
        "-  **고정된 특징 추출기로써의 합성곱 신경망**: 여기서는 마지막에 완전히 연결\n",
        "   된 계층을 제외한 모든 신경망의 가중치를 고정합니다. 이 마지막의 완전히 연결된\n",
        "   계층은 새로운 무작위의 가중치를 갖는 계층으로 대체되어 이 계층만 학습합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InrzHQ9NwCCF"
      },
      "outputs": [],
      "source": [
        "# License: BSD\n",
        "# Author: Sasank Chilamkurthy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "from PIL import Image\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # 대화형 모드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBqf6ldhwCCG"
      },
      "source": [
        "### 1.1. 데이터 불러오기\n",
        "\n",
        "데이터를 불러오기 위해 torchvision과 torch.utils.data 패키지를 사용하겠습니다.\n",
        "\n",
        "여기서 풀고자 하는 문제는 **개미** 와 **벌** 을 분류하는 모델을 학습하는 것입니다.\n",
        "개미와 벌 각각의 학습용 이미지는 대략 120장 정도 있고, 75개의 검증용 이미지가\n",
        "있습니다. 일반적으로 맨 처음부터 학습을 한다면 이는 일반화하기에는 아주 작은\n",
        "데이터셋입니다. 하지만 우리는 전이학습을 할 것이므로, 일반화를 제법 잘 할 수 있을\n",
        "것입니다.\n",
        "\n",
        "이 데이터셋은 ImageNet의 아주 작은 일부입니다.\n",
        "\n",
        ".. Note ::\n",
        "   데이터를 [여기](https://download.pytorch.org/tutorial/hymenoptera_data.zip)\n",
        "   에서 다운로드 받아 현재 디렉토리에 압축을 푸십시오.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0bAzmAcxgja"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# zip 파일 경로와 압축 해제할 디렉토리 설정\n",
        "zip_file_path = './hymenoptera_data.zip'\n",
        "extract_to_path = './data'\n",
        "\n",
        "# 디렉토리가 존재하지 않으면 생성\n",
        "os.makedirs(extract_to_path, exist_ok=True)\n",
        "\n",
        "# zip 파일 열기\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # 모든 파일을 지정한 디렉토리에 추출\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "\n",
        "print(f'파일이 {extract_to_path} 디렉토리에 성공적으로 압축 해제되었습니다.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EKIhMg-wCCG"
      },
      "outputs": [],
      "source": [
        "# 학습을 위해 데이터 증가(augmentation) 및 일반화(normalization)\n",
        "# 검증을 위한 일반화\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = 'data/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLZtzKAfwCCH"
      },
      "source": [
        "#### 1.1.1. 일부 이미지 시각화하기\n",
        "데이터 증가를 이해하기 위해 일부 학습용 이미지를 시각화해보겠습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJBh4TMowCCH"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"tensor를 입력받아 일반적인 이미지로 보여줍니다.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # 갱신이 될 때까지 잠시 기다립니다.\n",
        "\n",
        "\n",
        "# 학습 데이터의 배치를 얻습니다.\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# 배치로부터 격자 형태의 이미지를 만듭니다.\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfkrX7H1wCCI"
      },
      "source": [
        "### 1.2. 모델 학습하기\n",
        "\n",
        "이제 모델을 학습하기 위한 일반 함수를 작성해보겠습니다. 여기서는 다음 내용들을\n",
        "설명합니다:\n",
        "\n",
        "-  학습률(learning rate) 관리(scheduling)\n",
        "-  최적의 모델 구하기\n",
        "\n",
        "아래에서 ``scheduler`` 매개변수는 ``torch.optim.lr_scheduler`` 의 LR 스케쥴러\n",
        "객체(Object)입니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuUF2U4awCCI"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    # Create a temporary directory to save training checkpoints\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_acc = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            # 각 에폭(epoch)은 학습 단계와 검증 단계를 갖습니다.\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # 모델을 학습 모드로 설정\n",
        "                else:\n",
        "                    model.eval()   # 모델을 평가 모드로 설정\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # 데이터를 반복\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    # 매개변수 경사도를 0으로 설정\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # 순전파\n",
        "                    # 학습 시에만 연산 기록을 추적\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # 학습 단계인 경우 역전파 + 최적화\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # 통계\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                # 모델을 깊은 복사(deep copy)함\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "        # 가장 나은 모델 가중치를 불러오기\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UM3XYLmwCCI"
      },
      "source": [
        "#### 1.2.1. 모델 예측값 시각화하기\n",
        "\n",
        "일부 이미지에 대한 예측값을 보여주는 일반화된 함수입니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SZsXwYswCCJ"
      },
      "outputs": [],
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGAfEmsLwCCJ"
      },
      "source": [
        "### 1.3. 합성곱 신경망 미세조정(finetuning)\n",
        "\n",
        "미리 학습한 모델을 불러온 후 마지막의 완전히 연결된 계층을 초기화합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6w6LPAUPwCCJ"
      },
      "outputs": [],
      "source": [
        "model_ft = models.resnet18(weights='IMAGENET1K_V1')\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# 여기서 각 출력 샘플의 크기는 2로 설정합니다.\n",
        "# 또는, ``nn.Linear(num_ftrs, len (class_names))`` 로 일반화할 수 있습니다.\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 모든 매개변수들이 최적화되었는지 관찰\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 7 에폭마다 0.1씩 학습률 감소\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA_CONjWwCCK"
      },
      "source": [
        "#### 1.3.1. 학습 및 평가하기\n",
        "\n",
        "CPU에서는 15-25분 가량, GPU에서는 1분 이내의 시간이 걸립니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jpy0I6XcwCCK"
      },
      "outputs": [],
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wHBPmBnwCCK"
      },
      "outputs": [],
      "source": [
        "visualize_model(model_ft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E8ktePzwCCK"
      },
      "source": [
        "### 1.4. 고정된 특징 추출기로써의 합성곱 신경망\n",
        "\n",
        "이제, 마지막 계층을 제외한 신경망의 모든 부분을 고정해야 합니다.\n",
        "``requires_grad = False`` 로 설정하여 매개변수를 고정하여 ``backward()`` 중에\n",
        "경사도가 계산되지 않도록 해야합니다.\n",
        "\n",
        "이에 대한 문서는\n",
        "[여기](http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward)_\n",
        "에서 확인할 수 있습니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Db8S0HpNwCCK"
      },
      "outputs": [],
      "source": [
        "model_conv = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 새로 생성된 모듈의 매개변수는 기본값이 requires_grad=True 임\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 이전과는 다르게 마지막 계층의 매개변수들만 최적화되는지 관찰\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 7 에폭마다 0.1씩 학습률 감소\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDtjycOFwCCL"
      },
      "source": [
        "### 1.5. 학습 및 평가하기\n",
        "\n",
        "CPU에서 실행하는 경우 이전과 비교했을 때 약 절반 가량의 시간만이 소요될 것입니다.\n",
        "이는 대부분의 신경망에서 경사도를 계산할 필요가 없기 때문입니다. 하지만,\n",
        "순전파는 계산이 필요합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EntIj6ldwCCL"
      },
      "outputs": [],
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c93qK7pwCCL"
      },
      "outputs": [],
      "source": [
        "visualize_model(model_conv)\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IngKVQSYwCCL"
      },
      "source": [
        "#### 1.5.1. 다른 이미지들에 대한 추론\n",
        "\n",
        "학습된 모델을 사용하여 사용자 지정 이미지에 대해 예측하고,\n",
        "예측된 클래스 레이블을 이미지와 함께 시각화합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrXTX-K8wCCL"
      },
      "outputs": [],
      "source": [
        "def visualize_model_predictions(model,img_path):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "\n",
        "    img = Image.open(img_path)\n",
        "    img = data_transforms['val'](img)\n",
        "    img = img.unsqueeze(0)\n",
        "    img = img.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        ax = plt.subplot(2,2,1)\n",
        "        ax.axis('off')\n",
        "        ax.set_title(f'Predicted: {class_names[preds[0]]}')\n",
        "        imshow(img.cpu().data[0])\n",
        "\n",
        "        model.train(mode=was_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZZrJCc8wCCL"
      },
      "outputs": [],
      "source": [
        "visualize_model_predictions(\n",
        "    model_conv,\n",
        "    img_path='data/hymenoptera_data/val/bees/72100438_73de9f17af.jpg'\n",
        ")\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}