{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pulsar-kkaturi/DL-Education/blob/master/VisionDL_Lecture/Lecture7_Segmentation_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Vuto0cDOYws"
      },
      "source": [
        "# Lecture 7. Image Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkRQHi3EOYwv"
      },
      "source": [
        "## 1. U-Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3VNY-otOYwv"
      },
      "source": [
        "### 1.1. 환경설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHtAZObjOYww"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "\n",
        "# https://pytorch.org/vision/stable/datasets.html\n",
        "# 파이토치에서는 torchvision.datasets에 MNIST 등의 다양한 데이터를 사용하기 용이하게 정리해놨습니다.\n",
        "# 이를 사용하면 데이터를 따로 학습에 맞게 정리하거나 하지 않아도 바로 사용이 가능합니다.\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "# https://pytorch.org/vision/stable/transforms.html\n",
        "# torchvision.transforms에는 이미지 데이터를 자르거나 확대 및 다양하게 변형시키는 함수들이 구현되어 있습니다.\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# https://pytorch.org/docs/stable/data.html\n",
        "# DataLoader는 전처리가 끝난 데이터들을 지정한 배치 크기에 맞게 모아서 전달해주는 역할을 합니다.\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "\n",
        "# 기본 라이브러리\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 영상처리 관련 라이브러리 불러오기\n",
        "import skimage\n",
        "from skimage import io as skio\n",
        "from skimage import transform as skit\n",
        "from skimage import morphology as skim\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz6rn9kCOYwx"
      },
      "outputs": [],
      "source": [
        "# Pytorch GPU check\n",
        "import os, torch\n",
        "print(\"현재 pytorch 버전은 무엇인가? : %s\" %(torch.__version__))\n",
        "print(\"사용 가능한 GPU가 존재하는가? (True or False): \", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"사용 가능한 GPU의 수는 {} 개 입니다.\".format(torch.cuda.device_count()))\n",
        "    print(\"GPU 각각의 이름은 아래와 같습니다.\")\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(\"GPU {}: {}\".format(i, torch.cuda.get_device_name(i)))\n",
        "else:\n",
        "    print(\"사용 가능한 GPU가 존재하지 않습니다. 혹은 GPU를 Pytorch가 찾지 못하고 있습니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93bTzqP3OYwy"
      },
      "source": [
        "### 1.2. 데이터셋"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEdUwpjZOYwy"
      },
      "source": [
        "#### 1.2.1. 데이터셋 다운로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H-NGV2TOYwy"
      },
      "source": [
        "* Dataset Download\n",
        "  - reference link: https://www.kaggle.com/datasets/nikhilroxtomar/brain-tumor-segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPOkev4JOYwy"
      },
      "outputs": [],
      "source": [
        "# 데이터셋을 이 세션으로 불러오기\n",
        "!git clone https://github.com/Pulsar-kkaturi/DL-Education.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJVxkbOqOYwz"
      },
      "outputs": [],
      "source": [
        "# 압축 풀기\n",
        "!tar -zxf ./DL-Education/dataset/brain_seg_2d.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RatSlvStOYwz"
      },
      "outputs": [],
      "source": [
        "img_fol_path = './brain_seg_2d/images'\n",
        "msk_fol_path = './brain_seg_2d/masks'\n",
        "img_file_list = [f for f in sorted(os.listdir(img_fol_path))]\n",
        "msk_file_list = [f for f in sorted(os.listdir(msk_fol_path))]\n",
        "# print(img_file_list)\n",
        "# print(msk_file_list)\n",
        "\n",
        "img_list, msk_list = [], []\n",
        "for i, i_ in enumerate(img_file_list):\n",
        "  img_path = os.path.join(img_fol_path, i_)\n",
        "  msk_path = os.path.join(msk_fol_path, msk_file_list[i])\n",
        "  img_arr = skio.imread(img_path)\n",
        "  msk_arr = skio.imread(msk_path)\n",
        "  img_list.append(img_arr)\n",
        "  msk_list.append(msk_arr)\n",
        "\n",
        "print('Image numbers = ', len(img_list))\n",
        "print('Mask numbers = ', len(msk_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fra3ijhUOYw4"
      },
      "outputs": [],
      "source": [
        "# 이미지 정보\n",
        "print('이미지 크기 = ', img_list[0].shape)\n",
        "print(f'이미지 최대값/최소값 = {np.max(img_list[0])}/{np.min(img_list[0])}')\n",
        "# 마스크 정보\n",
        "print('마스크 크기 = ', msk_list[0].shape)\n",
        "print(f'마스크 최대값/최소값 = {np.max(msk_list[0])}/{np.min(msk_list[0])}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK9FHPzFOYw5"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(131)\n",
        "plt.title('Image')\n",
        "plt.imshow(img_list[0])\n",
        "plt.subplot(132)\n",
        "plt.title('Mask')\n",
        "plt.imshow(msk_list[0])\n",
        "plt.subplot(133)\n",
        "plt.title('Overlay')\n",
        "plt.imshow(img_list[0], cmap='gray')\n",
        "plt.imshow(msk_list[0], cmap='Reds', alpha=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfoPsloJOYw5"
      },
      "source": [
        "#### 1.2.3. 데이터셋 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts8_9cq4OYw5"
      },
      "outputs": [],
      "source": [
        "img_size = (200, 200) # 이미지 사이즈 정규화\n",
        "num_classes = 1 # 레이블 종류 (tumor 1개)\n",
        "\n",
        "# 이미지 전처리\n",
        "resized_imgs = [skit.resize(img, img_size, anti_aliasing=True) for img in img_list] # 이미지 크기 리사이징\n",
        "img_arrays = np.expand_dims(np.array(resized_imgs, dtype=np.float32), axis=-1) # 이미지를 array로 변환\n",
        "input_imgs = (img_arrays - np.min(img_arrays))/(np.max(img_arrays)-np.min(img_arrays)) # 이미지 정규화 (0~1)\n",
        "\n",
        "# 마스크 전처리\n",
        "resized_msks = [skit.resize(msk, img_size) for msk in msk_list] # 이미지 크기 리사이징\n",
        "msk_arrays = np.expand_dims(np.array(resized_msks), axis=-1) # 마스크를 array로 변환\n",
        "targets = np.where(msk_arrays > 0, 1, 0) # 레이블 형태(0,1)로 변환\n",
        "targets = targets.astype(np.uint8)\n",
        "\n",
        "# 이미지 정보\n",
        "print('입력 어레이 크기 = ', input_imgs.shape)\n",
        "print(f'입력 어레이 최대값/최소값 = {np.max(input_imgs)}/{np.min(input_imgs)}')\n",
        "# 마스크 정보\n",
        "print('타겟 어레이 크기 = ', targets.shape)\n",
        "print(f'타켓 어레이 최대값/최소값 = {np.max(targets)}/{np.min(targets)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9N5f5NNOYw6"
      },
      "outputs": [],
      "source": [
        "# 검증 데이터셋 분할\n",
        "num_val_samples = 100 # 검증 데이터셋에는 100건 사용\n",
        "train_input_imgs = input_imgs[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_input_imgs = input_imgs[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]\n",
        "\n",
        "# 검증 데이터셋 확인\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(131)\n",
        "plt.title('Image')\n",
        "plt.imshow(val_input_imgs[0])\n",
        "plt.subplot(132)\n",
        "plt.title('Mask')\n",
        "plt.imshow(val_targets[0])\n",
        "plt.subplot(133)\n",
        "plt.title('Overlay')\n",
        "plt.imshow(val_input_imgs[0], cmap='gray')\n",
        "plt.imshow(val_targets[0], cmap='Reds', alpha=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ3gGEQYOYw6"
      },
      "source": [
        "### 1.3. 학습 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olfvka2hOYw7"
      },
      "source": [
        "#### 1.3.1. 텐서 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5PIORnfOYw7"
      },
      "outputs": [],
      "source": [
        "class BrainDataset(Dataset):\n",
        "    def __init__(self, img_list, lab_list, resize=200):\n",
        "        self.img_list = img_list\n",
        "        self.lab_list = lab_list\n",
        "        self.resize = (resize, resize)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_list[idx]\n",
        "        lab_path = self.lab_list[idx]\n",
        "        img_arr = skio.imread(img_path)\n",
        "        lab_arr = skio.imread(lab_path)\n",
        "\n",
        "        # 이미지 전처리\n",
        "        input_arr = skit.resize(img_arr, self.resize, anti_aliasing=True) # 이미지 크기 리사이징\n",
        "        input_arr = np.expand_dims(np.array(input_arr), axis=0) # 이미지를 tensor로 변환\n",
        "        input_arr = (input_arr - np.min(input_arr))/(np.max(input_arr)-np.min(input_arr)) # 이미지 정규화 (0~1)\n",
        "        input_tensor = torch.tensor(input_arr, dtype=torch.float32)\n",
        "\n",
        "        # 마스크 전처리\n",
        "        output_arr = skit.resize(lab_arr, self.resize) # 이미지 크기 리사이징\n",
        "        output_arr = np.expand_dims(np.array(output_arr), axis=0) # 마스크를 tensor로 변환\n",
        "        output_arr = np.where(output_arr > 0, 1, 0) # 레이블 형태(0,1)로 변환\n",
        "        output_tensor = torch.tensor(output_arr, dtype=torch.float32)\n",
        "\n",
        "        return input_tensor, output_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMVBd-s5OYw7"
      },
      "outputs": [],
      "source": [
        "# 검증 데이터셋 분할\n",
        "img_fol_path = './brain_seg_2d/images'\n",
        "msk_fol_path = './brain_seg_2d/masks'\n",
        "num_val_samples = 100 # 검증 데이터셋에는 100건 사용\n",
        "img_file_list = [os.path.join(img_fol_path, i) for i in sorted(os.listdir(img_fol_path))]\n",
        "msk_file_list = [os.path.join(msk_fol_path, i) for i in sorted(os.listdir(msk_fol_path))]\n",
        "train_images = img_file_list[:-num_val_samples]\n",
        "train_labels = msk_file_list[:-num_val_samples]\n",
        "test_images = img_file_list[-num_val_samples:]\n",
        "test_labels = msk_file_list[-num_val_samples:]\n",
        "print(f'Train Number = ({len(train_images)}/{len(train_labels)})')\n",
        "print(f'Validation Number = ({len(test_images)}/{len(test_labels)})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTtmENREOYw7"
      },
      "outputs": [],
      "source": [
        "brain_train = BrainDataset(train_images, train_labels, resize=256)\n",
        "brain_test = BrainDataset(test_images, test_labels, resize=256)\n",
        "\n",
        "# 데이터셋 확인 (torch tensor)\n",
        "print(brain_train.__len__())\n",
        "print(brain_train.__getitem__(0)[0].size(), brain_train.__len__())\n",
        "print(brain_test.__getitem__(0)[0].size(), brain_test.__len__())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enSguEtsOYw8"
      },
      "outputs": [],
      "source": [
        "print(brain_test[0][0].size()) # 0번째 프레임의 이미지 크기 출력\n",
        "print(brain_test[0][1].size()) # 0번째 프레임의 레이블 크기 출력\n",
        "plt.figure(figsize=(12,7))\n",
        "for i in range(4): # 4개의 데이터 추가 확인\n",
        "    plt.subplot(2,4,i+1)\n",
        "    plt.imshow(np.moveaxis(brain_test[i][0].numpy(), 0, -1)) # np.moveaxis()는 channel 위치를 0 -> -1로 옮겨준다.\n",
        "    plt.title(f'image_{i+1}')\n",
        "    plt.subplot(2,4,i+5)\n",
        "    plt.imshow(np.moveaxis(brain_test[i][1].numpy(), 0, -1)) # np.moveaxis()는 channel 위치를 0 -> -1로 옮겨준다.\n",
        "    plt.title(f'label_{i+1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD3e-zBsOYw8"
      },
      "source": [
        "#### 1.4. 모델 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJXEd-nwOYw8"
      },
      "outputs": [],
      "source": [
        "# 자주 쓰는 연산들과 항상 세트로 쓰는 연산들은 편의를 위해 함수로 정의해 놓습니다.\n",
        "\n",
        "def conv_block(in_dim,out_dim,act_fn):\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_dim,out_dim, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_dim),\n",
        "        act_fn,\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def conv_trans_block(in_dim,out_dim,act_fn):\n",
        "    model = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_dim,out_dim, kernel_size=3, stride=2, padding=1,output_padding=1),\n",
        "        nn.BatchNorm2d(out_dim),\n",
        "        act_fn,\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def maxpool():\n",
        "    pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    return pool\n",
        "\n",
        "def conv_block_2(in_dim,out_dim,act_fn):\n",
        "    model = nn.Sequential(\n",
        "        conv_block(in_dim,out_dim,act_fn),\n",
        "        nn.Conv2d(out_dim,out_dim, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_dim),\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jivDB-tOYw8"
      },
      "outputs": [],
      "source": [
        "class UnetGenerator(nn.Module):\n",
        "    def __init__(self,in_dim,out_dim,num_filter):\n",
        "        super(UnetGenerator,self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.num_filter = num_filter\n",
        "        act_fn = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "        self.down_1 = conv_block_2(self.in_dim,self.num_filter,act_fn)\n",
        "        self.pool_1 = maxpool()\n",
        "        self.down_2 = conv_block_2(self.num_filter*1,self.num_filter*2,act_fn)\n",
        "        self.pool_2 = maxpool()\n",
        "        self.down_3 = conv_block_2(self.num_filter*2,self.num_filter*4,act_fn)\n",
        "        self.pool_3 = maxpool()\n",
        "        self.down_4 = conv_block_2(self.num_filter*4,self.num_filter*8,act_fn)\n",
        "        self.pool_4 = maxpool()\n",
        "\n",
        "        self.bridge = conv_block_2(self.num_filter*8,self.num_filter*16,act_fn)\n",
        "\n",
        "        self.trans_1 = conv_trans_block(self.num_filter*16,self.num_filter*8,act_fn)\n",
        "        self.up_1 = conv_block_2(self.num_filter*16,self.num_filter*8,act_fn)\n",
        "        self.trans_2 = conv_trans_block(self.num_filter*8,self.num_filter*4,act_fn)\n",
        "        self.up_2 = conv_block_2(self.num_filter*8,self.num_filter*4,act_fn)\n",
        "        self.trans_3 = conv_trans_block(self.num_filter*4,self.num_filter*2,act_fn)\n",
        "        self.up_3 = conv_block_2(self.num_filter*4,self.num_filter*2,act_fn)\n",
        "        self.trans_4 = conv_trans_block(self.num_filter*2,self.num_filter*1,act_fn)\n",
        "        self.up_4 = conv_block_2(self.num_filter*2,self.num_filter*1,act_fn)\n",
        "\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Conv2d(self.num_filter,self.out_dim,3,1,1),\n",
        "            nn.Sigmoid(),  #필수는 아님\n",
        "        )\n",
        "\n",
        "    def forward(self,input):\n",
        "        down_1 = self.down_1(input)\n",
        "        pool_1 = self.pool_1(down_1)\n",
        "        down_2 = self.down_2(pool_1)\n",
        "        pool_2 = self.pool_2(down_2)\n",
        "        down_3 = self.down_3(pool_2)\n",
        "        pool_3 = self.pool_3(down_3)\n",
        "        down_4 = self.down_4(pool_3)\n",
        "        pool_4 = self.pool_4(down_4)\n",
        "\n",
        "\n",
        "        bridge = self.bridge(pool_4)\n",
        "\n",
        "        trans_1 = self.trans_1(bridge)\n",
        "        concat_1 = torch.cat([trans_1,down_4],dim=1)\n",
        "        up_1 = self.up_1(concat_1)\n",
        "        trans_2 = self.trans_2(up_1)\n",
        "        concat_2 = torch.cat([trans_2,down_3],dim=1)\n",
        "        up_2 = self.up_2(concat_2)\n",
        "        trans_3 = self.trans_3(up_2)\n",
        "        concat_3 = torch.cat([trans_3,down_2],dim=1)\n",
        "        up_3 = self.up_3(concat_3)\n",
        "        trans_4 = self.trans_4(up_3)\n",
        "        concat_4 = torch.cat([trans_4,down_1],dim=1)\n",
        "        up_4 = self.up_4(concat_4)\n",
        "        out = self.out(up_4)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drh3tFGJOYw8"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "img_size = 256\n",
        "in_dim = 1\n",
        "out_dim = 1\n",
        "num_filters = 32\n",
        "\n",
        "train_loader = DataLoader(brain_train, batch_size=batch_size, shuffle=True, num_workers=2,drop_last=True)\n",
        "test_loader = DataLoader(brain_test, batch_size=batch_size, shuffle=False, num_workers=2,drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq6ddYF6OYw9"
      },
      "outputs": [],
      "source": [
        "# gpu가 사용 가능한 경우에는 device를 gpu로 설정하고 불가능하면 cpu로 설정합니다.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# 모델을 지정한 장치로 올립니다.\n",
        "model = UnetGenerator(in_dim=in_dim,out_dim=out_dim,num_filter=num_filters).to(device)\n",
        "\n",
        "# 손실함수로는 Binary Cross-Entropy Loss를 사용합니다.\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# 평가 지표로는 DIce score를 사용합니다.\n",
        "def dice_score(predicted, target):\n",
        "    intersection = torch.sum(predicted * target)\n",
        "    union = torch.sum(predicted) + torch.sum(target)\n",
        "    dice = (2.0 * intersection + 1e-5) / (union + 1e-5)\n",
        "    return dice\n",
        "\n",
        "# 손실함수로는 Binary Cross-Entropy Loss를 사용합니다.\n",
        "def dice_loss(predicted, target):\n",
        "    intersection = torch.sum(predicted * target)\n",
        "    union = torch.sum(predicted) + torch.sum(target)\n",
        "    dice = (2.0 * intersection + 1e-5) / (union + 1e-5)\n",
        "    return 1-dice\n",
        "# loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# 최적화함수로는 Adam을 사용합니다.\n",
        "learning_rate = 0.0001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVXV9TmKOYw9"
      },
      "outputs": [],
      "source": [
        "summary(model, (1,256,256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhHYUyeTOYw9"
      },
      "source": [
        "### 1.4. 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XxDsXcAOYw-"
      },
      "outputs": [],
      "source": [
        "# 학습 모듈\n",
        "def train(dataloader, model, loss_fn, metric_fn, optimizer, epoch, ):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.train()\n",
        "    pbar = tqdm(total=num_batches)\n",
        "    train_loss, train_met = 0, 0\n",
        "\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "        metric = metric_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Epoch result\n",
        "        train_loss += loss.item()\n",
        "        train_met += metric.item()\n",
        "\n",
        "        # Traing Process check\n",
        "        loss, metric, current = loss.item(), metric.item(), (batch + 1) * len(x)\n",
        "        pbar.set_description(f\" - Batch Training[{epoch}]({current}/{size}): loss = {loss:>5f}, dice = {metric:>0.3f}\")\n",
        "        pbar.update(1)\n",
        "    pbar.close()\n",
        "    # epoch\n",
        "    train_loss /= num_batches\n",
        "    train_met /= num_batches\n",
        "    return train_loss, train_met"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qvlIRQuOYw-"
      },
      "outputs": [],
      "source": [
        "# 검증 모듈\n",
        "def test(dataloader, model, loss_fn, metric_fn, epoch, show=False):\n",
        "    # size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, test_met = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            test_met += metric_fn(pred, y).item()\n",
        "    test_loss /= num_batches\n",
        "    test_met /= num_batches\n",
        "    if show:\n",
        "        print(f\"    = Validation[{epoch}]: val_loss = {test_loss:>5f}, val_dice: {(test_met):>0.3f}%\")\n",
        "    return test_loss, test_met"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpriyEJhOYw_"
      },
      "outputs": [],
      "source": [
        "num_epoch = 10\n",
        "\n",
        "best_model = None\n",
        "best_loss = float('inf')\n",
        "\n",
        "history = {'loss': [], 'val_loss': [], 'dice': [], 'val_dice': []}\n",
        "for t in range(num_epoch):\n",
        "    train_loss, train_met = train(train_loader, model, dice_loss, dice_score, optimizer, t+1)\n",
        "    val_loss, val_met = test(test_loader, model, dice_loss, dice_score, t+1)\n",
        "\n",
        "    # Best Validation loss save\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        best_model = model.state_dict()\n",
        "\n",
        "    history['loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['dice'].append(train_met)\n",
        "    history['val_dice'].append(val_met)\n",
        "    print(f'# Training[{t+1}/{num_epoch}]: loss = {train_loss:>5f}, dice = {train_met:>0.3f}, val_loss = {val_loss:5>f}, val_dice = {val_met:>0.3f}')\n",
        "\n",
        "torch.save(best_model, 'best_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsm54B0AOYxA"
      },
      "source": [
        "### 1.5. 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfafTmdYOYxA"
      },
      "outputs": [],
      "source": [
        "for key in history.keys():\n",
        "    print(key, history[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DIuMMAfOYxA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(121)\n",
        "plt.title('Loss')\n",
        "plt.plot(history['loss'], c='b', label='train')\n",
        "plt.plot(history['val_loss'], c='r', label='validation')\n",
        "plt.legend()\n",
        "plt.subplot(122)\n",
        "plt.title('Dice')\n",
        "plt.plot(history['dice'], c='b', label='train')\n",
        "plt.plot(history['val_dice'], c='r', label='validation')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4lw0nhROYxB"
      },
      "outputs": [],
      "source": [
        "# 저장된 모델 불러오기\n",
        "model = UnetGenerator(in_dim=in_dim,out_dim=out_dim,num_filter=num_filters).to(device)\n",
        "model.load_state_dict(torch.load('./best_model.h5'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ohJPhCgOYxB"
      },
      "outputs": [],
      "source": [
        "pred_list = []\n",
        "with torch.no_grad():\n",
        "    for img, lab in test_loader:\n",
        "        x = img.to(device)\n",
        "        pred = model.forward(x)\n",
        "        for i in range(len(x)):\n",
        "            probs = pred[i].cpu().detach().numpy()\n",
        "            pred_list.append(probs)\n",
        "print(pred_list[0].shape)\n",
        "print(len(pred_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MCNMOTtOYxB"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "for i in range(4):\n",
        "    img = np.moveaxis(brain_test[i][0].detach().numpy(), 0 , -1)\n",
        "    label = np.moveaxis(brain_test[i][1].detach().numpy(), 0 , -1)\n",
        "    pred = np.moveaxis(pred_list[i], 0 , -1)\n",
        "    plt.subplot(3,4,i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f'image_{i+1}')\n",
        "    plt.subplot(3,4,i+5)\n",
        "    plt.imshow(label)\n",
        "    plt.title(f'label_{i+1}')\n",
        "    plt.subplot(3,4,i+9)\n",
        "    plt.imshow(pred)\n",
        "    plt.title(f'prediction_{i+1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS4su2WTOYxB"
      },
      "outputs": [],
      "source": [
        "n = 0\n",
        "img = np.moveaxis(brain_test[n][0].detach().numpy(), 0 , -1)\n",
        "label = np.moveaxis(brain_test[n][1].detach().numpy(), 0 , -1)\n",
        "pred = np.moveaxis(pred_list[n], 0 , -1)\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.subplot(131)\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.imshow(label, cmap='Reds', alpha=0.2)\n",
        "plt.title('Label')\n",
        "plt.subplot(132)\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.imshow(pred, cmap='Blues', alpha=0.2)\n",
        "plt.title('Prediction')\n",
        "plt.subplot(133)\n",
        "plt.imshow(pred, cmap='Blues', alpha=0.5)\n",
        "plt.imshow(label, cmap='Reds', alpha=0.5)\n",
        "plt.title('Comparison')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPH1lhmjOYxG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}