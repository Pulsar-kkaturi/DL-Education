{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lecture 9. Generative Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "SkmcZfUshJLG"
      },
      "source": [
        "## 1. Image Style Transfer\n",
        "\n",
        "![alt text](https://bloglunit.files.wordpress.com/2017/04/e18489e185b3e1848fe185b3e18485e185b5e186abe18489e185a3e186ba-2017-05-16-e1848be185a9e18492e185ae-1-50-07.png)\n",
        "\n",
        "- A Neural Algorithm of Artistic Style (https://arxiv.org/abs/1508.06576)\n",
        "- Pretrained ResNet50\n",
        "- Reference below\n",
        "- https://discuss.pytorch.org/t/how-to-extract-features-of-an-image-from-a-trained-model/119/3\n",
        "- https://github.com/leongatys/PytorchNeuralStyleTransfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HctlUrAAi9yB",
        "outputId": "4421ea4b-9ecc-4ee1-eadb-e3f7576c4446"
      },
      "outputs": [],
      "source": [
        "# 필요한 이미지들을 다운받습니다.\n",
        "\n",
        "!rm -r images\n",
        "import os\n",
        "\n",
        "try:\n",
        "  os.mkdir(\"images\")\n",
        "  os.mkdir(\"images/content\")\n",
        "  os.mkdir(\"images/style\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg -P images/content\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1280px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg -P images/style"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su2DR0W-hJLJ"
      },
      "source": [
        "### 1.1. Settings\n",
        "#### 1.1.1. Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pKUSKKqhJLL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils as utils\n",
        "import torch.utils.data as data\n",
        "import torchvision.models as models\n",
        "import torchvision.utils as v_utils\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCQzolImhJLR"
      },
      "source": [
        "#### 1.1.2. Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqSqMQJQhJLS"
      },
      "outputs": [],
      "source": [
        "# 컨텐츠 손실을 어느 지점에서 맞출것인지 지정해놓습니다.\n",
        "content_layer_num = 1\n",
        "image_size = 512\n",
        "epoch = 5000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKseM74dhJLZ"
      },
      "source": [
        "### 1.2. Data\n",
        "#### 1.2.1. Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4B4QT0JhJLc"
      },
      "outputs": [],
      "source": [
        "content_dir = \"./images/content/Tuebingen_Neckarfront.jpg\"\n",
        "style_dir = \"./images/style/1280px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwG8VswKhJLg"
      },
      "source": [
        "#### 1.2.2. Prepocessing Function\n",
        "- 전처리 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAUqtQpRhJLh"
      },
      "outputs": [],
      "source": [
        "# 이미 학습된 ResNet 모델이 이미지넷으로 학습된 모델이기 때문에 이에 따라 정규화해줍니다.\n",
        "\n",
        "def image_preprocess(img_dir):\n",
        "    img = Image.open(img_dir)\n",
        "    transform = transforms.Compose([\n",
        "                    transforms.Resize(image_size),\n",
        "                    transforms.CenterCrop(image_size),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(mean=[0.40760392, 0.45795686, 0.48501961],\n",
        "                                         std=[1,1,1]),\n",
        "                ])\n",
        "    img = transform(img).view((-1,3,image_size,image_size))\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUGQV0EvhJLn"
      },
      "source": [
        "#### 1.2.3. Post processing Function\n",
        "- 후처리 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY_XL_-ehJLp"
      },
      "outputs": [],
      "source": [
        "# 정규화 된 상태로 연산을 진행하고 다시 이미지화 해서 보기위해 뺐던 값들을 다시 더해줍니다.\n",
        "# 또한 이미지가 0에서 1사이의 값을 가지게 해줍니다.\n",
        "\n",
        "def image_postprocess(tensor):\n",
        "    transform = transforms.Normalize(mean=[-0.40760392, -0.45795686, -0.48501961],\n",
        "                                     std=[1,1,1])\n",
        "    img = transform(tensor.clone())\n",
        "    img = img.clamp(0,1)\n",
        "    img = torch.transpose(img,0,1)\n",
        "    img = torch.transpose(img,1,2)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M69L17TihJL8"
      },
      "source": [
        "### 1.3. Model & Loss Function\n",
        "#### 1.3.1. Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzBsHtB1hJL9",
        "outputId": "9c7f9603-9283-4bb5-a1f5-fafe873b3eb9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# 미리 학습된 resnet50를 사용합니다.\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "for name,module in resnet.named_children():\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc8JSJuMhJMG"
      },
      "source": [
        "#### 1.3.2. Delete Fully Connected Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLETfWPthJMH"
      },
      "outputs": [],
      "source": [
        "# 레이어마다 결과값을 가져올 수 있게 forward를 정의합니다.\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Resnet,self).__init__()\n",
        "        self.layer0 = nn.Sequential(*list(resnet.children())[0:1])\n",
        "        self.layer1 = nn.Sequential(*list(resnet.children())[1:4])\n",
        "        self.layer2 = nn.Sequential(*list(resnet.children())[4:5])\n",
        "        self.layer3 = nn.Sequential(*list(resnet.children())[5:6])\n",
        "        self.layer4 = nn.Sequential(*list(resnet.children())[6:7])\n",
        "        self.layer5 = nn.Sequential(*list(resnet.children())[7:8])\n",
        "\n",
        "    def forward(self,x):\n",
        "        out_0 = self.layer0(x)\n",
        "        out_1 = self.layer1(out_0)\n",
        "        out_2 = self.layer2(out_1)\n",
        "        out_3 = self.layer3(out_2)\n",
        "        out_4 = self.layer4(out_3)\n",
        "        out_5 = self.layer5(out_4)\n",
        "        return out_0, out_1, out_2, out_3, out_4, out_5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "rz06Ml1ehJML"
      },
      "source": [
        "#### 1.3.3. Gram Matrix Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLsk4GwlhJMM"
      },
      "outputs": [],
      "source": [
        "# 그람 행렬을 생성하는 클래스 및 함수를 정의합니다.\n",
        "# [batch,channel,height,width] -> [b,c,h*w]\n",
        "# [b,c,h*w] x [b,h*w,c] = [b,c,c]\n",
        "\n",
        "class GramMatrix(nn.Module):\n",
        "    def forward(self, input):\n",
        "        b,c,h,w = input.size()\n",
        "        F = input.view(b, c, h*w)\n",
        "        G = torch.bmm(F, F.transpose(1,2))\n",
        "        return G"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq4FK2UghJMP"
      },
      "source": [
        "#### 1.3.4. Model on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFjEjaeQhJMQ",
        "outputId": "fbe66ddf-a7bf-4f89-d3be-43a82b2c1ab6"
      },
      "outputs": [],
      "source": [
        "# 모델을 학습의 대상이 아니기 때문에 requires_grad를 False로 설정합니다.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "resnet = Resnet().to(device)\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3c3FMTzhJMU"
      },
      "source": [
        "#### 1.3.5. Gram Matrix Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBV1zMXfhJMV"
      },
      "outputs": [],
      "source": [
        "# 그람행렬간의 손실을 계산하는 클래스 및 함수를 정의합니다.\n",
        "\n",
        "class GramMSELoss(nn.Module):\n",
        "    def forward(self, input, target):\n",
        "        out = nn.MSELoss()(GramMatrix()(input), target)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ7-SYokhJMY"
      },
      "source": [
        "### 1.4. Train\n",
        "#### 1.4.1. Prepare Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ci1KGWNThJMZ",
        "outputId": "6b273687-b1b1-488d-8db1-7a483f7694c8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# 컨텐츠 이미지, 스타일 이미지, 학습의 대상이 되는 이미지를 정의합니다.\n",
        "\n",
        "content = image_preprocess(content_dir).to(device)\n",
        "style = image_preprocess(style_dir).to(device)\n",
        "generated = content.clone().requires_grad_().to(device)\n",
        "\n",
        "print(content.requires_grad,style.requires_grad,generated.requires_grad)\n",
        "\n",
        "# 각각을 시각화 합니다.\n",
        "\n",
        "plt.imshow(image_postprocess(content[0].cpu()))\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(image_postprocess(style[0].cpu()))\n",
        "plt.show()\n",
        "\n",
        "gen_img = image_postprocess(generated[0].cpu()).data.numpy()\n",
        "plt.imshow(gen_img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhXSiPhchJMe"
      },
      "source": [
        "#### 1.4.2. Set Targets & Style Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17oym5hMhJMf"
      },
      "outputs": [],
      "source": [
        "# 목표값을 설정하고 행렬의 크기에 따른 가중치도 함께 정의해놓습니다\n",
        "\n",
        "style_target = list(GramMatrix().to(device)(i) for i in resnet(style))\n",
        "content_target = resnet(content)[content_layer_num]\n",
        "style_weight = [1/n**2 for n in [64,64,256,512,1024,2048]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2mJgogOhJMl"
      },
      "source": [
        "#### 1.4.3. Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfz8A6eVhJMl",
        "outputId": "a6f53e8c-5841-44c5-ad5b-4210429b4a6b"
      },
      "outputs": [],
      "source": [
        "# LBFGS 최적화 함수를 사용합니다.\n",
        "# 이때 학습의 대상은 모델의 가중치가 아닌 이미지 자체입니다.\n",
        "# for more info about LBFGS -> http://pytorch.org/docs/optim.html?highlight=lbfgs#torch.optim.LBFGS\n",
        "\n",
        "optimizer = optim.LBFGS([generated])\n",
        "\n",
        "iteration = [0]\n",
        "while iteration[0] < epoch:\n",
        "    def closure():\n",
        "        optimizer.zero_grad()\n",
        "        out = resnet(generated)\n",
        "\n",
        "        # 스타일 손실을 각각의 목표값에 따라 계산하고 이를 리스트로 저장합니다.\n",
        "        style_loss = [GramMSELoss().to(device)(out[i],style_target[i])*style_weight[i] for i in range(len(style_target))]\n",
        "\n",
        "        # 컨텐츠 손실은 지정한 위치에서만 계산되므로 하나의 수치로 저장됩니다.\n",
        "        content_loss = nn.MSELoss().to(device)(out[content_layer_num],content_target)\n",
        "\n",
        "        # 스타일:컨텐츠 = 1000:1의 비중으로 총 손실을 계산합니다.\n",
        "        total_loss = 1000 * sum(style_loss) + torch.sum(content_loss)\n",
        "        total_loss.backward()\n",
        "\n",
        "        if iteration[0] % 100 == 0:\n",
        "            print(total_loss)\n",
        "        iteration[0] += 1\n",
        "        return total_loss\n",
        "\n",
        "    optimizer.step(closure)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSuUgaAShJMo"
      },
      "source": [
        "### 1.5. Check Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "dDM-c1lbhJMp",
        "outputId": "15cc7050-2221-40a1-93a6-e676b9354f40"
      },
      "outputs": [],
      "source": [
        "# 학습된 결과 이미지를 확인합니다.\n",
        "\n",
        "gen_img = image_postprocess(generated[0].cpu()).data.numpy()\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(gen_img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAeA-UJCqENu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
