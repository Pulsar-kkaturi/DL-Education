{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\[7\\] Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, matplotlib, csv, shutil, json, random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "import skimage\n",
    "from skimage import io as skio\n",
    "from skimage import transform as skit\n",
    "\n",
    "# scikit-learn\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "# https://pytorch.org/vision/stable/datasets.html\n",
    "# 파이토치에서는 torchvision.datasets에 MNIST 등의 다양한 데이터를 사용하기 용이하게 정리해놨습니다.\n",
    "# 이를 사용하면 데이터를 따로 학습에 맞게 정리하거나 하지 않아도 바로 사용이 가능합니다.\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "# https://pytorch.org/vision/stable/transforms.html\n",
    "# torchvision.transforms에는 이미지 데이터를 자르거나 확대 및 다양하게 변형시키는 함수들이 구현되어 있습니다.\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# https://pytorch.org/docs/stable/data.html\n",
    "# DataLoader는 전처리가 끝난 데이터들을 지정한 배치 크기에 맞게 모아서 전달해주는 역할을 합니다.\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Data Loading\n",
    "* Kaggle Garbage Classification Dataset\n",
    "  - Reference link: https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Download\n",
    "!git clone https://github.com/Pulsar-kkaturi/DL-Education.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 압축 풀기\n",
    "!tar -zxf ./DL-Education/dataset/garbage_cls_2d.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './garbage_cls_2d'\n",
    "label_list = list(sorted(os.listdir(data_path)))\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data number check\n",
    "for c in label_list:\n",
    "  cn = 0\n",
    "  cls_path = os.path.join(data_path, c)\n",
    "  for f in os.listdir(cls_path):\n",
    "    cn += 1\n",
    "  print(f'{c} number = {cn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visulization\n",
    "plt.figure(figsize=(12,6))\n",
    "for i, c in enumerate(label_list):\n",
    "  cls_path = os.path.join(data_path, c)\n",
    "  sam_path = os.path.join(cls_path, os.listdir(cls_path)[0])\n",
    "  sam_arr = skio.imread(sam_path)\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.title(c)\n",
    "  plt.imshow(sam_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "for c in label_list:\n",
    "  onehot = [0]*len(label_list)\n",
    "  onehot[label_list.index(c)] = 1\n",
    "  print(c, label_list.index(c), onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy array로 데이터 변환\n",
    "data_dic, label_dic = {}, {}\n",
    "for key in label_list:\n",
    "  data_dic[key] = []\n",
    "  label_dic[key] = []\n",
    "\n",
    "for i, c in enumerate(label_list):\n",
    "  cls_path = os.path.join(data_path, c)\n",
    "  for f in sorted(os.listdir(cls_path)):\n",
    "    file_path = os.path.join(cls_path, f)\n",
    "    data_arr = skio.imread(file_path)\n",
    "    onehot = [0]*len(label_list)\n",
    "    onehot[label_list.index(c)] = 1\n",
    "    data_dic[c].append(data_arr)\n",
    "    label_dic[c].append(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "for i, k in enumerate(data_dic.keys()):\n",
    "  print(f'{k}: data_number = {len(data_dic[k])}, label_number = {len(label_dic[k])}')\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.title(f'{k}: {label_dic[k][0]}')\n",
    "  plt.imshow(data_dic[k][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Tensor Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
